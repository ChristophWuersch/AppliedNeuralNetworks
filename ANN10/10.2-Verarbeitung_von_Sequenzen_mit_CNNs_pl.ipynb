{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\"  align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch, François Chollet </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik-neu/systemtechnik/ice-institut-fuer-computational-engineering\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN10/10.2-Verarbeitung_von_Sequenzen_mit_CNNs_pl.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In Kapitel 5 haben Sie CNNs kennengelernt und erfahren, dass sie besonders gut\n",
    "für Aufgabenstellungen des maschinellen Sehens geeignet sind. \n",
    "- Sie verdanken das ihrer Fähigkeit, durch Faltungsoperationen Merkmale **lokaler Eingabe-Patches** zu extrahieren. \n",
    "- Darüber hinaus ermöglichen sie **modulare Repräsentationen** und bieten eine effiziente Verwaltung der Daten. \n",
    "- Dieselben Eigenschaften, die dafür verantwortlich sind, dass sich CNNs beim maschinellen Sehen hervortun, sorgen auch dafür, dass ihnen bei der Verarbeitung von Sequenzen grosse Bedeutung zukommt. \n",
    "- **Die Zeit kann als eine räumliche Dimension behandelt** werden – wie die Höhe oder die Breite eines zweidimensionalen Bildes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Eindimensionale CNNs können sich bei bestimmten Aufgaben der Sequenzverarbeitung durchaus mit RNNs messen, benötigen dafür aber in der Regel einen **erheblich geringeren Rechenaufwand**. \n",
    "- In jüngster Zeit sind eindimensionale CNNs, die typischerweise einen erweiterten Kernel verwenden, mit großem Erfolg zur Klangerzeugung und zur maschinellen Übersetzung von Fremdsprachen eingesetzt worden.\n",
    "- Von diesen gelungenen Ergebnissen einmal abgesehen, ist seit Langem bekannt, dass kleine eindimensionale CNNs bei einfachen Aufgaben wie Textklassifizierung und Vorhersage von Zeitreihen eine **schnelle Alternative zu RNNs** darstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import torch\n",
    "import tarfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 10.2 Eindimensionale Faltung sequenzieller Daten \n",
    "(sequence processing with convnets)\n",
    "\n",
    "Dieses Notizbuch enthält die Codebeispiele aus Kapitel 6, Abschnitt 3 von [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). \n",
    "\n",
    "\n",
    " Bei den bislang verwendeten Convolutional Layern handelte es sich um 2-D-Faltungen,\n",
    "die Patches aus den Bildtensoren extrahieren und auf jeden Patch dieselbe\n",
    "Transformation anwenden. Auf ähnliche Weise kann eine eindimensionale Faltung\n",
    "verwendet werden, um lokale 1-D-Patches aus Sequenzen zu extrahieren\n",
    "(also Untersequenzen, siehe folgende Abbildung).\n",
    "\n",
    "<img src=\"Bilder/1D_CNN.png\" width=\"440\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Diese eindimensionalen Convolutional Layer sind in der Lage, lokale Muster in\n",
    "einer Sequenz zu erkennen. Da auf alle Patches dieselbe Transformation angewendet\n",
    "wird, kann ein an einer bestimmten Stelle im Satz erlerntes Muster später an\n",
    "einer anderen Stelle ebenfalls erkannt werden. \n",
    "\n",
    "- **Eindimensionale CNNs sind also translationsinvariant (bei zeitlichen Verschiebungen)**.\n",
    "- Beispielsweise sollte ein eindimensionales CNN, das zur Verarbeitung einer Zeichensequenz ein Faltungsfenster der Grösse 5 verwendet, in einer Eingabesequenz 5 (oder weniger) Zeichen lange Wörter oder Wortfragmente erlernen können und in der Lage sein, diese Wörter in einem beliebigen Kontext wiederzuerkennen. \n",
    "- *Ein eindimensionales CNN zur Verarbeitung von Zeichen kann also die Form und Gestalt von Wörtern erlernen*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Eindimensionales Pooling sequenzieller Daten\n",
    "\n",
    "Zweidimensionale Pooling-Operationen wie `Mean`- und `Max`-Pooling, die von CNNs zum räumlichen Downsampling von Bildtensoren verwendet werden, sind Ihnen bereits bekannt. Zu den zweidimensionalen Operationen gibt es eindimensionale Pendants:\n",
    "- das Extrahieren von 1-D-Patches (Subsequenzen) aus einer Eingabe sowie Ausgabe des Maximalwerts (Max-Pooling) oder des Mittelwerts (Mean- oder Average-Pooling). Wie bei zweidimensionalen CNNs dienen diese Operationen dazu, die Länge der eindimensionalen Eingabe zu verringern (sogenanntes **Subsampling**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Klassifikation mit einer rekurrenten 1D-CNN-Architektur Sentiment Analysis der imdb-Filmkritiken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Projekt führen wir eine Sentiment-Analyse auf dem bekannten IMDb-Filmrezensionsdatensatz durch. Ziel ist es, automatisch zu klassifizieren, ob eine gegebene Filmkritik positiv oder negativ ist. Dafür verarbeiten wir reinen Text mit Hilfe eines einfachen Tokenizers, erstellen ein manuelles Word-to-Index-Vokabular, und wandeln die Texte in numerische Sequenzen um. Diese Sequenzen werden anschließend auf eine einheitliche Länge gebracht (Padding), um sie in ein neuronales Netz einspeisen zu können.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "In PyTorch können Sie für 1-D-CNNs den Conv1D-Layer einsetzen, der eine ähnliche Schnittstelle wie Conv2D besitzt. \n",
    "- Er nimmt einen **3-D-Tensor** mit der Shape `(samples, time, features)` als Eingabe entgegen und gibt Tensoren mit der gleichen Shape zurück. \n",
    "- Das Faltungsfenster ist ein 1-D-Fenster entlang der zeitlichen Achse: die Achse 1 des Eingabetensors.\n",
    "\n",
    "Wir erzeugen nun ein einfaches zweischichtiges CNN und klassifizieren damit die\n",
    "IMDb-Datensammlung. Zur Erinnerung hier der Code zum Einlesen und Vorbereiten\n",
    "der Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Download & Extraktion** (nur wenn nötig)\n",
    "2. **Laden der Daten** mit Labels & Tokenisierung\n",
    "3. **Sequenzumwandlung** mittels Wortindex\n",
    "4. **Padding der Sequenzen**\n",
    "5. **Ausgabe der Shapes** der Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "max_features = 10000\n",
    "max_len = 500\n",
    "data_dir = Path(\"data/aclImdb\")\n",
    "\n",
    "\n",
    "# Download & Extract IMDb Dataset\n",
    "def download_and_extract_imdb(destination: Path):\n",
    "    url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "    dest_file = destination.parent / \"aclImdb_v1.tar.gz\"\n",
    "    if not destination.exists():\n",
    "        print(\"Downloading IMDb dataset...\")\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(dest_file, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(\"Extracting...\")\n",
    "        with tarfile.open(dest_file, \"r:gz\") as tar:\n",
    "            tar.extractall(path=destination.parent)\n",
    "        print(\"Done!\")\n",
    "    else:\n",
    "        print(\"IMDb dataset already exists.\")\n",
    "\n",
    "\n",
    "# Tokenizer\n",
    "def simple_tokenizer(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z']\", \" \", text)\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "# IMDb Loader + Vocabulary\n",
    "def load_imdb_data(path: Path, num_words: int):\n",
    "    def load_texts_and_labels(subdir):\n",
    "        texts, labels = [], []\n",
    "        for label in [\"pos\", \"neg\"]:\n",
    "            folder = path / subdir / label\n",
    "            for file in sorted(folder.glob(\"*.txt\")):\n",
    "                texts.append(file.read_text(encoding=\"utf-8\"))\n",
    "                labels.append(1 if label == \"pos\" else 0)\n",
    "        return texts, labels\n",
    "\n",
    "    train_texts, train_labels = load_texts_and_labels(\"train\")\n",
    "    test_texts, test_labels = load_texts_and_labels(\"test\")\n",
    "\n",
    "    # Vokabular\n",
    "    all_tokens = [token for text in train_texts for token in simple_tokenizer(text)]\n",
    "    counter = Counter(all_tokens)\n",
    "    most_common = counter.most_common(num_words - 2)\n",
    "    word_index = {word: i + 2 for i, (word, _) in enumerate(most_common)}\n",
    "    word_index[\"<PAD>\"] = 0\n",
    "    word_index[\"<UNK>\"] = 1\n",
    "\n",
    "    def texts_to_sequences(texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            tokens = simple_tokenizer(text)\n",
    "            indices = [word_index.get(token, 1) for token in tokens]  # 1 = <UNK>\n",
    "            sequences.append(torch.tensor(indices, dtype=torch.long))\n",
    "        return sequences\n",
    "\n",
    "    x_train = texts_to_sequences(train_texts)\n",
    "    x_test = texts_to_sequences(test_texts)\n",
    "    y_train = torch.tensor(train_labels, dtype=torch.long)\n",
    "    y_test = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, word_index\n",
    "\n",
    "\n",
    "# Padding wie in Keras\n",
    "def pad_sequences_torch(sequences, maxlen):\n",
    "    padded = torch.zeros(len(sequences), maxlen, dtype=torch.long)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        if len(seq) > maxlen:\n",
    "            padded[i] = seq[:maxlen]\n",
    "        else:\n",
    "            padded[i, -len(seq) :] = seq  # rechtsbündig (post-padding)\n",
    "    return padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_extract_imdb(data_dir)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "x_train, y_train, x_test, y_test, word_index = load_imdb_data(data_dir, max_features)\n",
    "\n",
    "print(len(x_train), \"train sequences\")\n",
    "print(len(x_test), \"test sequences\")\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "x_train = pad_sequences_torch(x_train, max_len)\n",
    "x_test = pad_sequences_torch(x_test, max_len)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDBTextCNN – PyTorch Lightning Modul für Textklassifikation\n",
    "`IMDBTextCNN` ist ein einfaches, aber effektives Textklassifikationsmodell auf Basis eines 1D-CNN, implementiert mit PyTorch Lightning. Es nutzt eine Embedding-Schicht, eine 1D-Convolution, Adaptive Max-Pooling und eine vollverbundene Schicht mit Sigmoid-Ausgabe für binäre Sentiment-Analyse. Das Modell loggt Training- und Validierungsmetriken epochweise und verwendet den Adam-Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBTextCNN(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, vocab_size=10000, embed_dim=128, num_filters=64, kernel_size=5, lr=1e-3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.conv = nn.Conv1d(embed_dim, num_filters, kernel_size)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Linear(num_filters, 1)\n",
    "\n",
    "        # Zwischenspeicher für Aggregation pro Epoche\n",
    "        self.train_losses = []\n",
    "        self.train_accs = []\n",
    "        self.val_losses = []\n",
    "        self.val_accs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        return torch.sigmoid(self.fc(x)).squeeze(-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        acc = ((y_hat > 0.5) == y).float().mean()\n",
    "        self.train_losses.append(loss.detach())\n",
    "        self.train_accs.append(acc.detach())\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        mean_loss = torch.stack(self.train_losses).mean()\n",
    "        mean_acc = torch.stack(self.train_accs).mean()\n",
    "        self.log(\"train_loss\", mean_loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"train_acc\", mean_acc, prog_bar=True, on_epoch=True)\n",
    "        self.train_losses.clear()\n",
    "        self.train_accs.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        acc = ((y_hat > 0.5) == y).float().mean()\n",
    "        self.val_losses.append(loss.detach())\n",
    "        self.val_accs.append(acc.detach())\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        mean_loss = torch.stack(self.val_losses).mean()\n",
    "        mean_acc = torch.stack(self.val_accs).mean()\n",
    "        self.log(\"val_loss\", mean_loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc\", mean_acc, prog_bar=True, on_epoch=True)\n",
    "        self.val_losses.clear()\n",
    "        self.val_accs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IMDBDataModule` ist ein PyTorch Lightning DataModule, das Trainings- und Validierungsdaten kapselt. Es wandelt Eingabedaten (`x_train`, `y_train`, `x_val`, `y_val`) in `TensorDataset`s um und stellt über `train_dataloader()` und `val_dataloader()` die entsprechenden DataLoader bereit – inklusive Batch-Größe und Shuffling für das Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, x_train, y_train, x_val, y_val, batch_size=128):\n",
    "        super().__init__()\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_ds = TensorDataset(self.x_train, self.y_train)\n",
    "        self.val_ds = TensorDataset(self.x_val, self.y_val)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird das Training des `IMDBTextCNN`-Modells mit PyTorch Lightning gestartet:\n",
    "\n",
    "- `IMDBDataModule` bereitet die Trainings- und Testdaten vor.\n",
    "- `IMDBTextCNN` ist das zu trainierende Textklassifikationsmodell.\n",
    "- `CSVLogger` speichert Metriken wie Loss und Accuracy in CSV-Dateien unter `logs/imdb_textcnn/`.\n",
    "- `Trainer` führt das Training über 15 Epochen aus, wählt automatisch das passende Gerät (CPU/GPU).\n",
    "- `trainer.fit(...)` startet das eigentliche Training mit dem DataModule und dem Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = IMDBDataModule(x_train, y_train, x_test, y_test, batch_size=128)\n",
    "model = IMDBTextCNN(vocab_size=max_features)\n",
    "\n",
    "csv_logger = CSVLogger(\"logs\", name=\"imdb_textcnn\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    logger=csv_logger,\n",
    "    accelerator=\"auto\",\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Code lädt die Trainings-Logs des Modells aus der `metrics.csv`-Datei (erstellt vom `CSVLogger`) und visualisiert den **Verlauf des Trainings- und Validierungsverlusts (Loss) über die Epochen**:\n",
    "\n",
    "### Schritte im Überblick:\n",
    "\n",
    "1. **CSV-Datei laden**  \n",
    "   ```python\n",
    "   df = pd.read_csv(metrics_path)\n",
    "   ```\n",
    "   - Liest die während des Trainings gespeicherten Metriken ein.\n",
    "\n",
    "2. **Trainings- und Validierungsdaten filtern**  \n",
    "   ```python\n",
    "   train_df = df[df[\"train_loss\"].notna()]\n",
    "   val_df = df[df[\"val_loss\"].notna()]\n",
    "   ```\n",
    "   - Trennt Zeilen, in denen `train_loss` bzw. `val_loss` vorhanden sind.\n",
    "\n",
    "3. **Loss-Kurven plotten**  \n",
    "   ```python\n",
    "   plt.plot(...)\n",
    "   ```\n",
    "   - Zeichnet zwei Linienplots: eine für `train_loss`, eine für `val_loss`.\n",
    "   - Marker (`o` und `x`) sowie unterschiedliche Linienstile sorgen für bessere Lesbarkeit.\n",
    "   - Achsen, Titel, Legende und Grid werden ergänzt für eine saubere Visualisierung.\n",
    "\n",
    "### Ergebnis:\n",
    "Ein Plot, der zeigt, wie sich der Loss auf Trainings- und Validierungsdaten über die Epochen hinweg entwickelt – hilfreich zur Beurteilung von **Lernfortschritt**, **Overfitting** oder **Underfitting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_path = csv_logger.log_dir + \"/metrics.csv\"\n",
    "df = pd.read_csv(metrics_path)\n",
    "\n",
    "# Zeilen mit train_loss und val_loss extrahieren\n",
    "train_df = df[df[\"train_loss\"].notna()]\n",
    "val_df = df[df[\"val_loss\"].notna()]\n",
    "\n",
    "# Plotten\n",
    "plt.plot(\n",
    "    train_df[\"epoch\"],\n",
    "    train_df[\"train_loss\"],\n",
    "    label=\"Train Loss\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    ")\n",
    "plt.plot(\n",
    "    val_df[\"epoch\"], val_df[\"val_loss\"], label=\"Val Loss\", marker=\"x\", linestyle=\"--\"\n",
    ")\n",
    "plt.title(\"Loss Curve (1D-CNN on IMDb)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Regression mit rekurrenten 1D-CNN-Modellen: Zeitreihen-Vorhersage der Jena Wetterdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt wenden wir 1D-Convolutional Neural Networks (1D-CNNs) auf die Jena-Klimadaten an, um zukünftige Wetterwerte auf Basis historischer Messungen vorherzusagen. Die Idee dabei ist, zeitliche Muster in den Daten zu erkennen, ohne auf rekurrente Strukturen wie RNNs oder LSTMs zurückzugreifen.\n",
    "\n",
    "Ein 1D-CNN funktioniert hier als Feature-Extractor, der lokal zeitliche Abhängigkeiten in den Input-Sequenzen identifiziert – ähnlich wie ein CNN in der Bildverarbeitung lokale Muster erkennt. Durch den Einsatz mehrerer Faltungsschichten können auch komplexere Zusammenhänge über längere Zeitspannen modelliert werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes wird:\n",
    "1. CSV-Datei eingelesen und\n",
    "2. normalisiert (Standardisierung)\n",
    "### Ziel:\n",
    "- Sicherstellen, dass alle Eingabefeatures **vergleichbare Skalen** haben.\n",
    "- Verbessert Stabilität und Lernverhalten von neuronalen Netzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV einlesen\n",
    "df = pd.read_csv(\"data/jena_climate_2009_2016.csv\")\n",
    "float_data = df.iloc[:, 1:].values  # alle außer Zeitstempel\n",
    "\n",
    "# Normierung (wie in Keras)\n",
    "mean = float_data[:200000].mean(axis=0)\n",
    "float_data -= mean\n",
    "std = float_data[:200000].std(axis=0)\n",
    "float_data /= std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TimeseriesDataset` ist eine benutzerdefinierte PyTorch-Dataset-Klasse zur Vorbereitung von **Zeitreihendaten für Vorhersageaufgaben** (z. B. Temperaturprognose auf Basis vergangener Messwerte).\n",
    "\n",
    "### Was passiert?\n",
    "\n",
    "- Nutzt ein gleitendes Fenster über normalisierte Klimadaten.\n",
    "- Für jeden Datenpunkt wird ein **Input-Window (`lookback`)** erstellt.\n",
    "- Zielwert (`target`) ist die **Temperatur (`data[:, 1]`) nach `delay` Zeitschritten**.\n",
    "\n",
    "### Parameter:\n",
    "\n",
    "- `lookback`: Wie viele Zeitschritte in die Vergangenheit als Input dienen.\n",
    "- `delay`: Wie viele Zeitschritte in die Zukunft vorhergesagt werden sollen.\n",
    "- `step`: Intervall zwischen zwei Zeitpunkten im Input-Window.\n",
    "- `min_index`, `max_index`: Begrenzung des Datenbereichs (z. B. für Training/Validierung/Test).\n",
    "\n",
    "### Rückgabe:\n",
    "\n",
    "- Ein `sample`: Input-Zeitfenster (mehrere Merkmale über Zeit)\n",
    "- Ein `target`: Temperaturwert in der Zukunft\n",
    "\n",
    "Verwendbar mit einem `DataLoader` für effizientes Batch-Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeseriesDataset(Dataset):\n",
    "    def __init__(self, data, lookback, delay, min_index, max_index, step=6):\n",
    "        self.data = data\n",
    "        self.lookback = lookback\n",
    "        self.delay = delay\n",
    "        self.step = step\n",
    "        self.min_index = min_index + lookback\n",
    "        self.max_index = max_index if max_index is not None else len(data) - delay - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.max_index - self.min_index\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.min_index + idx\n",
    "        indices = range(i - self.lookback, i, self.step)\n",
    "        sample = self.data[indices]\n",
    "        target = self.data[i + self.delay][1]  # Temperatur (2. Spalte)\n",
    "        return torch.tensor(sample, dtype=torch.float32), torch.tensor(\n",
    "            target, dtype=torch.float32\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`JenaDataModule` ist ein **PyTorch Lightning DataModule** zur Organisation der Jena-Klimadaten für Zeitreihenmodelle.\n",
    "\n",
    "### Hauptfunktionen:\n",
    "\n",
    "- Teilt die normalisierten Daten (`float_data`) in:\n",
    "  - **Training** (0 – 200.000)\n",
    "  - **Validierung** (200.001 – 300.000)\n",
    "  - **Test** (ab 300.001)\n",
    "- Verwendet dabei das `TimeseriesDataset`, das Eingabefenster (`lookback`) und Zielwerte (`delay`) für Vorhersagen erstellt.\n",
    "\n",
    "### Parameter:\n",
    "\n",
    "- `lookback`: Anzahl vergangener Zeitschritte als Input\n",
    "- `delay`: Zielzeitpunkt in der Zukunft\n",
    "- `step`: Zeitintervall innerhalb des Inputfensters\n",
    "- `batch_size`: Größe der Trainings- und Test-Batches\n",
    "\n",
    "### Methoden:\n",
    "\n",
    "- `train_dataloader()`, `val_dataloader()`, `test_dataloader()` liefern passende DataLoader für den Trainingsprozess.\n",
    "\n",
    "Dieses Modul kapselt die gesamte **zeitliche Datenaufbereitung und Batch-Erstellung** – sauber und wiederverwendbar für Lightning-Modelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JenaDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, float_data, lookback=1440, delay=144, step=6, batch_size=128):\n",
    "        super().__init__()\n",
    "        self.float_data = float_data\n",
    "        self.lookback = lookback\n",
    "        self.delay = delay\n",
    "        self.step = step\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train = TimeseriesDataset(\n",
    "            self.float_data, self.lookback, self.delay, 0, 200000, self.step\n",
    "        )\n",
    "        self.val = TimeseriesDataset(\n",
    "            self.float_data, self.lookback, self.delay, 200001, 300000, self.step\n",
    "        )\n",
    "        self.test = TimeseriesDataset(\n",
    "            self.float_data, self.lookback, self.delay, 300001, None, self.step\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`JenaCNN` ist ein Modell zur Vorhersage zukünftiger Temperaturen auf Basis historischer Klimadaten. Es verwendet ein eindimensionales Convolutional Neural Network (1D-CNN), um zeitliche Muster in den Daten zu erkennen. Die Architektur besteht aus mehreren Faltungs- und Pooling-Schritten zur Merkmalextraktion und einer finalen Regressionsausgabe. Als Fehlerfunktion wird der mittlere absolute Fehler (MAE) verwendet. Das Modell nutzt RMSprop zur Optimierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JenaCNN(pl.LightningModule):\n",
    "    def __init__(self, num_features, lr=1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(num_features, 32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "            nn.Conv1d(32, 32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "            nn.Conv1d(32, 32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool1d(1),\n",
    "        )\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "        self.loss_fn = nn.L1Loss()  # MAE = Mean Absolute Error\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B, T, F) → (B, F, T)\n",
    "        x = self.model(x).squeeze(-1)  # (B, C, 1) → (B, C)\n",
    "        return self.fc(x).squeeze(-1)  # (B)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.RMSprop(self.parameters(), lr=self.hparams.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt wird das 1D-CNN-Modell `JenaCNN` mit dem vorbereiteten `JenaDataModule` trainiert. Das DataModule organisiert die Zeitreihendaten in Trainings-, Validierungs- und Testsets. Das Modell wird mit einem PyTorch Lightning `Trainer` für 10 Epochen trainiert, wobei alle Metriken über einen CSV-Logger gespeichert werden. Die Hardware (CPU/GPU) wird automatisch gewählt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataModule\n",
    "data = JenaDataModule(float_data)\n",
    "data.setup()\n",
    "\n",
    "# Modell\n",
    "num_features = float_data.shape[-1]\n",
    "model = JenaCNN(num_features=num_features)\n",
    "\n",
    "# Trainer\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=10, logger=CSVLogger(\"logs\", name=\"jena-cnn\"), accelerator=\"auto\"\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier werden wieder die Kurven geplottet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_path = trainer.logger.log_dir + \"/metrics.csv\"\n",
    "df = pd.read_csv(metrics_path)\n",
    "# Zeilen mit train_loss und val_loss extrahieren\n",
    "train_df = df[df[\"train_loss\"].notna()]\n",
    "val_df = df[df[\"val_loss\"].notna()]\n",
    "# Plotten\n",
    "plt.plot(\n",
    "    train_df[\"epoch\"],\n",
    "    train_df[\"train_loss\"],\n",
    "    label=\"Train Loss\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    ")\n",
    "plt.plot(\n",
    "    val_df[\"epoch\"], val_df[\"val_loss\"], label=\"Val Loss\", marker=\"x\", linestyle=\"--\"\n",
    ")\n",
    "plt.title(\"Loss Curve (1D-CNN on Jena)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`JenaCNNGRU` ist ein hybrides Modell zur Zeitreihenvorhersage, das **1D-CNNs** und eine **GRU** kombiniert. Die CNN-Schichten extrahieren lokale Muster aus den Eingabedaten, während die GRU die zeitlichen Abhängigkeiten verarbeitet. Das Modell gibt am Ende einen einzelnen Regressionswert (z. B. zukünftige Temperatur) aus. Es verwendet MAE als Loss und wird mit RMSprop optimiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JenaCNNGRU(pl.LightningModule):\n",
    "    def __init__(self, num_features, lr=1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Feature-Extraktion (lokale Muster)\n",
    "        self.conv1 = nn.Conv1d(num_features, 32, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5)\n",
    "\n",
    "        # Zeitliches Kontextverständnis\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=32,\n",
    "            hidden_size=32,\n",
    "            batch_first=True,\n",
    "            dropout=0.5,  # fester Wert wie in Keras\n",
    "        )\n",
    "\n",
    "        # Regressionsoutput\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "        # MAE = Mean Absolute Error\n",
    "        self.loss_fn = nn.L1Loss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Eingabe: (B, T, F)\n",
    "        x = x.permute(0, 2, 1)  # (B, F, T)\n",
    "        x = torch.relu(self.conv1(x))  # (B, 32, T')\n",
    "        x = self.pool1(x)  # (B, 32, T'')\n",
    "        x = torch.relu(self.conv2(x))  # (B, 32, T''')\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # (B, T, C) für GRU\n",
    "        out, _ = self.gru(x)  # (B, T, H)\n",
    "        last_hidden = out[:, -1, :]  # nur letztes Zeitschritt\n",
    "        return self.fc(last_hidden).squeeze(-1)  # (B,)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.RMSprop(self.parameters(), lr=self.hparams.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird das hybride Modell `JenaCNNGRU`, das CNNs und GRUs kombiniert, für 10 Epochen mit dem `JenaDataModule` trainiert. Der `Trainer` von PyTorch Lightning übernimmt das Training, speichert Metriken mit einem CSV-Logger und wählt automatisch die passende Hardware (CPU oder GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JenaCNNGRU(num_features=float_data.shape[-1])\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10, logger=CSVLogger(\"logs\", name=\"jena-cnn-gru\"), accelerator=\"auto\"\n",
    ")\n",
    "trainer.fit(model, datamodule=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_path = trainer.logger.log_dir + \"/metrics.csv\"\n",
    "df = pd.read_csv(metrics_path)\n",
    "# Filtere die Zeilen, in denen ein Wert für train_loss bzw. val_loss steht\n",
    "train = df[df[\"train_loss\"].notna()]\n",
    "val = df[df[\"val_loss\"].notna()]\n",
    "\n",
    "\n",
    "# Plotten\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(\n",
    "    train[\"epoch\"], train[\"train_loss\"], label=\"Train Loss\", marker=\"o\", linestyle=\"-\"\n",
    ")\n",
    "plt.plot(val[\"epoch\"], val[\"val_loss\"], label=\"Val Loss\", marker=\"x\", linestyle=\"--\")\n",
    "plt.title(\"Loss-Kurve: CNN + GRU (Jena-Klimadaten)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (MAE)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Where's the intelligence?\n",
    "\n",
    "- In welchen Situationen zeigen RNNs bessere Performance als 1D-CONV-Netze? \n",
    "- Wie könnte man CONV-Netze dahingehend verbessern?\n",
    "- Wie wird bei RNN das *vanishing gradients* Problem gelöst?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
