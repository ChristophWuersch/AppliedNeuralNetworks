{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/U12/ANN12_Denoising_Autoencoder_TEMPLATE_pl.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Denoising Autoencoder für MNIST-Ziffern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Einführung\n",
    "\n",
    "Dieses Beispiel zeigt, wie man einen tiefen Faltungs-Autoencoder für die Bildentrauschung implementiert, um aus verrauschten Ziffernbilder aus dem MNIST-Datensatz saubere Ziffernbilder zu erzeugen. Diese Implementierung basiert auf einem ursprünglichen Blogbeitrag mit dem Titel [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "von [François Chollet](https://twitter.com/fchollet).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import webbrowser\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Setup, Hilfsfunktionen für das Preprocessing\n",
    "### Hilfsfunktionen zur Datenvorbereitung, Visualisierung und Evaluation\n",
    "\n",
    "Dieser Abschnitt enthält unterstützende Funktionen zur Vorbereitung und Auswertung von Bilddaten, insbesondere für Denoising Autoencoder auf dem MNIST-Datensatz.\n",
    "\n",
    "##### `preprocess(array)`\n",
    "- **Zweck**: Normalisiert die Pixelwerte von Bildern auf den Bereich `[0, 1]` und formt sie in das Format `(Batch, Höhe, Breite, Kanäle)` um.\n",
    "- **Verwendung**: Wird auf Rohbilder angewendet, um sie für ein neuronales Netz vorzubereiten.\n",
    "- **Hinweis**: Das Kanalformat ist auf 1 (graustufige Bilder) gesetzt.\n",
    "\n",
    "##### `noise(array, noise_factor=0.4)`\n",
    "- **Zweck**: Fügt Gaußsches Rauschen zu den Bildern hinzu, um verrauschte Eingabedaten für den Denoising Autoencoder zu generieren.\n",
    "- **Parameter**:\n",
    "  - `noise_factor`: Stärke des hinzugefügten Rauschens.\n",
    "- **Rückgabe**: Bildarray mit Rauschen, begrenzt auf Werte zwischen `0.0` und `1.0`.\n",
    "\n",
    "##### `display_images(original, compared)`\n",
    "- **Zweck**: Visualisiert zufällig ausgewählte Originalbilder und die dazugehörigen Vergleichsbilder (z. B. verrauschte oder rekonstruierte Bilder).\n",
    "- **Darstellung**: Zeigt 10 Bildpaare in zwei Reihen – oben die Originalbilder, unten die Vergleichsbilder.\n",
    "\n",
    "##### `display_multiple_predictions(model, dataset, n_blocks=5, n_images=10)`\n",
    "- **Zweck**: Führt mehrere Vorhersageblöcke mit dem Denoising-Modell aus und zeigt die Ergebnisse.\n",
    "- **Ablauf**:\n",
    "  - Wählt zufällige Beispiele aus dem Dataset aus.\n",
    "  - Führt Vorwärtsdurchlauf durch das Modell aus.\n",
    "  - Visualisiert jeweils `n_images` verrauschte und rekonstruierte Bilder in mehreren Blöcken (`n_blocks`).\n",
    "- **Voraussetzung**: Das Dataset muss Paare `(noisy_image, clean_image)` zurückgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# (a) Hilfsfunktionen\n",
    "# ------------------------\n",
    "# Normalisierung und Umformung der Bilder\n",
    "def preprocess(array):\n",
    "    array = array.astype(\"float32\") / 255.0\n",
    "    array = np.reshape(array, (len(array), 28, 28, 1))\n",
    "    return array\n",
    "\n",
    "\n",
    "# Hinzufügen von Rauschen zum Bild (Gaussian Noise)\n",
    "def noise(array, noise_factor=0.4):\n",
    "    noisy_array = array + noise_factor * np.random.normal(0.0, 1.0, array.shape)\n",
    "    return np.clip(noisy_array, 0.0, 1.0)\n",
    "\n",
    "\n",
    "# Darstellung von Original- und Vergleichsbildern (z. B. noisy vs. recon)\n",
    "def display_images(original, compared):\n",
    "    n = 10\n",
    "    indices = np.random.randint(len(original), size=n)\n",
    "    original, compared = original[indices], compared[indices]\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 4))\n",
    "    fig.suptitle(\"Original vs. Vergleichsbilder\", fontsize=16)\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(original[i].reshape(28, 28), cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(\"Original\", fontsize=10)\n",
    "\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(compared[i].reshape(28, 28), cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(\"Vergleich\", fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Darstellung mehrerer zufälliger Vorhersageblöcke\n",
    "def display_multiple_predictions(model, dataset, n_blocks=5, n_images=10):\n",
    "    model.eval()\n",
    "    for block_idx in range(n_blocks):\n",
    "        idxs = np.random.choice(len(dataset), n_images, replace=False)\n",
    "        noisy = torch.stack([dataset[i][0] for i in idxs])\n",
    "        clean = torch.stack([dataset[i][1] for i in idxs])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            denoised = model(noisy)\n",
    "\n",
    "        fig = plt.figure(figsize=(20, 4))\n",
    "        fig.suptitle(f\"Vorhersageblock {block_idx + 1}\", fontsize=16)\n",
    "        display_images(\n",
    "            noisy.numpy().transpose(0, 2, 3, 1), denoised.numpy().transpose(0, 2, 3, 1)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Datenvorbereitung\n",
    "\n",
    "In diesem Abschnitt wird ein spezielles Dataset für den Denoising Autoencoder erstellt. Dabei werden verrauschte Versionen der MNIST-Bilder generiert und gemeinsam mit den sauberen Bildern verwendet.\n",
    "\n",
    "#### `NoisyMNIST` Dataset-Klasse\n",
    "- **Zweck**: Erstellt ein eigenes `Dataset`-Objekt mit verrauschten Eingabebildern und den dazugehörigen sauberen Zielbildern.\n",
    "- **Details**:\n",
    "  - Die MNIST-Daten werden geladen und als `numpy`-Array verarbeitet.\n",
    "  - Die Bilder werden mit der Funktion `preprocess()` normalisiert und umgeformt.\n",
    "  - Über `noise()` wird Gaußsches Rauschen hinzugefügt.\n",
    "- **`__getitem__`**:\n",
    "  - Gibt jeweils ein Paar `(noisy_image, clean_image)` im Format `(Kanäle, Höhe, Breite)` zurück – konvertiert zu PyTorch-Tensoren.\n",
    "\n",
    "#### DataLoader\n",
    "```python\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "```\n",
    "- Lädt die Daten in Batches von 128 Bildern.\n",
    "- Beim Training werden die Daten zufällig durchmischt (`shuffle=True`).\n",
    "\n",
    "#### Beispielbilder anzeigen\n",
    "```python\n",
    "examples = next(iter(train_loader))\n",
    "display_images(\n",
    "    examples[1].numpy().transpose(0, 2, 3, 1),  # Saubere Bilder (Ziel)\n",
    "    examples[0].numpy().transpose(0, 2, 3, 1),  # Verrauschte Bilder (Eingabe)\n",
    ")\n",
    "```\n",
    "- Zeigt 10 zufällig ausgewählte Bildpaare: **sauber (Original)** vs. **verrauscht (Input)**.\n",
    "- Die Darstellung dient der Überprüfung, ob das Rauschen korrekt hinzugefügt wurde und ob die Datenstruktur passt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# (b) Datenvorbereitung\n",
    "# ------------------------\n",
    "# Dataset mit verrauschten und sauberen Bildern\n",
    "class NoisyMNIST(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        data = MNIST(\"data\", train=train, download=True).data.numpy()\n",
    "        self.clean = preprocess(data)\n",
    "        self.noisy = noise(self.clean)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clean)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.noisy[idx], dtype=torch.float32).permute(2, 0, 1)\n",
    "        y = torch.tensor(self.clean[idx], dtype=torch.float32).permute(2, 0, 1)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# Laden der Trainings- und Testdaten\n",
    "train_dataset = NoisyMNIST(train=True)\n",
    "test_dataset = NoisyMNIST(train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "# Beispielbilder darstellen (clean vs. noisy)\n",
    "examples = next(iter(train_loader))\n",
    "display_images(\n",
    "    examples[1].numpy().transpose(0, 2, 3, 1), examples[0].numpy().transpose(0, 2, 3, 1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Aufbau des Autoencoders\n",
    "In diesem Abschnitt wird ein einfacher **Convolutional Autoencoder** mit PyTorch Lightning implementiert. Das Modell besteht aus einem **Encoder** zum Komprimieren und einem **Decoder** zum Rekonstruieren der Eingabebilder.\n",
    "\n",
    "#### `LitAutoEncoder` (LightningModule)\n",
    "Ein vollständig trainierbares Autoencoder-Modell mit Trainings- und Validierungsschritten.\n",
    "\n",
    "#### Encoder\n",
    "```python\n",
    "self.encoder = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(32, 32, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    ")\n",
    "```\n",
    "- **Ziel**: Komprimiert das Eingabebild durch zwei Faltungs- und Pooling-Stufen.\n",
    "- **Details**:\n",
    "  - `Conv2d`: Extrahiert Merkmale aus dem Bild.\n",
    "  - `MaxPool2d`: Halbiert jeweils die räumliche Auflösung.\n",
    "\n",
    "#### Decoder\n",
    "```python\n",
    "self.decoder = nn.Sequential(\n",
    "    nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 1, 3, padding=1),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "```\n",
    "- **Ziel**: Rekonstruiert das Bild schrittweise aus der komprimierten Darstellung.\n",
    "- **Details**:\n",
    "  - `ConvTranspose2d`: Führt Upsampling durch (umgekehrte Faltung).\n",
    "  - `Sigmoid`: Begrenzt die Ausgabewerte auf `[0, 1]` zur Bildrekonstruktion.\n",
    "\n",
    "#### `forward(x)`\n",
    "- Führt die Eingabe durch Encoder und Decoder.\n",
    "- Gibt das rekonstruierte Bild zurück.\n",
    "\n",
    "#### `training_step`\n",
    "```python\n",
    "loss = F.binary_cross_entropy(self(x), y)\n",
    "```\n",
    "- Führt einen Trainingsschritt mit **Binary Cross Entropy** zwischen Rekonstruktion und Zielbild durch.\n",
    "- Loggt den Trainingsverlust als `\"train_loss\"`.\n",
    "\n",
    "#### `validation_step`\n",
    "- Führt einen Validierungsschritt identisch zum Training aus.\n",
    "- Loggt den Validierungsverlust als `\"val_loss\"`.\n",
    "\n",
    "#### `configure_optimizers`\n",
    "```python\n",
    "return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "```\n",
    "- Verwendet den **Adam-Optimierer** mit Lernrate `1e-3` zur Optimierung aller Modellparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# (c) Autoencoder-Modell\n",
    "# ------------------------\n",
    "# Einfacher Conv-Autoencoder mit 2 Downsampling- und 2 Upsampling-Stufen\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "       #insert your code here\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "       #insert your code here\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #insert your code here\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        #insert your code here\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        #insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Training des Autoencoders\n",
    "In diesem Abschnitt wird das Autoencoder-Modell mit PyTorch Lightning trainiert. Dabei kommen **Early Stopping** und ein **TensorBoard Logger** zum Einsatz.\n",
    "\n",
    "#### Modellinitialisierung\n",
    "```python\n",
    "model = LitAutoEncoder()\n",
    "```\n",
    "- Erstellt eine Instanz des zuvor definierten Autoencoder-Modells.\n",
    "\n",
    "#### TensorBoard Logger\n",
    "```python\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"denoising_ae\")\n",
    "```\n",
    "- Speichert Trainingsmetriken zur Visualisierung mit TensorBoard.\n",
    "- Logs werden im Verzeichnis `tb_logs/denoising_ae/` abgelegt.\n",
    "\n",
    "#### Trainer-Konfiguration\n",
    "```python\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    logger=logger,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    callbacks=[EarlyStopping(monitor=\"train_loss\", patience=5)],\n",
    ")\n",
    "```\n",
    "- **`max_epochs=20`**: Training wird maximal 20 Epochen lang durchgeführt.\n",
    "- **`accelerator=\"auto\"`**: Automatische Auswahl von CPU oder GPU.\n",
    "- **`devices=1`**: Nutzt ein einzelnes Gerät (GPU oder CPU).\n",
    "- **`EarlyStopping`**: Bricht das Training frühzeitig ab, wenn sich der Trainingsverlust (`train_loss`) 5 Epochen lang nicht verbessert.\n",
    "\n",
    "#### Training starten\n",
    "```python\n",
    "trainer.fit(model, train_loader, test_loader)\n",
    "```\n",
    "- Startet das Training mit den definierten Trainings- und Test-Daten.\n",
    "- Das Test-Set wird hier als Validierungs-Set verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# (d) Training\n",
    "# ------------------------\n",
    "# Trainiere Modell mit EarlyStopping und TensorBoard-Logger\n",
    "model = LitAutoEncoder()\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"denoising_ae\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    logger=logger,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    callbacks=[EarlyStopping(monitor=\"train_loss\", patience=5)],\n",
    ")\n",
    "trainer.fit(model, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) Speichern des Modells\n",
    "Nach dem Training wird das Modell gespeichert, um es später erneut laden und verwenden zu können – z. B. für Inferenz oder Fine-Tuning.\n",
    "\n",
    "#### Speichern der Modellgewichte\n",
    "```python\n",
    "torch.save(model.state_dict(), \"AE_weights.pt\")\n",
    "```\n",
    "- Speichert die **gelernten Gewichte** des Modells in einer Datei namens `\"AE_weights.pt\"`.\n",
    "- Nur die **Gewichte** werden gespeichert, nicht die gesamte Modellstruktur.\n",
    "- Kann später mit `model.load_state_dict(torch.load(\"AE_weights.pt\"))` wieder geladen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# (e) Modell speichern\n",
    "# ------------------------\n",
    "# Speicher die gelernten Gewichte\n",
    "torch.save(model.state_dict(), \"AE_weights.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f) Lernkurven anzeigen\n",
    "In diesem Schritt wird **TensorBoard** gestartet, um das Training visuell auszuwerten – z. B. den Verlauf von Verlustfunktionen oder anderen Metriken.\n",
    "\n",
    "####  Starten von TensorBoard\n",
    "```python\n",
    "logdir = \"tb_logs/denoising_ae\"\n",
    "subprocess.Popen([\"tensorboard\", \"--logdir\", logdir])\n",
    "```\n",
    "- Startet einen TensorBoard-Server im Hintergrund.\n",
    "- Verwendet das zuvor definierte Logverzeichnis `\"tb_logs/denoising_ae\"`.\n",
    "\n",
    "#### Browser öffnen\n",
    "```python\n",
    "url = \"http://localhost:6006/\"\n",
    "time.sleep(2)\n",
    "webbrowser.open(url)\n",
    "```\n",
    "- Wartet 2 Sekunden, um sicherzustellen, dass TensorBoard gestartet ist.\n",
    "- Öffnet anschließend automatisch den Browser unter `http://localhost:6006/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# (f) TensorBoard anzeigen\n",
    "# ------------------------\n",
    "# Starte TensorBoard und öffne Browser zur Visualisierung\n",
    "logdir = \"tb_logs/denoising_ae\"\n",
    "url = \"http://localhost:6006/\"\n",
    "subprocess.Popen([\"tensorboard\", \"--logdir\", logdir])\n",
    "time.sleep(2)\n",
    "webbrowser.open(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (g) Vorhersagen machen (Rekonstruktion der Testdaten)\n",
    "In diesem letzten Schritt wird das trainierte Modell verwendet, um verrauschte **Testbilder** zu rekonstruieren. Anschließend werden Original vs. Rekonstruktion visualisiert.\n",
    "\n",
    "#### Modell in Evaluierungsmodus versetzen\n",
    "```python\n",
    "model.eval()\n",
    "```\n",
    "- Deaktiviert Dropout und BatchNorm.\n",
    "- Modell befindet sich jetzt im **Evaluierungsmodus** (wichtig für konsistente Vorhersagen).\n",
    "\n",
    "#### Vorhersage-Schleife über Testdaten\n",
    "```python\n",
    "preds = []\n",
    "for batch in test_loader:\n",
    "    x, _ = batch\n",
    "    with torch.no_grad():\n",
    "        preds.append(model(x))\n",
    "```\n",
    "- Geht alle Batches im Test-Loader durch.\n",
    "- Führt Vorhersagen im **no_grad**-Kontext aus (kein Gradiententracking → effizienter).\n",
    "- Ergebnisse werden in der Liste `preds` gesammelt.\n",
    "\n",
    "#### Zusammensetzen & Umwandeln der Vorhersagen\n",
    "```python\n",
    "pred_images = torch.cat(preds, dim=0).numpy().transpose(0, 2, 3, 1)\n",
    "```\n",
    "- Alle Batches werden zu einem großen Array zusammengesetzt.\n",
    "- Anschließend wird die Tensorform von `(Batch, Channels, Height, Width)` zu `(Batch, Height, Width, Channels)` konvertiert – für die Bildanzeige.\n",
    "\n",
    "#### Visualisierung: Noisy vs. Reconstructed\n",
    "```python\n",
    "display_images(test_dataset.noisy, pred_images)\n",
    "```\n",
    "- Zeigt eine Auswahl an verrauschten Testbildern (Input) und den rekonstruierten Bildern (Output des Autoencoders).\n",
    "- Ideal zur qualitativen Bewertung der Modellleistung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# (g) Test-Vorhersage\n",
    "# ------------------------\n",
    "# Rekonstruiere verrauschte Testbilder\n",
    "model.eval()\n",
    "preds = []\n",
    "for batch in test_loader:\n",
    "    x, _ = batch\n",
    "    with torch.no_grad():\n",
    "        preds.append(model(x))\n",
    "\n",
    "pred_images = torch.cat(preds, dim=0).numpy().transpose(0, 2, 3, 1)\n",
    "display_images(test_dataset.noisy, pred_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (h) Denoising mit dem Autoencoder (100 Epochen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# (h) Training mit 100 Epochen\n",
    "# ------------------------\n",
    "# Optional: längeres Training zur Verbesserung der Rekonstruktion\n",
    "model = LitAutoEncoder()\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    logger=logger,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    callbacks=[EarlyStopping(monitor=\"train_loss\", patience=5)],\n",
    ")\n",
    "trainer.fit(model, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (i) Rauschfiltertest (Denoising mit Testdaten)\n",
    "Dieser Schritt ist **optional** und dient dazu, die Qualität der Rekonstruktionen weiter zu verbessern, indem das Modell **länger trainiert** wird.\n",
    "\n",
    "#### Neues Modell initialisieren\n",
    "```python\n",
    "model = LitAutoEncoder()\n",
    "```\n",
    "- Erstellt ein neues Autoencoder-Modell.\n",
    "- Hinweis: Wenn du das bereits trainierte Modell weitertrainieren möchtest, kannst du alternativ die gespeicherten Gewichte laden.\n",
    "\n",
    "#### Trainer mit 100 Epochen konfigurieren\n",
    "```python\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    logger=logger,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    callbacks=[EarlyStopping(monitor=\"train_loss\", patience=5)],\n",
    ")\n",
    "```\n",
    "- **`max_epochs=100`**: Maximale Trainingsdauer beträgt 100 Epochen.\n",
    "- **`EarlyStopping`**: Training wird frühzeitig beendet, wenn sich der Trainingsverlust 5 Epochen lang nicht verbessert.\n",
    "- **`logger`**: TensorBoard Logger wird wiederverwendet (aus vorherigem Schritt).\n",
    "\n",
    "#### Training starten\n",
    "```python\n",
    "trainer.fit(model, train_loader, test_loader)\n",
    "```\n",
    "- Startet das verlängerte Training mit den gleichen Trainings- und Testdaten.\n",
    "- Ziel: Bessere Rekonstruktionen durch längeres Lernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# (i) Finaler Denoising-Test\n",
    "# ------------------------\n",
    "# Rekonstruiere komplette Testmenge und speichere das Bild\n",
    "model.eval()\n",
    "preds = []\n",
    "for batch in test_loader:\n",
    "    x, _ = batch\n",
    "    with torch.no_grad():\n",
    "        preds.append(model(x))\n",
    "\n",
    "pred_images = torch.cat(preds, dim=0).numpy().transpose(0, 2, 3, 1)\n",
    "display_images(test_dataset.noisy, pred_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (j) Mehrfach-Vorhersagen anzeigen (5 Bildblöcke)\n",
    "Dieser Schritt dient der **visuellen Evaluation des Modells** über mehrere zufällig ausgewählte Bildgruppen hinweg. So lassen sich unterschiedliche Rekonstruktionsbeispiele einfach vergleichen.\n",
    "\n",
    "#### Mehrfachanzeige von Vorhersageblöcken\n",
    "```python\n",
    "display_multiple_predictions(model, test_dataset, n_blocks=5)\n",
    "```\n",
    "- **Zweck**: Zeigt 5 verschiedene Vorhersageblöcke mit jeweils 10 Bildern.\n",
    "- Für jeden Block werden zufällig:\n",
    "  - **10 verrauschte Bilder (Input)** aus dem Testset ausgewählt\n",
    "  - die **rekonstruierten Bilder** mit dem Autoencoder erzeugt\n",
    "- Jedes Bildpaar (oben: noisy, unten: reconstructed) wird zur qualitativen Einschätzung dargestellt.\n",
    "- Besonders hilfreich, um die Modellleistung bei **verschiedenen Bildtypen** visuell zu analysieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# (j) Mehrfache Vorhersagen\n",
    "# ------------------------\n",
    "# Zeige 5 zufällige Blöcke an Vorhersagen\n",
    "display_multiple_predictions(model, test_dataset, n_blocks=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "autoencoder",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
