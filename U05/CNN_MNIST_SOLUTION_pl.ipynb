{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\"  align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/U05/CNN_MNIST_SOLUTION_pl.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faltungsnetzwerke\n",
    "\n",
    "Diese Übungsserie zeigt, wie man die sogenannte PyTorch Lightning API zum einfachen Aufbau von Convolutional Neural Networks in PyTorch verwendet. PyTorch Lightning ist eine High-Level-API für PyTorch, die den Trainingsprozess vereinfacht und strukturiert.\n",
    "\n",
    "Dieses Serie zeigt auch, wie man PyTorch Lightning benutzt, um ein Modell zu speichern und zu laden, und wie man die Gewichte und Ausgaben von Faltungsschichten erhält. PyTorch Lightning wird in Zukunft sehr wahrscheinlich die Standard-API für PyTorch sein. PyTorch Lightning ist bereits sehr gut und wird ständig verbessert. Es wird also empfohlen, PyTorch Lightning zu verwenden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flowchart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das folgende Diagramm zeigt grob, wie die Daten in dem unten implementierten neuronalen Faltungsnetzwerk fliessen. \n",
    "\n",
    "Es gibt zwei Faltungsschichten, jeweils gefolgt von einem Down-Sampling mit Max-Pooling (in diesem Flussdiagramm nicht dargestellt). Dann folgen zwei vollständig verbundene Schichten, die in einem Softmax-Klassifikator enden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Flowchart](Bilder/02_network_flowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Notebook vorbereiten und Daten Laden\n",
    "In diesem Code werden verschiedene Schritte durchgeführt\n",
    "1. Importieren von Bibliotheken\n",
    "2. Definition der Transformationen für den MNIST-Datensatz\n",
    "3. Laden des MNIST-Datensatzes\n",
    "4. Aufteilen des Trainingssatzes in Trainings- und Validierungssätze\n",
    "5. Erstellen der DataLoader\n",
    "6. Hilfsfunktion zur Visualisierung einiger Trainingsbilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports und Hilfsfunktionen\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Transformationsdefinition für MNIST\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),  # Konvertierung in Tensor\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),  # Normalisierung\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Laden des MNIST-Datensatzes\n",
    "mnist_full = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(\n",
    "    root=\"data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# Aufteilen des Trainingssatzes in Training und Validierung\n",
    "train_size = int(0.9 * len(mnist_full))\n",
    "val_size = len(mnist_full) - train_size\n",
    "mnist_train, mnist_val = random_split(mnist_full, [train_size, val_size])\n",
    "\n",
    "# Erstellen der DataLoader\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(\n",
    "    mnist_train, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    mnist_val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    mnist_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Hilfsfunktion zum Visualisieren einiger MNIST-Bilder\n",
    "def plot_mnist_samples(dataset, num_samples=6):\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(num_samples * 2, 2))\n",
    "    for i in range(num_samples):\n",
    "        image, label = dataset[i]\n",
    "        axes[i].imshow(image.squeeze(), cmap=\"gray\")\n",
    "        axes[i].set_title(str(label))\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Beispiel: Anzeigen einiger Trainingsbilder\n",
    "plot_mnist_samples(mnist_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Aufbau des CNN-Modells (Variante 1) mit PyTorch Lightning\n",
    "Dieser Code definiert eine Convolutional Neural Network (CNN) Klasse `LitCNN` mit Konstruktor, Forward Methode Training Step, Validation Step und Test Step. Es wird auch ein Optimierer definiert.\n",
    "\n",
    "- Netzwerkarchitektur:\n",
    "    - 2 Convolutional Layers mit Max-Pooling, um Merkmale aus den Bildern zu extrahieren.\n",
    "\t- 2 Fully Connected Layers, um die Klassifikation durchzuführen.\n",
    "- Trainingsprozess:\n",
    "\t- Loss: Cross-Entropy-Loss zur Klassifikation.\n",
    "\t- Optimizer: Adam-Optimizer zur Gewichtsaktualisierung.\n",
    "\t- Metrik: Genauigkeit (Accuracy) zur Bewertung.\n",
    "- LightningModule-Funktionen:\n",
    "\t- ``training_step()``: Berechnet Loss & Accuracy für das Training.\n",
    "\t- ``validation_step()``: Berechnet Loss & Accuracy für die Validierung.\n",
    "\t- ``test_step()``: Testet das Modell auf neuen Daten.\n",
    "\t- ``configure_optimizers()``: Definiert den Adam-Optimizer.\n",
    "\n",
    "Das Modell trainiert ein CNN für eine 10-Klassen-Klassifikation mit automatisiertem Training & Logging über PyTorch Lightning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCNN(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=1e-3):\n",
    "        super(LitCNN, self).__init__()\n",
    "        # Convolutional Layer 1: Input (1,28,28) -> Output (16,28,28)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2)  # Output (16,14,14)\n",
    "        # Convolutional Layer 2: Output (36,14,14)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=36, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2)  # Output (36,7,7)\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(36 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        self.learning_rate = learning_rate  # Lernrate\n",
    "        self.accuracy = Accuracy(\n",
    "            task=\"multiclass\", num_classes=10\n",
    "        )  # weil MNIST 10 Klassen hat\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, 1, 28, 28]\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)  # -> [batch, 16, 14, 14]\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)  # -> [batch, 36, 7, 7]\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)  # Cross-Entropy-Loss\n",
    "        preds = torch.argmax(logits, dim=1)  # Vorhersage\n",
    "        acc = self.accuracy(preds, y)  # Genauigkeit\n",
    "        self.log(\"train_loss\", loss)  # Logging\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)  # Logging\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)\n",
    "        return {\"preds\": preds, \"targets\": y}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # GPU   \n",
    "else:\n",
    "    device = \"cpu\" # CPU\n",
    "\n",
    "model = LitCNN().to(device)\n",
    "summary(model, (1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) Training des Modells (Variante 1)\n",
    "Hier wird das Modell ``LitCNN`` mit PyTorch Lightning trainiert und die Ergebnisse als CSV-Logs gespeichert.\n",
    "- Modellinstanzierung: ``LitCNN`` wird mit einer Lernrate von $0.001$ erstellt.\n",
    "- Logging: CSVLogger speichert Trainingsmetriken in ``logs/mnist_model/``.\n",
    "- Trainer-Erstellung:\n",
    "    - Maximal 5 Epochen ``(max_epochs=5)``\n",
    "    - Automatische Hardware-Auswahl ``(accelerator=\"auto\")``\n",
    "    - Ein Gerät nutzen (devices=1)\n",
    "    - Training starten: ``trainer.fit()`` trainiert das Modell mit ``train_loader`` & validiert es mit ``val_loader``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "# Instanziiere das Modell und trainiere es\n",
    "model = LitCNN(learning_rate=1e-3)\n",
    "\n",
    "# Erstelle den CSVLogger\n",
    "csv_logger = CSVLogger(\"logs\", name=\"mnist_model\")\n",
    "\n",
    "# Erstelle den Trainer (bei Bedarf automatisch die passende Hardware auswählen)\n",
    "trainer = pl.Trainer(max_epochs=5, accelerator=\"auto\", devices=1, logger=csv_logger)\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d) Evaluation des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste das Modell auf dem Testset\n",
    "test_results = trainer.test(model, test_loader)\n",
    "print(\"Test-Ergebnisse:\", test_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e) Vorhersage und Konfusionsmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne Vorhersagen und erstelle die Konfusionsmatrix\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x, y = batch\n",
    "        logits = model(x)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(y.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title(\"Konfusionsmatrix - Testdaten\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f) Visualisierung falsch klassifizierter Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_errors(model, dataloader, num_errors=6):\n",
    "    model.eval()\n",
    "    error_images = []\n",
    "    error_preds = []\n",
    "    error_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)  # Move batch to GPU\n",
    "\n",
    "            logits = model(x)\n",
    "            preds = torch.argmax(logits, dim=1) \n",
    "            # Indizes der falsch klassifizierten Bilder\n",
    "            incorrect = preds != y\n",
    "            if incorrect.sum() > 0:\n",
    "                error_images.append(x[incorrect].cpu())\n",
    "                error_preds.append(preds[incorrect].cpu())\n",
    "                error_targets.append(y[incorrect].cpu())\n",
    "            # Beenden, wenn genügend Fehler gesammelt wurden\n",
    "            if sum([img.shape[0] for img in error_images]) >= num_errors:\n",
    "                break\n",
    "\n",
    "    if error_images:\n",
    "        error_images = torch.cat(error_images, dim=0)[:num_errors]\n",
    "        error_preds = torch.cat(error_preds, dim=0)[:num_errors]\n",
    "        error_targets = torch.cat(error_targets, dim=0)[:num_errors]\n",
    "        fig, axes = plt.subplots(1, num_errors, figsize=(num_errors * 2, 2))\n",
    "        for i in range(num_errors):\n",
    "            axes[i].imshow(error_images[i].squeeze(), cmap=\"gray\")\n",
    "            axes[i].set_title(\n",
    "                f\"pred: {error_preds[i].item()}\\ntrue: {error_targets[i].item()}\"\n",
    "            )\n",
    "            axes[i].axis(\"off\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Keine falsch klassifizierten Beispiele gefunden.\")\n",
    "\n",
    "\n",
    "# Zeige einige falsch klassifizierte Bilder\n",
    "plot_example_errors(model, test_loader, num_errors=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# g) Erstellung eines zweiten Modells (Variante 2) mit RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCNN_RMSprop(LitCNN):\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.RMSprop(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "# Instanziiere das zweite Modell und trainiere es\n",
    "model2 = LitCNN_RMSprop(learning_rate=1e-3).to(device)\n",
    "\n",
    "summary(model2, (1, 28, 28))\n",
    "\n",
    "# Erstelle den CSVLogger\n",
    "csv_logger = CSVLogger(\"logs\", name=\"mnist_model_rmsprop\")\n",
    "\n",
    "# Erstelle den Trainer (bei Bedarf automatisch die passende Hardware auswählen)\n",
    "trainer = pl.Trainer(max_epochs=5, accelerator=\"auto\", devices=1, logger=csv_logger)\n",
    "trainer.fit(model2, train_loader, val_loader)\n",
    "\n",
    "# Evaluation des zweiten Modells\n",
    "test_results2 = trainer.test(model2, test_loader)\n",
    "print(\"Test-Ergebnisse (RMSprop):\", test_results2)\n",
    "\n",
    "# Erzeuge die Konfusionsmatrix für model2\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "model2.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x, y = batch\n",
    "        logits = model2(x)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(y.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title(\"Konfusionsmatrix - Testdaten (RMSprop)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h) Modell abspeichern und laden\n",
    "Dieser Code speichert ein trainiertes Modell und lädt es später in eine neue Instanz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern des Modells (model2)\n",
    "torch.save(model2.state_dict(), \"model2.pth\")\n",
    "# Lösche model2 aus dem Speicher\n",
    "del model2\n",
    "\n",
    "# Lade das Modell in eine neue Instanz (model3)\n",
    "model3 = LitCNN_RMSprop(learning_rate=1e-3)\n",
    "model3.load_state_dict(torch.load(\"model2.pth\"))\n",
    "model3.eval()\n",
    "print(\"Modell wurde erfolgreich geladen.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i) Visualisierung der Gewichte der Faltungskerne\n",
    "- Jeder 3×3-Filter entspricht einer Kanten- oder Mustererkennung.\n",
    "- Durch die Visualisierung kann man verstehen, welche Merkmale das Modell aus den Eingabebildern lernt.\n",
    "- Die Filter detektieren z. B. Kanten, Texturen oder Kontraste in den Eingabedaten.\n",
    "So kann überprüft werden, ob das Modell sinnvolle Merkmale aus den Bildern extrahiert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisiere die Filter des ersten Convolutional Layers\n",
    "weights = model.conv1.weight.data.cpu().numpy()  # Shape: [16, 1, 3, 3]\n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < weights.shape[0]:\n",
    "        ax.imshow(weights[i, 0, :, :], cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\"Gewichte der ersten Convolutional Layer\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# j) Visualisierung des Outputs einer Faltungsschicht\n",
    "Dieser Code zeigt, wie ein Bild durch das CNN verarbeitet wird und welche Merkmale die zweite Convolutional Layer erkennt.\n",
    "- Die Feature Maps zeigen aktivierte Bereiche, die bestimmte Muster im Bild repräsentieren.\n",
    "- Helle Bereiche in den Visualisierungen bedeuten starke Aktivierungen für bestimmte Filter.\n",
    "- Dies hilft bei der Analyse, ob das Modell sinnvolle Merkmale extrahiert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv2_output(model, x):\n",
    "    with torch.no_grad():\n",
    "        x = model.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = model.pool1(x)\n",
    "        x = model.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Wähle ein Beispielbild aus dem Testset\n",
    "sample, _ = next(iter(test_loader))\n",
    "conv2_output = get_conv2_output(model, sample[0:1].to(device))\n",
    "num_feature_maps = conv2_output.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature_maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "num_rows, num_cols = 6, 6  # Define the grid size\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 12))  # Adjust the figure size\n",
    "axes = axes.flatten()  # Flatten to iterate easily\n",
    "\n",
    "for i in range(min(num_feature_maps, num_rows * num_cols)):  # Avoid out-of-bounds errors\n",
    "    axes[i].imshow(conv2_output[0, i, :, :].cpu().numpy(), cmap=\"gray\")\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "# Hide unused subplots if there are fewer feature maps than grid spaces\n",
    "for i in range(num_feature_maps, num_rows * num_cols):\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Output der zweiten Convolutional Layer\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
