{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/U01/WoodsMammography-keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\" height=\"120\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2022 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "\n",
    "# Ein neuronales Netz zur Klassifizierung von Brustkrebs \n",
    "### (Woods Mammography Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Source: https://machinelearningmastery.com/develop-a-neural-network-for-woods-mammography-dataset/\n",
    "\n",
    "In dieser Übungsaufgabe erfahren Sie, wie Sie ein neuronales Mehrschicht-Perceptron-Netzwerkmodell für den Wood's Mammographie-Klassifizierungsdatensatz entwickeln.\n",
    "\n",
    "Nach erfolgreichem Abschluss dieser Übungsaufgabe werden Sie wissen:\n",
    "\n",
    "- Wie man den Wood's Mammography-Datensatz lädt und zusammenfasst und die Ergebnisse nutzt, um Vorschläge für die Datenaufbereitung und die zu verwendenden Modellkonfigurationen zu machen.\n",
    "- Wie man die Lerndynamik von einfachen MLP-Modellen auf dem Datensatz untersucht.\n",
    "- Wie man robuste Schätzungen der Modellleistung entwickelt, die Modellleistung abstimmt und Vorhersagen für neue Daten macht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross-validation of base model for the mammography dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## (a) Laden des Datensatzes\n",
    "\n",
    "Der Datensatz geht auf Kevin Woods et al. und die 1993 veröffentlichte Arbeit mit dem Titel [Comparative Evaluation Of Pattern Recognition Techniques For Detection Of Microcalcifications In Mammography](https://www.worldscientific.com/doi/abs/10.1142/S0218001493000698) zurück.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "#df = pd.read_csv('mammography.csv', header=None)\n",
    "df=pd.read_csv('https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/U01/mammography.csv', header=None)\n",
    "\n",
    "#infoFile='mammography.names'\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## (b) Plotten von Histogrammen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df.hist(bins=51,figsize=(16,9));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "- Es ist zu erkennen, dass die meisten Variablen vielleicht eine Exponentialverteilung haben, und vielleicht ist Variable 5 (die letzte Eingabevariable) normalverteilt mit einigen Ausreissern/fehlenden Werten.\n",
    "- Es könnte von Vorteil sein, eine *Potenztransformation* (`PowerTransformer`) auf jede Variable anzuwenden, um die Wahrscheinlichkeitsverteilung weniger schief zu machen, was die Leistung des Modells wahrscheinlich verbessern wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(10,10))   \n",
    "\n",
    "sns.heatmap(df.corr(),annot=True,linewidths=.5,cmap=\"YlGnBu\",square=True, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## (c) Aufteilen in Trainings- und Validierungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input and output columns\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "X, y = df.values[:, :-1], df.values[:, -1]\n",
    "# ensure all data are floating point values\n",
    "X = X.astype('float32')\n",
    "# encode strings to integer\n",
    "y = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the number of input features\n",
    "n_features = X.shape[1]\n",
    "print('Input Features: %i' % (n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## (d) Modell erstellen und kompilieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## (e) Modell trainieren und Lernkurven darstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, epochs=300, batch_size=32, verbose=0, \n",
    "                    validation_data=(X_test,y_test))\n",
    "# predict test set\n",
    "#yhat = model.predict_classes(X_test)\n",
    "yhat = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "# evaluate predictions\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curves\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.semilogy(history.history['loss'], label='train')\n",
    "plt.semilogy(history.history['val_loss'], label='val')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curves\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## (f) Robuste Model-Bewertung mit der k-fachen Kreuzvalidierung\n",
    "\n",
    "Das Verfahren der k-fachen Kreuzvalidierung kann eine zuverlässigere Schätzung der MLP-Leistung liefern, obwohl es sehr langsam sein kann.\n",
    "\n",
    "Dies liegt daran, dass $k$ Modelle angepasst und bewertet werden müssen. Dies ist kein Problem, wenn der Datensatz klein ist. \n",
    "Wir können die Klasse `StratifiedKFold` verwenden und jeden Fold manuell aufzählen, das Modell anpassen, es auswerten und dann am Ende des Verfahrens den Mittelwert der Auswertungsergebnisse angeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare cross validation\n",
    "kfold = StratifiedKFold(10)\n",
    "# enumerate splits\n",
    "scores = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_ix, test_ix in kfold.split(X, y):\n",
    "\t# split data\n",
    "\tX_train, X_test, y_train, y_test = X[train_ix], X[test_ix], y[train_ix], y[test_ix]\n",
    "\t# fit the model\n",
    "\tmodel.fit(X_train, y_train, epochs=300, batch_size=32, verbose=0)\n",
    "\t# predict test set\n",
    "\tyhat = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\t#yhat = model.predict_classes(X_test)\n",
    "\t# evaluate predictions\n",
    "\tscore = accuracy_score(y_test, yhat)\n",
    "\tprint('>%.3f' % score)\n",
    "\tscores.append(score)\n",
    "# summarize all scores\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Hinweis: Ihre Ergebnisse können aufgrund der stochastischen Natur des Algorithmus oder des Bewertungsverfahrens oder aufgrund von Unterschieden in der numerischen Präzision variieren. Führen Sie das Beispiel ein paar Mal aus und vergleichen Sie das durchschnittliche Ergebnis.\n",
    "\n",
    "In diesem Fall können wir sehen, dass das MLP-Modell eine mittlere Genauigkeit von etwa 98,7 Prozent erreicht, was unserer groben Schätzung aus dem vorherigen Abschnitt ziemlich nahe kommt.\n",
    "\n",
    "Dies bestätigt unsere Erwartung, dass die Basismodellkonfiguration für diesen Datensatz besser funktionieren könnte als ein naives Modell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## (h) Endgültiges Modell und Vorhersagen machen\n",
    "\n",
    "Sobald wir uns für eine Modellkonfiguration entschieden haben, können wir ein endgültiges Modell auf allen verfügbaren Daten trainieren und es verwenden, um Vorhersagen für neue Daten zu treffen.\n",
    "\n",
    "In diesem Fall verwenden wir das Modell mit Dropout und einer kleinen Losgröße als endgültiges Modell.\n",
    "\n",
    "Wir können die Daten vorbereiten und das Modell wie zuvor anpassen, allerdings mit dem gesamten Datensatz anstelle einer Trainingsuntermenge des Datensatzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a final model and make predictions on new data for the mammography dataset\n",
    "\n",
    "# define a row of new data\n",
    "row = [0.23001961,5.0725783,-0.27606055,0.83244412,-0.37786573,0.4803223]\n",
    "# make prediction\n",
    "yhat = model.predict_classes([row])\n",
    "# invert transform to get label for class\n",
    "yhat = le.inverse_transform(yhat)\n",
    "# report prediction\n",
    "print('Predicted: %s' % (yhat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ANN]",
   "language": "python",
   "name": "conda-env-ANN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
