{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\"  align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch, François Chollet </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik-neu/systemtechnik/ice-institut-fuer-computational-engineering\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/U07/ANN07_VGG16_SOLUTION_pl.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# für Ausführung auf Google Colab auskommentieren und installieren\n",
    "!pip install -q -r https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "import tarfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Knifey-Spoony-Datensatz herunterladen und vorbereiten\n",
    "\n",
    "In diesem Abschnitt laden wir den Knifey-Spoony-Datensatz (22 MB) herunter, falls dieser noch nicht lokal vorhanden ist.\n",
    "Anschliessend extrahieren wir das Archiv und kopieren die Bilder in eine Ordnerstruktur, die von PyTorchs `ImageFolder`-Klasse erwartet wird.\n",
    "\n",
    "Dabei wird pro Klasse (z. B. fork, knife, spoon) ein eigener Unterordner angelegt und ca. 70 % der Bilder werden\n",
    "für das Training und ca. 30 % für den Test genutzt. So erhält man eine saubere Trennung zwischen Trainings- und Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download_and_extract(\n",
    "    dataset_url=\"https://github.com/Hvass-Labs/knifey-spoony/raw/master/knifey-spoony.tar.gz\",\n",
    "    dest_dir=\"knifey_spoony\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Lädt den Knifey-Spoony-Datensatz herunter und extrahiert ihn,\n",
    "    falls das Zielverzeichnis noch nicht existiert.\n",
    "\n",
    "    Parameter:\n",
    "      - dataset_url: URL zum Herunterladen des Tar-Archivs.\n",
    "      - dest_dir: Zielordner, in dem der Datensatz gespeichert und extrahiert wird.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "        tar_path = os.path.join(dest_dir, \"knifey-spoony.tar.gz\")\n",
    "        print(\"Lade Knifey-Spoony-Datensatz herunter ...\")\n",
    "        urllib.request.urlretrieve(dataset_url, tar_path)\n",
    "        print(\"Extrahiere den Datensatz ...\")\n",
    "        with tarfile.open(tar_path, \"r:gz\") as tar_ref:\n",
    "            tar_ref.extractall(dest_dir)\n",
    "        # Lösche das heruntergeladene Archiv, um Speicherplatz zu sparen\n",
    "        os.remove(tar_path)\n",
    "        print(\"Datensatz heruntergeladen und extrahiert.\")\n",
    "    else:\n",
    "        print(\"Knifey-Spoony-Datensatz ist bereits vorhanden.\")\n",
    "\n",
    "\n",
    "def copy_files(\n",
    "    src_dir=\"knifey_spoony\",\n",
    "    train_dest=\"knifey/train\",\n",
    "    test_dest=\"knifey/test\",\n",
    "    train_ratio=0.7,\n",
    "):\n",
    "    \"\"\"\n",
    "    Kopiert die Bilder aus dem extrahierten Knifey-Spoony-Datensatz in eine Ordnerstruktur,\n",
    "    die von der PyTorch-Klasse ImageFolder erwartet wird.\n",
    "\n",
    "    Für jede Klasse wird ein Unterordner in den Zielverzeichnissen (train und test) erstellt.\n",
    "    Der Parameter train_ratio gibt an, wieviel Anteil der Bilder ins Training übernommen wird.\n",
    "\n",
    "    Parameter:\n",
    "      - src_dir: Quellordner mit den extrahierten Bilddateien, sortiert nach Klassen.\n",
    "      - train_dest: Zielordner für Trainingsbilder.\n",
    "      - test_dest: Zielordner für Testbilder.\n",
    "      - train_ratio: Anteil der Bilder, der fürs Training verwendet wird (z. B. 0.7 = 70%).\n",
    "    \"\"\"\n",
    "    # Erstelle die Zielverzeichnisse, falls sie noch nicht existieren\n",
    "    os.makedirs(train_dest, exist_ok=True)\n",
    "    os.makedirs(test_dest, exist_ok=True)\n",
    "\n",
    "    # Durchlaufe alle Unterordner (Klassen) im Quellordner\n",
    "    for cls in os.listdir(src_dir):\n",
    "        cls_path = os.path.join(src_dir, cls)\n",
    "        if os.path.isdir(cls_path):\n",
    "            # Erstelle für jede Klasse entsprechende Unterordner in den Trainings- und Testverzeichnissen\n",
    "            train_cls_dir = os.path.join(train_dest, cls)\n",
    "            test_cls_dir = os.path.join(test_dest, cls)\n",
    "            os.makedirs(train_cls_dir, exist_ok=True)\n",
    "            os.makedirs(test_cls_dir, exist_ok=True)\n",
    "\n",
    "            # Erstelle eine Liste aller Bilddateien (nur jpg, jpeg, png) in diesem Klassenordner\n",
    "            images = [\n",
    "                f\n",
    "                for f in os.listdir(cls_path)\n",
    "                if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "            ]\n",
    "            images = sorted(images)  # Sortieren für Reproduzierbarkeit\n",
    "            np.random.shuffle(\n",
    "                images\n",
    "            )  # Zufällige Reihenfolge zur Aufteilung in Training und Test\n",
    "            split_idx = int(len(images) * train_ratio)\n",
    "            train_images = images[:split_idx]\n",
    "            test_images = images[split_idx:]\n",
    "\n",
    "            # Kopiere die Trainingsbilder in den entsprechenden Ordner\n",
    "            for img in train_images:\n",
    "                src_file = os.path.join(cls_path, img)\n",
    "                dest_file = os.path.join(train_cls_dir, img)\n",
    "                if not os.path.exists(dest_file):\n",
    "                    shutil.copy(src_file, dest_file)\n",
    "            # Kopiere die Testbilder in den entsprechenden Ordner\n",
    "            for img in test_images:\n",
    "                src_file = os.path.join(cls_path, img)\n",
    "                dest_file = os.path.join(test_cls_dir, img)\n",
    "                if not os.path.exists(dest_file):\n",
    "                    shutil.copy(src_file, dest_file)\n",
    "            print(\n",
    "                f\"Kopierte {len(train_images)} Trainingsbilder und {len(test_images)} Testbilder für Klasse '{cls}'.\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"'{cls_path}' ist kein Verzeichnis und wird übersprungen.\")\n",
    "\n",
    "    print(\"Bilder in Trainings- und Testordner kopiert.\")\n",
    "\n",
    "\n",
    "# Führe den Download und die Extraktion aus (sofern noch nicht geschehen)\n",
    "maybe_download_and_extract()\n",
    "\n",
    "# Kopiere die Bilder in eine klare Train/Test-Ordnerstruktur\n",
    "copy_files()\n",
    "\n",
    "# Setze die Pfade für die DataLoader\n",
    "train_dir = \"knifey/train\"\n",
    "test_dir = \"knifey/test\"\n",
    "\n",
    "print(\"Trainingsverzeichnis:\", train_dir)\n",
    "print(\"Testverzeichnis:\", test_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b-c) Datenvorverarbeitung und DataLoader\n",
    "\n",
    "In diesem Schritt definieren wir zwei Transformations-Pipelines:\n",
    "\n",
    "1. **Training-Transformationen:**\n",
    "   - Grössenanpassung (Resize) auf 224x224 Pixel.\n",
    "   - RandomAffine: Wendet zufällige Rotationen, Translationen, Scherungen und Skalierungen an.\n",
    "   - Zufällige horizontale und vertikale Spiegelung (Flip) zur Erhöhung der Variabilität.\n",
    "   - Umwandlung in Tensoren und Normalisierung (gemäß ImageNet-Standards).\n",
    "\n",
    "2. **Test-Transformationen:**\n",
    "   - Nur Grössenanpassung, Umwandlung in Tensoren und Normalisierung – keine Augmentierung.\n",
    "\n",
    "Anschließend erstellen wir über ImageFolder die Trainings- und Test-Datasets\n",
    "und verpacken sie in DataLoader für die spätere Modellschulung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet-Standardnormalisierungswerte\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Transformations-Pipeline für das Training (inkl. Datenaugmentierung)\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),  # Passe die Bildgröße an\n",
    "        transforms.RandomAffine(\n",
    "            degrees=180,  # Zufällige Rotation bis zu 180°\n",
    "            translate=(0.1, 0.1),  # Zufällige Verschiebung (bis zu 10% der Bildgröße)\n",
    "            shear=10,  # Zufällige Scherung um 10 Grad\n",
    "            scale=(0.9, 1.5),  # Zufälliger Zoom zwischen 0.9 und 1.5\n",
    "        ),\n",
    "        transforms.RandomHorizontalFlip(),  # Zufälliges Spiegeln horizontal\n",
    "        transforms.RandomVerticalFlip(),  # Zufälliges Spiegeln vertikal\n",
    "        transforms.ToTensor(),  # Konvertiere das Bild zu einem Tensor\n",
    "        transforms.Normalize(\n",
    "            mean=imagenet_mean, std=imagenet_std\n",
    "        ),  # Normalisiere die Pixelwerte\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Transformations-Pipeline für den Test (ohne Augmentierung)\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),  # Passe die Bildgröße an\n",
    "        transforms.ToTensor(),  # Konvertiere das Bild zu einem Tensor\n",
    "        transforms.Normalize(\n",
    "            mean=imagenet_mean, std=imagenet_std\n",
    "        ),  # Normalisiere die Pixelwerte\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Erstelle die Datasets mit ImageFolder. Die Ordnerstruktur (train_dir und test_dir)\n",
    "# legt automatisch die Klassen anhand der Unterordner fest.\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transforms)\n",
    "\n",
    "# Erstelle DataLoader, um den Datensatz in Batches zu verarbeiten\n",
    "BATCH_SIZE = 20\n",
    "NUM_WORKERS = 4  # Passe die Anzahl der parallelen Prozesse ggf. an\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "# Ausgabe der Klassenbezeichnungen und der Anzahl der Klassen\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(\"Klassen:\", class_names)\n",
    "print(\"Anzahl der Klassen:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Berechnung der Klassengewichte\n",
    "\n",
    "Bei unausgeglichenen Datensätzen (unbalanced datasets) kann es hilfreich sein,\n",
    "der Verlustfunktion Klassengewichte mitzugeben, damit seltener vertretene Klassen\n",
    "stärker gewichtet werden.\n",
    "\n",
    "Hier berechnen wir die Klassengewichte mit `compute_class_weight` aus scikit‑learn,\n",
    "basierend auf der Verteilung der Labels im Trainingsdatensatz.\n",
    "Die Gewichte werden dann in einen Torch-Tensor umgewandelt und später in den Loss integriert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sammle alle Labels aus dem Trainingsdatensatz\n",
    "train_labels = [s[1] for s in train_dataset.samples]\n",
    "# Berechne die Klassengewichte (balanced mode passt die Gewichte automatisch an)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=np.unique(train_labels), y=train_labels\n",
    ")\n",
    "print(\"Klassengewichte:\", class_weights)\n",
    "# Konvertiere die Gewichte in einen Torch-Tensor\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) Definition des Modells mit lightning\n",
    "\n",
    "Wir verwenden ein vortrainiertes VGG16-Modell als Feature-Extractor.\n",
    "Dabei entfernen wir den originalen Klassifikator und fügen einen neuen, eigenen\n",
    "Klassifikator hinzu, bestehend aus:\n",
    "\n",
    "- Flatten: Um die 3D-Feature-Maps in einen 1D-Vektor umzuwandeln.\n",
    "- Einem Linear-Layer mit ReLU-Aktivierung und Dropout (zur Regularisierung).\n",
    "- Einem finalen Linear-Layer, der direkt die Klassenvorhersagen liefert.\n",
    "\n",
    "Beim Transfer Learning bleiben zunächst alle Parameter des Feature-Extractors eingefroren.\n",
    "Beim Fine-Tuning (wenn ``fine_tuning=True``) werden einige der tieferen Schichten wieder trainierbar gemacht.\n",
    "\n",
    "Das LightningModule implementiert zudem die Trainings-, Validierungs- und Testschritte,\n",
    "sowie die Konfiguration des Optimierers (hier Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16TransferLearning(L.LightningModule):\n",
    "    def __init__(self, num_classes, lr=1e-5, class_weights=None, fine_tuning=False):\n",
    "        \"\"\"\n",
    "        Initialisiert das Transfer Learning-Modell basierend auf VGG16.\n",
    "\n",
    "        Parameter:\n",
    "          - num_classes (int): Anzahl der zu klassifizierenden Klassen.\n",
    "          - lr (float): Lernrate.\n",
    "          - class_weights (Tensor): Klassengewichte, um unbalancierte Klassen zu kompensieren.\n",
    "          - fine_tuning (bool): Falls True, werden tiefer liegende Schichten für ein Fine-Tuning freigegeben.\n",
    "        \"\"\"\n",
    "        super(VGG16TransferLearning, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.fine_tuning = fine_tuning\n",
    "\n",
    "        # Lade das vortrainierte VGG16-Modell aus torchvision\n",
    "        vgg16 = models.vgg16(pretrained=True)\n",
    "        # Extrahiere nur den Feature-Extractor (ohne den originalen Klassifikator)\n",
    "        self.features = vgg16.features\n",
    "        # print(self.features)\n",
    "\n",
    "        # Beim Transfer Learning frieren wir die Parameter des Feature-Extractors ein,\n",
    "        # sodass nur der neue Klassifikator trainiert wird.\n",
    "        if not self.fine_tuning:\n",
    "            for param in self.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            # Wenn Fine-Tuning gewünscht ist, frieren wir nur die ersten 24 Schichten ein.\n",
    "            for i, layer in enumerate(self.features):\n",
    "                if i < 28:\n",
    "                    for param in layer.parameters():\n",
    "                        param.requires_grad = False\n",
    "                else:\n",
    "                    for param in layer.parameters():\n",
    "                        param.requires_grad = True\n",
    "\n",
    "        # Nach der Extraktion liefern VGG16 bei 224x224 eine Feature-Map von Dimension 512 x 7 x 7.\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                512 * 7 * 7, 1024\n",
    "            ),  # Reduziert die Dimension und leitet sie an den nächsten Layer weiter\n",
    "            nn.ReLU(),  # Aktivierungsfunktion\n",
    "            nn.Dropout(0.5),  # Dropout zur Vermeidung von Overfitting\n",
    "            nn.Linear(\n",
    "                1024, self.num_classes\n",
    "            ),  # Finaler Linear-Layer, der die Klassenvorhersagen liefert\n",
    "        )\n",
    "\n",
    "        # Wähle die Loss-Funktion (CrossEntropyLoss) und integriere ggf. die Klassengewichte\n",
    "        if class_weights is not None:\n",
    "            self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        else:\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Vorwärtsdurchlauf: Zuerst den Feature-Extractor anwenden, dann flatten und Klassifikator\n",
    "        x = self.features(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Ein Trainingsschritt: Berechne den Loss und die Genauigkeit (Accuracy)\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        # Logge die Metriken\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Ein Validierungsschritt: Berechne Loss und Accuracy und sammle Vorhersagen für die spätere Auswertung\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        return {\"val_loss\": loss, \"val_acc\": acc, \"preds\": preds, \"targets\": y}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Ein Testschritt, ähnlich wie bei der Validierung, um die Leistung auf dem Testdatensatz zu evaluieren\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)\n",
    "        return {\"test_loss\": loss, \"test_acc\": acc, \"preds\": preds, \"targets\": y}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Verwende den Adam-Optimierer für das Training\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![VGG16](https://storage.googleapis.com/lds-media/images/transfer-learning-fine-tuning-approach.width-1200.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f) Training – Phase 1 (Transfer Learning)\n",
    "\n",
    "In dieser Trainingsphase bleibt der Feature-Extractor eingefroren, und es wird nur\n",
    "der neue Klassifikator (die letzten Schichten) trainiert. Hier nutzen wir eine relativ\n",
    "hohe Lernrate (1e-5), da nur wenige Parameter aktualisiert werden.\n",
    "\n",
    "Ein TensorBoard-Logger wird eingerichtet, um während des Trainings Metriken zu überwachen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Richte den TensorBoard Logger ein, um das Training zu protokollieren\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"vgg16_transfer_learning\")\n",
    "\n",
    "# Initialisiere das Modell für Transfer Learning (ohne Fine-Tuning)\n",
    "model_transfer = VGG16TransferLearning(\n",
    "    num_classes=num_classes,\n",
    "    lr=1e-5,\n",
    "    class_weights=class_weights_tensor,\n",
    "    fine_tuning=False,\n",
    ")\n",
    "\n",
    "# Konfiguriere den Trainer von lightning\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    log_every_n_steps=10,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Starte das Training und validiere gleichzeitig mit dem Test-Dataloader\n",
    "trainer.fit(model_transfer, train_loader, test_loader)\n",
    "# Teste das Modell nach dem Training\n",
    "trainer.test(model_transfer, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (g) Evaluation und Visualisierung\n",
    "\n",
    "Nach dem Training wollen wir die Leistung unseres Modells besser verstehen.\n",
    "Hierzu berechnen wir die Konfusionsmatrix, die zeigt, wie oft Bilder einer Klasse\n",
    "fälschlicherweise einer anderen zugeordnet wurden.\n",
    "\n",
    "Dazu definieren wir:\n",
    "- Eine Funktion `plot_confusion_matrix`, die die Matrix visualisiert.\n",
    "- Eine Funktion `get_predictions`, die alle Vorhersagen und tatsächlichen Labels sammelt.\n",
    "\n",
    "Abschließend plotten wir die normalisierte Konfusionsmatrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    cm, classes, normalize=False, title=\"Confusionsmatrix\", cmap=plt.cm.Blues\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualisiert die Konfusionsmatrix.\n",
    "\n",
    "    Parameter:\n",
    "      - cm: Die Konfusionsmatrix.\n",
    "      - classes: Liste der Klassennamen.\n",
    "      - normalize: Falls True, werden die Werte normiert (Prozentsatz pro Klasse).\n",
    "      - title: Titel des Plots.\n",
    "      - cmap: Farbschema für den Plot.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.0\n",
    "    # Beschrifte jede Zelle der Matrix\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "    plt.ylabel(\"Tatsächliche Klasse\")\n",
    "    plt.xlabel(\"Vorhergesagte Klasse\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_predictions(model, dataloader):\n",
    "    \"\"\"\n",
    "    Holt die Vorhersagen und die tatsächlichen Labels für alle Daten aus dem Dataloader.\n",
    "\n",
    "    Parameter:\n",
    "      - model: Das trainierte Modell.\n",
    "      - dataloader: Der DataLoader, von dem die Daten geladen werden.\n",
    "\n",
    "    Rückgabe:\n",
    "      - all_preds: Array der Vorhersagen.\n",
    "      - all_targets: Array der tatsächlichen Labels.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            # Stelle sicher, dass die Daten auf demselben Gerät wie das Modell liegen\n",
    "            x = x.to(model.device) if hasattr(model, \"device\") else x\n",
    "            logits = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_targets.append(y.cpu().numpy())\n",
    "    return np.concatenate(all_preds), np.concatenate(all_targets)\n",
    "\n",
    "\n",
    "# Hole alle Vorhersagen und tatsächlichen Labels für den Testdatensatz\n",
    "preds, targets = get_predictions(model_transfer, test_loader)\n",
    "# Berechne die Konfusionsmatrix\n",
    "cm = confusion_matrix(targets, preds)\n",
    "# Visualisiere die normalisierte Konfusionsmatrix\n",
    "plot_confusion_matrix(cm, classes=class_names, normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (h) Training – Phase 2 (Fine-Tuning)\n",
    "\n",
    "Nachdem der neue Klassifikator im Transfer-Learning-Ansatz trainiert wurde,\n",
    "möchten wir nun auch Teile des Feature-Extractors weiter anpassen.\n",
    "\n",
    "Beim Fine-Tuning werden ab Layer-Index 24 die Parameter freigegeben, sodass auch\n",
    "der Feature-Extractor weiter optimiert wird. Da hier wesentlich mehr Parameter\n",
    "trainiert werden, wird eine deutlich niedrigere Lernrate (hier 1e-6) verwendet, um\n",
    "Überanpassung (Overfitting) zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisiere das Modell für das Fine-Tuning (teilweise freigegebene Schichten)\n",
    "model_finetune = VGG16TransferLearning(\n",
    "    num_classes=num_classes,\n",
    "    lr=1e-5,  # Geringere Lernrate für das Fine-Tuning\n",
    "    class_weights=class_weights_tensor,\n",
    "    fine_tuning=True,\n",
    ")\n",
    "\n",
    "# Konfiguriere einen weiteren Trainer für das Fine-Tuning\n",
    "trainer_finetune = L.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    log_every_n_steps=10,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Starte das Fine-Tuning\n",
    "trainer_finetune.fit(model_finetune, train_loader, test_loader)\n",
    "# Teste das feinabgestimmte Modell\n",
    "trainer_finetune.test(model_finetune, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hole alle Vorhersagen und tatsächlichen Labels für den Testdatensatz\n",
    "preds_finetune, targets_finetune = get_predictions(model_finetune, test_loader)\n",
    "# Berechne die Konfusionsmatrix\n",
    "cm_finetune = confusion_matrix(targets, preds)\n",
    "# Visualisiere die normalisierte Konfusionsmatrix\n",
    "plot_confusion_matrix(cm_finetune, classes=class_names, normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "In diesem Notebook haben wir:\n",
    "\n",
    "- Den Knifey-Spoony-Datensatz heruntergeladen, extrahiert und in eine übersichtliche\n",
    "  Train/Test-Ordnerstruktur kopiert.\n",
    "- Datenvorverarbeitung und Augmentierung definiert und die Daten über ImageFolder in\n",
    "  DataLoader verpackt.\n",
    "- Ein vortrainiertes VGG16-Modell als Feature-Extractor genutzt und einen neuen Klassifikator\n",
    "  aufgebaut.\n",
    "- Zuerst Transfer Learning (eingefrorener Feature-Extractor) und anschließend Fine-Tuning\n",
    "  (teilweise freigegebene Schichten) durchgeführt.\n",
    "- Trainings-, Validierungs- und Testschritte in einem LightningModule implementiert.\n",
    "- Eine Evaluation mittels einer Konfusionsmatrix durchgeführt, um die Klassifizierungsleistung\n",
    "  zu beurteilen.\n",
    "\n",
    "Du kannst den Code weiter an Deine Anforderungen anpassen, z. B. indem Du andere Modelle oder\n",
    "Hyperparameter ausprobierst."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
