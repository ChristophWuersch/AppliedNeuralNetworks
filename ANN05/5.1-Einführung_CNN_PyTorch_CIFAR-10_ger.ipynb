{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> ¬© Christoph W√ºrsch, Fran√ßois Chollet </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN05/5.1-Einf√ºhrung_CNN_PyTorch_CIFAR-10_ger.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Der Aufbau eines neuronalen Faltungsnetzwerks (Convolutional Neural Network, CNN) mit PyTorch umfasst mehrere Schritte, darunter die Definition der Architektur des Netzwerks, die Vorbereitung der Daten, das Training des Modells und die Bewertung seiner Leistung. In diesem Artikel werden wir sehen, wie wir ein CNN-Netzwerk in PyTorch aufbauen k√∂nnen.\n",
    "\n",
    "Inhalts√ºbersicht\n",
    "\n",
    "Was sind Faltungsneuronale Netze?\n",
    "Code-Implementierung f√ºr den Aufbau eines neuronalen Faltungsnetzwerks in PyTorch\n",
    "* Schritt 1: Importieren der erforderlichen Bibliotheken\n",
    "* Schritt 2: Vorbereiten des Datensatzes\n",
    "* Schritt 3: Definieren der CNN-Architektur\n",
    "* Schritt 4: Definieren der Verlustfunktion und des Optimierers\n",
    "* Schritt 5: Trainieren des Netzwerks\n",
    "* Schritt 6: Testen des Netzwerks\n",
    "\n",
    "Vollst√§ndiger Code zum Aufbau eines CNN mit PyTorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was sind Faltungsneuronale Netze?\n",
    "\n",
    "Faltungsneuronale Netze (Convolutional Neural Networks, CNN) sind eine Klasse von tiefen neuronalen Netzen, die haupts√§chlich f√ºr die Analyse visueller Bilder verwendet werden. Sie bestehen aus mehreren Schichten, darunter Faltungsschichten, Pooling-Schichten und vollst√§ndig verbundene Schichten. CNNs sind darauf ausgelegt, automatisch und adaptiv r√§umliche Hierarchien von Merkmalen aus Eingabebildern zu lernen. Hier sind einige Komponenten von CNN.\n",
    "\n",
    "- *Faltungsschichten*: Diese Schichten wenden Faltungsoperationen auf die Eingabe an und extrahieren effektiv Merkmale wie Kanten, Texturen und Muster.\n",
    "- *Pooling-Schichten*: Pooling-Schichten reduzieren die r√§umlichen Dimensionen des Inputs durch Downsampling und helfen so, die Rechenkomplexit√§t zu verringern und die √úberanpassung zu kontrollieren.\n",
    "- *Aktivierungsfunktionen*: Aktivierungsfunktionen wie ReLU (Rectified Linear Unit) f√ºhren Nichtlinearit√§t in das Netz ein, so dass es komplexe Beziehungen lernen kann.\n",
    "- *Vollst√§ndig verbundene Schichten*: Diese auch als dichte Schichten bezeichneten Schichten f√ºhren eine Klassifizierung auf der Grundlage der von den vorherigen Schichten extrahierten Merkmale durch.\n",
    "- *Verlustfunktion*: Die Verlustfunktion misst die Differenz zwischen der vorhergesagten Ausgabe des Netzes und der Grundwahrheit und steuert den Lernprozess des Netzes.\n",
    "- *Optimierungsalgorithmus*: Algorithmen wie Stochastic Gradient Descent (SGD), Adam oder RMSprop werden verwendet, um die Parameter des Netzes durch Minimierung der Verlustfunktion zu optimieren.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementierung des Aufbaus eines neuronalen Faltungsnetzes in PyTorch\n",
    "\n",
    "### Schritt 1: Importieren der notwendigen Bibliotheken\n",
    "In diesem Python-Codeblock importieren wir wichtige Module aus der PyTorch-Bibliothek, einem beliebten Open-Source-Framework f√ºr maschinelles Lernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f√ºr Ausf√ºhrung auf Google Colab auskommentieren und installieren\n",
    "%pip install -q -r https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/main/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tain on the GPU, we use CUDA 12.4\n",
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "\n",
    "# Select device: CUDA if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 2: Vorbereiten des Datensatzes\n",
    "\n",
    "- Dieser Code bereitet den CIFAR-10-Datensatz f√ºr das Training und Testen eines neuronalen Netzes mit PyTorch vor.\n",
    "- Er definiert eine Reihe von Bildtransformationen, einschlie√ülich der Umwandlung von Bildern in PyTorch-Tensoren und deren Normalisierung. Anschlie√üend werden Datensatzobjekte f√ºr die Trainings- und Testdatens√§tze von CIFAR-10 erstellt, wobei das Stammverzeichnis, die Angabe, dass es sich um einen Trainings- oder Testdatensatz handelt, und die Transformationssequenz angegeben werden.\n",
    "- Als N√§chstes werden Datenlader f√ºr beide Datens√§tze erstellt, die das Laden der Daten in Stapeln, das Mischen der Daten und die Verwendung mehrerer Prozesse f√ºr ein schnelleres Laden der Daten erm√∂glichen.\n",
    "- Schlie√ülich werden die Klassenbezeichnungen f√ºr CIFAR-10 definiert, die die 10 verschiedenen Objektklassen im Datensatz repr√§sentieren. \n",
    "- Insgesamt bereitet dieser Code den CIFAR-10-Datensatz f√ºr die Verwendung beim Training und bei der Evaluierung neuronaler Netzmodelle vor.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    \"\"\"Helper function to unnormalize and return an image for plotting.\"\"\"\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    return np.transpose(npimg, (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "\n",
    "\n",
    "def plot_batch(dataloader, classes, batch_size=4):\n",
    "    \"\"\"\n",
    "    Plots a batch of images from the given dataloader in a single figure.\n",
    "\n",
    "    Args:\n",
    "        dataloader: PyTorch dataloader for CIFAR-10 dataset.\n",
    "        classes: Tuple of class names in CIFAR-10.\n",
    "        batch_size: Number of images to display in the batch.\n",
    "    \"\"\"\n",
    "    # Get one batch of images and labels\n",
    "    data_iter = iter(dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(1, batch_size, figsize=(batch_size * 3, 3))\n",
    "    for i in range(batch_size):\n",
    "        img = imshow(images[i])  # Unnormalize and prepare the image\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(classes[labels[i]])\n",
    "        axes[i].axis(\"off\")  # Hide axes\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to avoid overlapping\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage with the CIFAR-10 trainloader\n",
    "plot_batch(trainloader, classes, batch_size=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Schritt 3: Definieren der CNN-Architektur\n",
    "- Dieser Code definiert eine neuronale Netzwerkarchitektur unter Verwendung der `nn.Module`-Klasse von PyTorch. Die Klasse Net erbt von nn.Module und definiert die Schichten des Netzwerks in ihrer `__init__`-Methode.\n",
    "- Es hat zwei Faltungsschichten (conv1 und conv2) mit ReLU-Aktivierungsfunktionen, gefolgt von Max-Pooling-Schichten (`pool`). Die vollst√§ndig verbundenen Schichten (`fc1`, `fc2` und `fc3`) verarbeiten die Ausgabe der Faltungsschichten.\n",
    "- Die Vorw√§rtsmethode `forward` definiert den Vorw√§rtsdurchlauf des Netzes, bei dem die Eingabe `x` nacheinander durch jede Schicht geleitet wird. Die view-Methode formt die Ausgabe der zweiten Faltungsschicht so um, dass sie mit den vollverkn√ºpften Schichten kompatibel ist. Schlie√ülich wird eine Instanz der Klasse Net erstellt, die das Modell des neuronalen Netzes darstellt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "#!pip install torchsummary torchviz\n",
    "\n",
    "# Import required libraries\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Summarize the model\n",
    "summary(\n",
    "    net, input_size=(3, 32, 32), device=\"cpu\"\n",
    ")  # Adjust input_size as per your model's requirement\n",
    "\n",
    "# Visualize the model architecture\n",
    "x = torch.randn(1, 3, 32, 32)  # Adjust input size as per your model's requirement\n",
    "y = net(x)\n",
    "make_dot(y, params=dict(net.named_parameters())).render(\"model_architecture_CIFAR\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "# Load and display the image\n",
    "image = Image.open(\"model_architecture_CIFAR.png\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 4: Definieren Sie Verlustfunktion und Optimierer\n",
    "- In diesem Code wird nn.CrossEntropyLoss() als Verlustfunktion (Kriterium) f√ºr das Training des neuronalen Netzes verwendet.\n",
    "- CrossEntropyLoss\" wird √ºblicherweise f√ºr Klassifizierungsaufgaben verwendet und berechnet den Verlust zwischen den vorhergesagten Klassenwahrscheinlichkeiten und den tats√§chlichen Klassenbezeichnungen.\n",
    "- Der Optimierer (`optim.SGD`) wird verwendet, um die Gewichte des neuronalen Netzes w√§hrend des Trainings zu aktualisieren.\n",
    "- Als Optimierungsalgorithmus wurde der stochastische Gradientenabstieg (SGD) mit einer Lernrate von 0,001 und einem Impuls von 0,9 gew√§hlt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Schritt 5: Trainieren des Netzwerks\n",
    "- Dieser Code trainiert ein neuronales Netz unter Verwendung des CIFAR-10-Datensatzes mit einer bestimmten Verlustfunktion (Kriterium) und einem Optimierer (Optimizer) f√ºr 2 Epochen und druckt den durchschnittlichen Verlust alle 2000 Mini-Batches aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=0.001):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Metrics\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.train_acc(outputs, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.val_acc(outputs, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model (replace with your actual model)\n",
    "net = Net()  # Assuming CNN() is your neural network model\n",
    "\n",
    "# Use PyTorch Lightning's CSVLogger to store logs\n",
    "logger = CSVLogger(\"logs\", name=\"CIFAR_model\")\n",
    "\n",
    "# Define the Lightning Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=4,  # Train for 4 epochs\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.fit(LitModel(net), trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# üìä Load and Plot CSV Logs\n",
    "# ===========================\n",
    "\n",
    "# Load training logs using pandas\n",
    "log_file = f\"logs/CIFAR_model/version_0/metrics.csv\"  # Path to logged metrics\n",
    "df = pd.read_csv(log_file)\n",
    "\n",
    "# Aggregate by epoch using `groupby.mean()`\n",
    "df_grouped = df.groupby(\"epoch\").mean()\n",
    "\n",
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training & Validation Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df_grouped.index, df_grouped[\"train_loss_epoch\"], \"o-\", label=\"Train Loss\")\n",
    "plt.plot(df_grouped.index, df_grouped[\"val_loss\"], \"s-\", label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot Training & Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df_grouped.index, df_grouped[\"train_acc_epoch\"], \"o-\", label=\"Train Accuracy\")\n",
    "plt.plot(df_grouped.index, df_grouped[\"val_acc\"], \"s-\", label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Netzwerk speichern und wieder laden\n",
    "\n",
    "Speichern Sie nach dem Training sowohl die Architektur des Modells als auch seine gelernten Gewichte.\n",
    "Um das Modell sp√§ter wiederherzustellen, m√ºssen Sie entweder das gesamte Modell oder sein Zustandsw√∂rterbuch laden.\n",
    "\n",
    "\n",
    "- Option 1 (Speichern des gesamten Modells): Einfach, aber weniger flexibel. Dadurch wird das gespeicherte Modell an den Code und die Umgebung zum Zeitpunkt der Speicherung gebunden.\n",
    "- Option 2 (Speichern des Zustandsw√∂rterbuchs): Ist flexibler und wird h√§ufig verwendet. Sie erm√∂glicht es Ihnen, nur die Gewichte zu speichern und die Modellstruktur neu zu initialisieren, was bei der Bereitstellung oder gemeinsamen Nutzung von Modellen n√ºtzlich ist.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model (structure and weights)\n",
    "torch.save(net, \"CIFAR_model.pth\")\n",
    "\n",
    "# Alternatively, save only the model's state dictionary (recommended)\n",
    "torch.save(net.state_dict(), \"CIFAR_model_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: Load the Model Weights (Recommended)\n",
    "When saving only the state dictionary, you must reinitialize the model structure first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model structure and weights\n",
    "net = torch.load(\"CIFAR_model.pth\", weights_only=False)\n",
    "net.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize the model structure\n",
    "net = Net()  # Replace with your model class\n",
    "\n",
    "# Load the weights\n",
    "net.load_state_dict(torch.load(\"model_weights.pth\"))\n",
    "net.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 6: Testen des Netzes\n",
    "- Dieser Code berechnet die Genauigkeit des neuronalen Netzes auf dem Testdatensatz (Testloader), indem er die vorhergesagten Bezeichnungen mit den tats√§chlichen Bezeichnungen vergleicht.\n",
    "- Er durchl√§uft den Testdatensatz, berechnet die Ausgaben des Netzes f√ºr jedes Bild und vergleicht die vorhergesagten Bezeichnungen mit den tats√§chlichen Bezeichnungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(\"Accuracy of the network on the 10000 test images: %d %%\" % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die bereitgestellte Ausgabe veranschaulicht den Trainingsprozess eines Convolutional Neural Network (CNN) f√ºr den CIFAR-10-Datensatz. Im Laufe von zwei Epochen verringert das Netzwerk schrittweise seine Verlustwerte, was auf eine Verbesserung seiner F√§higkeit, genaue Vorhersagen zu treffen, hinweist. W√§hrend des Trainings sinkt der Verlust kontinuierlich von 2,279 auf 1,263, was zeigt, dass das Netzwerk lernt, sich besser an die Trainingsdaten anzupassen. Trotz dieser Verbesserung bleibt die Genauigkeit im Testsatz bei 54 %, was darauf hindeutet, dass das Netzwerk zwar lernt, seine Leistung bei ungesehenen Daten jedoch m√§√üig ist. Die Verbesserung der Leistung des Modells k√∂nnte weitere Experimente mit Hyperparametern, √Ñnderungen der Architektur oder eine Verl√§ngerung der Trainingsdauer beinhalten. Insgesamt zeigt der Trainingsprozess die iterative Natur des Deep Learning, bei dem eine schrittweise Verfeinerung im Laufe der Zeit zu einer verbesserten Leistung f√ºhrt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(net, dataloader, classes, batch_size=4):\n",
    "    \"\"\"\n",
    "    Plots a batch of images from the given dataloader with predicted labels as titles.\n",
    "\n",
    "    Args:\n",
    "        net: The trained neural network model.\n",
    "        dataloader: PyTorch dataloader (e.g., testloader).\n",
    "        classes: Tuple of class names in CIFAR-10.\n",
    "        batch_size: Number of images to display in the batch.\n",
    "    \"\"\"\n",
    "    # Get one batch of images and labels\n",
    "    data_iter = iter(dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "\n",
    "    # Get predictions from the model\n",
    "    net.eval()  # Ensure the model is in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(1, batch_size, figsize=(batch_size * 3, 3))\n",
    "    for i in range(batch_size):\n",
    "        img = imshow(images[i])  # Unnormalize and prepare the image\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Pred: {classes[predicted[i]]}\\nTrue: {classes[labels[i]]}\")\n",
    "        axes[i].axis(\"off\")  # Hide axes\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to avoid overlapping\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "plot_predictions(net, testloader, classes, batch_size=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "ger",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "ger",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
