{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch, François Chollet </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN05/5.1-Einführung_CNN_PyTorch_CIFAR-10_ger.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Der Aufbau eines neuronalen Faltungsnetzwerks (Convolutional Neural Network, CNN) mit PyTorch umfasst mehrere Schritte, darunter die Definition der Architektur des Netzwerks, die Vorbereitung der Daten, das Training des Modells und die Bewertung seiner Leistung. In diesem Artikel werden wir sehen, wie wir ein CNN-Netzwerk in PyTorch aufbauen können.\n",
    "\n",
    "Inhaltsübersicht\n",
    "\n",
    "Was sind Faltungsneuronale Netze?\n",
    "Code-Implementierung für den Aufbau eines neuronalen Faltungsnetzwerks in PyTorch\n",
    "* Schritt 1: Importieren der erforderlichen Bibliotheken\n",
    "* Schritt 2: Vorbereiten des Datensatzes\n",
    "* Schritt 3: Definieren der CNN-Architektur\n",
    "* Schritt 4: Definieren der Verlustfunktion und des Optimierers\n",
    "* Schritt 5: Trainieren des Netzwerks\n",
    "* Schritt 6: Testen des Netzwerks\n",
    "\n",
    "Vollständiger Code zum Aufbau eines CNN mit PyTorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was sind Faltungsneuronale Netze?\n",
    "\n",
    "Faltungsneuronale Netze (Convolutional Neural Networks, CNN) sind eine Klasse von tiefen neuronalen Netzen, die hauptsächlich für die Analyse visueller Bilder verwendet werden. Sie bestehen aus mehreren Schichten, darunter Faltungsschichten, Pooling-Schichten und vollständig verbundene Schichten. CNNs sind darauf ausgelegt, automatisch und adaptiv räumliche Hierarchien von Merkmalen aus Eingabebildern zu lernen. Hier sind einige Komponenten von CNN.\n",
    "\n",
    "- *Faltungsschichten*: Diese Schichten wenden Faltungsoperationen auf die Eingabe an und extrahieren effektiv Merkmale wie Kanten, Texturen und Muster.\n",
    "- *Pooling-Schichten*: Pooling-Schichten reduzieren die räumlichen Dimensionen des Inputs durch Downsampling und helfen so, die Rechenkomplexität zu verringern und die Überanpassung zu kontrollieren.\n",
    "- *Aktivierungsfunktionen*: Aktivierungsfunktionen wie ReLU (Rectified Linear Unit) führen Nichtlinearität in das Netz ein, so dass es komplexe Beziehungen lernen kann.\n",
    "- *Vollständig verbundene Schichten*: Diese auch als dichte Schichten bezeichneten Schichten führen eine Klassifizierung auf der Grundlage der von den vorherigen Schichten extrahierten Merkmale durch.\n",
    "- *Verlustfunktion*: Die Verlustfunktion misst die Differenz zwischen der vorhergesagten Ausgabe des Netzes und der Grundwahrheit und steuert den Lernprozess des Netzes.\n",
    "- *Optimierungsalgorithmus*: Algorithmen wie Stochastic Gradient Descent (SGD), Adam oder RMSprop werden verwendet, um die Parameter des Netzes durch Minimierung der Verlustfunktion zu optimieren.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementierung des Aufbaus eines neuronalen Faltungsnetzes in PyTorch\n",
    "\n",
    "### Schritt 1: Importieren der notwendigen Bibliotheken\n",
    "In diesem Python-Codeblock importieren wir wichtige Module aus der PyTorch-Bibliothek, einem beliebten Open-Source-Framework für maschinelles Lernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# für Ausführung auf Google Colab auskommentieren und installieren\n",
    "%pip install -q -r https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/main/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tain on the GPU, we use CUDA 12.4\n",
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "\n",
    "# Select device: CUDA if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 2: Vorbereiten des Datensatzes\n",
    "\n",
    "- Dieser Code bereitet den CIFAR-10-Datensatz für das Training und Testen eines neuronalen Netzes mit PyTorch vor.\n",
    "- Er definiert eine Reihe von Bildtransformationen, einschließlich der Umwandlung von Bildern in PyTorch-Tensoren und deren Normalisierung. Anschließend werden Datensatzobjekte für die Trainings- und Testdatensätze von CIFAR-10 erstellt, wobei das Stammverzeichnis, die Angabe, dass es sich um einen Trainings- oder Testdatensatz handelt, und die Transformationssequenz angegeben werden.\n",
    "- Als Nächstes werden Datenlader für beide Datensätze erstellt, die das Laden der Daten in Stapeln, das Mischen der Daten und die Verwendung mehrerer Prozesse für ein schnelleres Laden der Daten ermöglichen.\n",
    "- Schließlich werden die Klassenbezeichnungen für CIFAR-10 definiert, die die 10 verschiedenen Objektklassen im Datensatz repräsentieren. \n",
    "- Insgesamt bereitet dieser Code den CIFAR-10-Datensatz für die Verwendung beim Training und bei der Evaluierung neuronaler Netzmodelle vor.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    \"\"\"Helper function to unnormalize and return an image for plotting.\"\"\"\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    return np.transpose(npimg, (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "\n",
    "\n",
    "def plot_batch(dataloader, classes, batch_size=4):\n",
    "    \"\"\"\n",
    "    Plots a batch of images from the given dataloader in a single figure.\n",
    "\n",
    "    Args:\n",
    "        dataloader: PyTorch dataloader for CIFAR-10 dataset.\n",
    "        classes: Tuple of class names in CIFAR-10.\n",
    "        batch_size: Number of images to display in the batch.\n",
    "    \"\"\"\n",
    "    # Get one batch of images and labels\n",
    "    data_iter = iter(dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(1, batch_size, figsize=(batch_size * 3, 3))\n",
    "    for i in range(batch_size):\n",
    "        img = imshow(images[i])  # Unnormalize and prepare the image\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(classes[labels[i]])\n",
    "        axes[i].axis(\"off\")  # Hide axes\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to avoid overlapping\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage with the CIFAR-10 trainloader\n",
    "plot_batch(trainloader, classes, batch_size=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Schritt 3: Definieren der CNN-Architektur\n",
    "- Dieser Code definiert eine neuronale Netzwerkarchitektur unter Verwendung der `nn.Module`-Klasse von PyTorch. Die Klasse Net erbt von nn.Module und definiert die Schichten des Netzwerks in ihrer `__init__`-Methode.\n",
    "- Es hat zwei Faltungsschichten (conv1 und conv2) mit ReLU-Aktivierungsfunktionen, gefolgt von Max-Pooling-Schichten (`pool`). Die vollständig verbundenen Schichten (`fc1`, `fc2` und `fc3`) verarbeiten die Ausgabe der Faltungsschichten.\n",
    "- Die Vorwärtsmethode `forward` definiert den Vorwärtsdurchlauf des Netzes, bei dem die Eingabe `x` nacheinander durch jede Schicht geleitet wird. Die view-Methode formt die Ausgabe der zweiten Faltungsschicht so um, dass sie mit den vollverknüpften Schichten kompatibel ist. Schließlich wird eine Instanz der Klasse Net erstellt, die das Modell des neuronalen Netzes darstellt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "#!pip install torchsummary torchviz\n",
    "\n",
    "# Import required libraries\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Summarize the model\n",
    "summary(\n",
    "    net, input_size=(3, 32, 32), device=\"cpu\"\n",
    ")  # Adjust input_size as per your model's requirement\n",
    "\n",
    "# Visualize the model architecture\n",
    "x = torch.randn(1, 3, 32, 32)  # Adjust input size as per your model's requirement\n",
    "y = net(x)\n",
    "make_dot(y, params=dict(net.named_parameters())).render(\"model_architecture_CIFAR\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "# Load and display the image\n",
    "image = Image.open(\"model_architecture_CIFAR.png\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 4: Definieren Sie Verlustfunktion und Optimierer\n",
    "- In diesem Code wird nn.CrossEntropyLoss() als Verlustfunktion (Kriterium) für das Training des neuronalen Netzes verwendet.\n",
    "- CrossEntropyLoss\" wird üblicherweise für Klassifizierungsaufgaben verwendet und berechnet den Verlust zwischen den vorhergesagten Klassenwahrscheinlichkeiten und den tatsächlichen Klassenbezeichnungen.\n",
    "- Der Optimierer (`optim.SGD`) wird verwendet, um die Gewichte des neuronalen Netzes während des Trainings zu aktualisieren.\n",
    "- Als Optimierungsalgorithmus wurde der stochastische Gradientenabstieg (SGD) mit einer Lernrate von 0,001 und einem Impuls von 0,9 gewählt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Schritt 5: Trainieren des Netzwerks\n",
    "- Dieser Code trainiert ein neuronales Netz unter Verwendung des CIFAR-10-Datensatzes mit einer bestimmten Verlustfunktion (Kriterium) und einem Optimierer (Optimizer) für 2 Epochen und druckt den durchschnittlichen Verlust alle 2000 Mini-Batches aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=0.001):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Metrics\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.train_acc(outputs, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.val_acc(outputs, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model (replace with your actual model)\n",
    "net = Net()  # Assuming CNN() is your neural network model\n",
    "\n",
    "# Use PyTorch Lightning's CSVLogger to store logs\n",
    "logger = CSVLogger(\"logs\", name=\"CIFAR_model\")\n",
    "\n",
    "# Define the Lightning Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=4,  # Train for 4 epochs\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.fit(LitModel(net), trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 📊 Load and Plot CSV Logs\n",
    "# ===========================\n",
    "\n",
    "# Load training logs using pandas\n",
    "log_file = f\"logs/CIFAR_model/version_0/metrics.csv\"  # Path to logged metrics\n",
    "df = pd.read_csv(log_file)\n",
    "\n",
    "# Aggregate by epoch using `groupby.mean()`\n",
    "df_grouped = df.groupby(\"epoch\").mean()\n",
    "\n",
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training & Validation Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df_grouped.index, df_grouped[\"train_loss_epoch\"], \"o-\", label=\"Train Loss\")\n",
    "plt.plot(df_grouped.index, df_grouped[\"val_loss\"], \"s-\", label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot Training & Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df_grouped.index, df_grouped[\"train_acc_epoch\"], \"o-\", label=\"Train Accuracy\")\n",
    "plt.plot(df_grouped.index, df_grouped[\"val_acc\"], \"s-\", label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Netzwerk speichern und wieder laden\n",
    "\n",
    "Speichern Sie nach dem Training sowohl die Architektur des Modells als auch seine gelernten Gewichte.\n",
    "Um das Modell später wiederherzustellen, müssen Sie entweder das gesamte Modell oder sein Zustandswörterbuch laden.\n",
    "\n",
    "\n",
    "- Option 1 (Speichern des gesamten Modells): Einfach, aber weniger flexibel. Dadurch wird das gespeicherte Modell an den Code und die Umgebung zum Zeitpunkt der Speicherung gebunden.\n",
    "- Option 2 (Speichern des Zustandswörterbuchs): Ist flexibler und wird häufig verwendet. Sie ermöglicht es Ihnen, nur die Gewichte zu speichern und die Modellstruktur neu zu initialisieren, was bei der Bereitstellung oder gemeinsamen Nutzung von Modellen nützlich ist.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model (structure and weights)\n",
    "torch.save(net, \"CIFAR_model.pth\")\n",
    "\n",
    "# Alternatively, save only the model's state dictionary (recommended)\n",
    "torch.save(net.state_dict(), \"CIFAR_model_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: Load the Model Weights (Recommended)\n",
    "When saving only the state dictionary, you must reinitialize the model structure first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model structure and weights\n",
    "net = torch.load(\"CIFAR_model.pth\", weights_only=False)\n",
    "net.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize the model structure\n",
    "net = Net()  # Replace with your model class\n",
    "\n",
    "# Load the weights\n",
    "net.load_state_dict(torch.load(\"model_weights.pth\"))\n",
    "net.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 6: Testen des Netzes\n",
    "- Dieser Code berechnet die Genauigkeit des neuronalen Netzes auf dem Testdatensatz (Testloader), indem er die vorhergesagten Bezeichnungen mit den tatsächlichen Bezeichnungen vergleicht.\n",
    "- Er durchläuft den Testdatensatz, berechnet die Ausgaben des Netzes für jedes Bild und vergleicht die vorhergesagten Bezeichnungen mit den tatsächlichen Bezeichnungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(\"Accuracy of the network on the 10000 test images: %d %%\" % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die bereitgestellte Ausgabe veranschaulicht den Trainingsprozess eines Convolutional Neural Network (CNN) für den CIFAR-10-Datensatz. Im Laufe von zwei Epochen verringert das Netzwerk schrittweise seine Verlustwerte, was auf eine Verbesserung seiner Fähigkeit, genaue Vorhersagen zu treffen, hinweist. Während des Trainings sinkt der Verlust kontinuierlich von 2,279 auf 1,263, was zeigt, dass das Netzwerk lernt, sich besser an die Trainingsdaten anzupassen. Trotz dieser Verbesserung bleibt die Genauigkeit im Testsatz bei 54 %, was darauf hindeutet, dass das Netzwerk zwar lernt, seine Leistung bei ungesehenen Daten jedoch mäßig ist. Die Verbesserung der Leistung des Modells könnte weitere Experimente mit Hyperparametern, Änderungen der Architektur oder eine Verlängerung der Trainingsdauer beinhalten. Insgesamt zeigt der Trainingsprozess die iterative Natur des Deep Learning, bei dem eine schrittweise Verfeinerung im Laufe der Zeit zu einer verbesserten Leistung führt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(net, dataloader, classes, batch_size=4):\n",
    "    \"\"\"\n",
    "    Plots a batch of images from the given dataloader with predicted labels as titles.\n",
    "\n",
    "    Args:\n",
    "        net: The trained neural network model.\n",
    "        dataloader: PyTorch dataloader (e.g., testloader).\n",
    "        classes: Tuple of class names in CIFAR-10.\n",
    "        batch_size: Number of images to display in the batch.\n",
    "    \"\"\"\n",
    "    # Get one batch of images and labels\n",
    "    data_iter = iter(dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "\n",
    "    # Get predictions from the model\n",
    "    net.eval()  # Ensure the model is in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(1, batch_size, figsize=(batch_size * 3, 3))\n",
    "    for i in range(batch_size):\n",
    "        img = imshow(images[i])  # Unnormalize and prepare the image\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Pred: {classes[predicted[i]]}\\nTrue: {classes[labels[i]]}\")\n",
    "        axes[i].axis(\"off\")  # Hide axes\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to avoid overlapping\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "plot_predictions(net, testloader, classes, batch_size=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "ger",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "ger",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
