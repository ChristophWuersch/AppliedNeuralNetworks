{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch, François Chollet </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN05/5.1-Einführung_CNN_MNIST_PyTorch_ger.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Der MNIST-Datensatz wurde von **Yann LeCun**, **Corinna Cortes** und **Christopher Burges** im Jahr 1998 eingeführt. Der MNIST-Datensatz und die Arbeit von Yann LeCun mit LeNet-5 ebneten den Weg für die Entwicklung von Convolutional Neural Networks, die heute das Rückgrat des modernen Deep Learning bilden. Durch das Studium von MNIST erhalten die Studierenden ein grundlegendes Verständnis für die Funktionsweise von CNNs und ihre historische Bedeutung im Bereich der KI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# für Ausführung auf Google Colab auskommentieren und installieren\n",
    "!pip install -q -r https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN05/Bilder/Yann-1024x341.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN05/Bilder/Yann-1024x341.jpg\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es handelt sich um eine Ableitung des ursprünglichen NIST-Datensatzes, der handgeschriebene Ziffern enthält, die von\n",
    "\n",
    "- **Angestellten der Volkszählungsbehörde** (saubere, weniger unterschiedliche Schreibstile).\n",
    "- **Highschool-Schülern** (unordentlicher, vielfältiger Schreibstil).\n",
    "\n",
    "Die Schöpfer von MNIST normalisierten und verarbeiteten diese Ziffern, um den Datensatz konsistenter und für Experimente zum maschinellen Lernen geeignet zu machen.\n",
    "In den späten 1980er Jahren demonstrierte Yann LeCun den ersten erfolgreichen Einsatz eines Convolutional Neural Network (CNN) für die Erkennung handgeschriebener Ziffern. Diese bahnbrechende Arbeit beinhaltete: LeCuns Modell mit der Bezeichnung **LeNet-5** bestand aus Faltungsschichten, Pooling-Schichten und vollständig verbundenen Schichten. Es wurde speziell für die Verarbeitung von Bildern und die Extraktion hierarchischer Merkmale entwickelt. LeNet-5 reduzierte die Anzahl der trainierbaren Parameter im Vergleich zu vollständig verknüpften Netzwerken erheblich, indem es die Gewichtsteilung nutzte.\n",
    "\n",
    "Das Modell wurde für die Ziffernerkennung bei der Post eingesetzt, um Postleitzahlen auf Briefumschlägen automatisch zu lesen. Die Aufgabe erforderte ein hohes Maß an Genauigkeit und Robustheit aufgrund der Variabilität der Handschrift. \n",
    "Die Anwendung eines Convolutional Neural Network (CNN) auf den MNIST-Datensatz ist eine beliebte Methode, um die Fähigkeiten von CNNs für Bildklassifizierungsaufgaben kennenzulernen und zu demonstrieren. Der MNIST-Datensatz besteht aus 28×28 Graustufenbildern handgeschriebener Ziffern (0-9), mit einem Trainingssatz von 60.000 Beispielen und einem Testsatz von 10.000 Beispielen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden wird ein grundlegender Ansatz zur Anwendung eines CNN auf den MNIST-Datensatz mithilfe der Programmiersprache Python und PyTorch vorgestellt:\n",
    "1.  *Laden* und Vorverarbeiten der Daten: Der MNIST-Datensatz kann mit der Keras-Bibliothek geladen werden, und die Bilder können normalisiert werden, um Pixelwerte zwischen 0 und 1 zu erhalten.\n",
    "2. *Definieren Sie die Modellarchitektur*: Die Architektur sollte in der Regel Faltungsschichten, Pooling-Schichten und voll verknüpfte Schichten umfassen.\n",
    "3. *Kompilieren des Modells*: Das Modell muss mit einer Verlustfunktion, einem Optimierer und einer Metrik zur Bewertung kompiliert werden.\n",
    "4. *Trainieren des Modells*: Das Modell kann mit der Keras-Funktion fit() auf dem Trainingssatz trainiert werden. Es ist wichtig, die Trainingsgenauigkeit und den Verlust zu überwachen, um sicherzustellen, dass das Modell richtig konvergiert.\n",
    "5. *Evaluieren Sie das Modell*: Das trainierte Modell kann mit Hilfe der Keras-Funktion evaluate() auf der Testmenge bewertet werden. Die für Klassifizierungsaufgaben üblicherweise verwendete Bewertungsmetrik ist die Genauigkeit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden finden Sie einige Tipps und bewährte Verfahren, die bei der Anwendung eines CNN auf den MNIST-Datensatz zu beachten sind:\n",
    "- Beginnen Sie mit einer einfachen Architektur und erhöhen Sie bei Bedarf schrittweise die Komplexität.\n",
    "- Experimentieren Sie mit verschiedenen Aktivierungsfunktionen, Optimierern, Lernraten und Stapelgrößen, um die optimale Kombination für Ihre spezielle Aufgabe zu finden.\n",
    "- Verwenden Sie Regularisierungstechniken wie Dropout oder Gewichtsabnahme, um eine Überanpassung zu verhindern.\n",
    "- Visualisieren Sie die vom Modell gelernten Filter und Feature-Maps, um Einblicke in seine Funktionsweise zu erhalten.\n",
    "- Vergleichen Sie die Leistung des CNN mit anderen Algorithmen des maschinellen Lernens wie Support Vector Machines oder Random Forests, um ein Gefühl für die relative Leistung zu bekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),  # Normalize to [-1, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=500, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warum wird 0.5 zur Normalisierung von Daten auf [-1, 1] verwendet?\n",
    "Die Funktion „Normalisieren“ in `PyTorch` ist wie folgt definiert:\n",
    "\n",
    "$$\n",
    "X_{\\text{norm}} = \\frac{X - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "wobei:\n",
    "- $\\mu$ der Mittelwert ist,\n",
    "- $\\sigma$ die Standardabweichung ist.\n",
    "\n",
    "Für den MNIST-Datensatz:\n",
    "- Die Pixelwerte reichen von $[0, 255]$.\n",
    "- Bei der Umwandlung in Tensoren mit „ToTensor()“ werden die Pixelwerte auf $[0, 1]$ skaliert.\n",
    "\n",
    "Um diese Werte auf $[-1, 1]$ zu normalisieren, verwenden wir:\n",
    "- $\\mu = 0.5$: Dadurch wird der Bereich von $[0, 1]$ auf $[-0,5, 0,5]$ verschoben.\n",
    "- $\\sigma = 0.5$: Damit wird der Bereich von $[-0,5, 0,5]$ auf $[-1, 1]$ verschoben.\n",
    "\n",
    "#### Formel:\n",
    "Für einen Eingabewert $x$:\n",
    "$$\n",
    "x_{\\text{norm}} = \\frac{x - 0.5}{0.5}\n",
    "$$\n",
    "\n",
    "#### Ergebnis:\n",
    "- Ursprünglicher Pixelbereich ($[0, 255]$): Skaliert auf $[0, 1]$ durch `ToTensor()`.\n",
    "- Nach der Normalisierung: Transformiert nach $[-1, 1]$ mit `Normalize((0.5,), (0.5,))`.\n",
    "\n",
    "Diese Normalisierung wird häufig verwendet, weil sie die Daten um $0$ mit einem konsistenten Bereich zentriert, was dazu beiträgt, dass neuronale Netze beim Training schneller konvergieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_mnist_digits(images, labels, num_images=10):\n",
    "    \"\"\"\n",
    "    Plots a selection of MNIST digits.\n",
    "\n",
    "    Parameters:\n",
    "    images (numpy.ndarray): Array of images.\n",
    "    labels (numpy.ndarray): Array of labels.\n",
    "    num_images (int): Number of images to display.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 2))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(torch.squeeze(images[i]), cmap=\"gray\")\n",
    "        plt.title(labels[i].numpy())\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "print_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "inputs, labels = next(iter(print_loader))  # Get the first batch\n",
    "\n",
    "plot_mnist_digits(inputs, labels, num_images=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_mnist_grid(images, labels, grid_size=(4, 4)):\n",
    "    \"\"\"\n",
    "    Plots a grid of MNIST digits with labels as insets.\n",
    "\n",
    "    Parameters:\n",
    "    images (torch.Tensor or numpy.ndarray): Array of images (shape: N x H x W).\n",
    "    labels (torch.Tensor or numpy.ndarray): Array of labels.\n",
    "    grid_size (tuple): Size of the grid (rows, cols).\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(\n",
    "        grid_size[0], grid_size[1], figsize=(grid_size[1] * 1.5, grid_size[0] * 1.5)\n",
    "    )\n",
    "\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < len(images):\n",
    "            ax.imshow(torch.squeeze(images[i]), cmap=\"gray\", aspect=\"auto\")\n",
    "            ax.text(\n",
    "                2,\n",
    "                5,\n",
    "                str(labels[i].item()),\n",
    "                fontsize=12,\n",
    "                color=\"red\",\n",
    "                bbox=dict(facecolor=\"white\", alpha=0.6),\n",
    "            )\n",
    "            ax.axis(\"off\")\n",
    "        else:\n",
    "            ax.axis(\"off\")  # Hide unused subplots\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)  # Reduce spacing\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 16\n",
    "print_loader = DataLoader(train_dataset, batch_size=grid_size**2, shuffle=True)\n",
    "images, labels = next(iter(print_loader))  # Get the first batch\n",
    "plot_mnist_grid(images, labels, grid_size=(grid_size, grid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)  # Output: [32, 26, 26]\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)  # Output: [64, 24, 24]\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3)  # Output: [64, 8, 8]\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 250)  # Adjusted for correct input size\n",
    "        self.fc2 = nn.Linear(250, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das CNN wurde entwickelt, um MNIST-Bilder (28x28 Graustufenbilder) in 10 Ziffernklassen (0-9) zu klassifizieren. Das Modell besteht aus den folgenden Komponenten:\n",
    "\n",
    "- **2 Convolutional Layers**\n",
    "- **1 Max-Pooling-Schicht**\n",
    "- **Dropout für Regularisierung**\n",
    "- **2 vollständig verknüpfte (lineare) Schichten**\n",
    "\n",
    "\n",
    "Die Eingabegrösse der MNIST-Bilder ist:\n",
    "\n",
    "$$\n",
    "\\text{Eingangsgrösse} = [\\text{Stapelgrösse}, 1, 28, 28]\n",
    "$$\n",
    "\n",
    "Hier:\n",
    "- Die Stapelgrösse ist die Anzahl der Bilder, die gleichzeitig verarbeitet werden.\n",
    "- $1$ ist die Anzahl der Kanäle (Graustufenbild).\n",
    "- $28 \\times 28$ ist die räumliche Auflösung des Bildes.\n",
    "\n",
    "\n",
    "##### **3.1 Faltungsschicht 1**\n",
    "\n",
    "- **Operation**: Wendet 32 Filter der Grösse $3 \\times 3$ an.\n",
    "- **Eingabegrösse**: $[1, 28, 28]$\n",
    "- **Ausgangsgrösse**: Berechnet als:\n",
    "  $$\n",
    "  \\text{Ausgabehöhe/-breite} = \\frac{\\text{Eingangsgrösse} - \\text{Kerngrösse} + 2 \\times \\text{Padding}}{\\text{Stride}} + 1\n",
    "  $$\n",
    "  Substituieren der Werte:\n",
    "  $$\n",
    "  \\text{Ausgabehöhe/-breite} = \\frac{28 - 3 + 2 \\times 0}{1} + 1 = 26\n",
    "  $$\n",
    "  Die Ausgabegrösse wird zu:\n",
    "  $$\n",
    "  [\\text{Stapelgrösse}, 32, 26, 26]\n",
    "  $$\n",
    "\n",
    "##### **3.2 Faltungsschicht 2**\n",
    "\n",
    "- **Operation**: Wendet 64 Filter der Grösse $3 \\times 3$ an.\n",
    "- **Eingabegrösse**: $[32, 26, 26]$\n",
    "- **Ausgangsgrösse**:\n",
    "  $$\n",
    "  \\text{Ausgabehöhe/-breite} = \\frac{26 - 3 + 2 \\times 0}{1} + 1 = 24\n",
    "  $$\n",
    "  Die Ausgabegrösse wird zu:\n",
    "  $$\n",
    "  [\\text{Stapelgrösse}, 64, 24, 24]\n",
    "  $$\n",
    "\n",
    "##### **3.3 Max-Pooling-Schicht**\n",
    "\n",
    "- **Operation**: Wendet eine $3 \\mal 3$ Pooling-Operation an.\n",
    "- **Eingabegrösse**: $[64, 24, 24]$\n",
    "- **Ausgangsgrösse**:\n",
    "  $$\n",
    "  \\text{Ausgabehöhe/-breite} = \\frac{24 - 3}{3} + 1 = 8\n",
    "  $$\n",
    "  Die Ausgabegrösse wird zu:\n",
    "  $$\n",
    "  [\\text{Stapelgrösse}, 64, 8, 8]\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### **3.4 Ebene abflachen**\n",
    "\n",
    "- **Operation**: Konvertiert den 3D-Tensor in einen 1D-Tensor für vollständig verbundene Schichten.\n",
    "- **Eingabegrösse**: $[64, 8, 8]$\n",
    "- **Ausgabegrösse**:\n",
    "  $$\n",
    "  \\text{Flattened size} = 64 \\times 8 \\times 8 = 4096\n",
    "  $$\n",
    "\n",
    "##### **3.5 Vollständig verknüpfte Schicht 1**\n",
    "\n",
    "- **Operation**: Ordnet die 4096 Eingangsmerkmale 250 Neuronen zu.\n",
    "- **Eingangsgrösse**: $4096$\n",
    "- **Ausgangsgrösse**:\n",
    "  $$\n",
    "  [250]\n",
    "  $$\n",
    "\n",
    "##### **3.6 Vollständig verknüpfte Schicht 2**\n",
    "\n",
    "- **Operation**: Verknüpft die 250 Eingabemerkmale mit 10 Ausgabeneuronen (eine für jede Ziffernklasse).\n",
    "- **Eingangsgrösse**: $250$\n",
    "- **Ausgangsgrösse**:\n",
    "  $$\n",
    "  [\\text{Stapelgrösse}, 10]\n",
    "  $$\n",
    "\n",
    "\n",
    "\n",
    "#### **4. Aktivierungsfunktionen**\n",
    "- **ReLU (Rectified Linear Unit)**: Wird in Faltungsschichten verwendet, um Nichtlinearität einzuführen.\n",
    "- **Sigmoid**: Wird in der ersten vollverknüpften Schicht angewendet, um die Ausgaben zu komprimieren.\n",
    "- **Softmax**: Wird intern nach der letzten Schicht (z. B. in `CrossEntropyLoss`) angewendet, um Logits in Wahrscheinlichkeiten umzuwandeln.\n",
    "\n",
    "\n",
    "\n",
    "#### **5. Vorwärtspass**\n",
    "Die Vorwärtsmethode verarbeitet die Eingabe durch die Schichten in der folgenden Reihenfolge:\n",
    "1. Faltungsschicht 1 mit ReLU-Aktivierung.\n",
    "2. Faltungsschicht 2 mit ReLU-Aktivierung.\n",
    "3. Max-Pooling-Schicht.\n",
    "4. Dropout-Schicht.\n",
    "5. Ebene abflachen.\n",
    "6. Vollständig verbundener Layer 1 mit Sigmoid-Aktivierung.\n",
    "7. Vollständig verbundene Schicht 2.\n",
    "\n",
    "\n",
    "#### **6. Zusammenfassung der Ausgabegrössen**\n",
    "| Schicht | Ausgabegrösse |\n",
    "|-------------------------|---------------------------|\n",
    "| Eingabe | $[\\text{Stapelgrösse}, 1, 28, 28]$ |\n",
    "| Faltungsschicht 1 | $[\\text{Stapelgrösse}, 32, 26, 26]$|\n",
    "| Faltungsschicht 2 | $[\\text{Stapelgrösse}, 64, 24, 24]$|\n",
    "| Max-Pooling-Schicht | $[\\text{Stapelgrösse}, 64, 8, 8]$ |\n",
    "| Flatten | $[\\text{Stapelgrösse}, 4096]$ |\n",
    "| Vollständig verbundene Schicht 1 | $[\\text{Stapelgrösse}, 250]$ |\n",
    "| Vollständig verbundene Schicht 2 | $[\\text{Stapelgrösse}, 10]$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "#!pip install torchsummary torchviz\n",
    "\n",
    "# Import required libraries\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot\n",
    "\n",
    "mymodel = CNN()  # Adjust device as per your requirement\n",
    "\n",
    "# Summarize the model\n",
    "summary(\n",
    "    mymodel, input_size=(1, 28, 28), device=\"cpu\"\n",
    ")  # Adjust input_size as per your model's requirement\n",
    "\n",
    "# Visualize the model architecture\n",
    "x = torch.randn(1, 1, 28, 28)  # Adjust input size as per your model's requirement\n",
    "y = mymodel(x)\n",
    "\n",
    "make_dot(y, params=dict(mymodel.named_parameters())).render(\n",
    "    \"model_architecture\", format=\"png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "# Load and display the image\n",
    "image = Image.open(\"model_architecture.png\")\n",
    "display(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tain on the GPU, we use CUDA 12.4\n",
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "\n",
    "# Select device: CUDA if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and move it to the selected device\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 12\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # Wrap train_loader with tqdm for progress bar\n",
    "    progress_bar = tqdm(\n",
    "        train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False\n",
    "    )\n",
    "\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move batch to CUDA\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update progress bar with loss info\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracies.append(100 * correct_train / total_train)\n",
    "\n",
    "    # ===========================\n",
    "    # Validation (Test) Phase\n",
    "    # ===========================\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed during validation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "    test_accuracies.append(100 * correct_test / total_test)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_losses[-1]:.4f} | Train Acc: {train_accuracies[-1]:.2f}% | Test Loss: {test_losses[-1]:.4f} | Test Acc: {test_accuracies[-1]:.2f}%\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label=\"Test Loss\", marker=\"s\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, label=\"Train Accuracy\", marker=\"o\")\n",
    "plt.plot(range(1, num_epochs + 1), test_accuracies, label=\"Test Accuracy\", marker=\"s\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Trainingsschleife ist für das Training des Modells über mehrere Epochen hinweg unter Verwendung der bereitgestellten Trainingsdaten verantwortlich. Im Folgenden werden die wichtigsten Komponenten der Schleife im Detail erläutert:\n",
    "\n",
    "### Zusammenfassung der wichtigsten Schritte:\n",
    "1. **Null-Gradienten**: Zurücksetzen der Gradienten vor der Verarbeitung eines neuen Stapels.\n",
    "2. **Vorwärtspass**: Berechnet Vorhersagen aus dem Modell.\n",
    "3. **Verlustberechnung**: Berechnung der Diskrepanz zwischen Vorhersagen und Beschriftungen.\n",
    "4. **Rückwärtspass**: Berechnung der Gradienten über Backpropagation.\n",
    "5. **Parameter-Aktualisierung**: Anpassung der Modellparameter mit Hilfe des Optimierers.\n",
    "6. **Metrische Aktualisierung**: Verfolgung von Verlust und Genauigkeit während des Trainings.\n",
    "\n",
    "Die Trainingsschleife wird für `num_epochs` wiederholt, um die Leistung des Modells iterativ zu verbessern.\n",
    "\n",
    "\n",
    "#### **1. Epochen-Schleife**\n",
    "- Diese Schleife durchläuft die Anzahl der Epochen, d. h. die Gesamtzahl der vollständigen Durchläufe durch den gesamten Trainingsdatensatz.\n",
    "- Jede Epoche aktualisiert die Modellparameter, um den Verlust zu minimieren und die Vorhersagen zu verbessern.\n",
    "#### **2. Modell in den Trainingsmodus versetzen**\n",
    "- Mit `model.train()` wird das Modell in den Trainingsmodus versetzt. Dies stellt sicher, dass sich Schichten wie `Dropout` oder `BatchNorm` korrekt verhalten (z.B. das Aktivieren von Dropout während des Trainings, aber nicht während der Auswertung).\n",
    "#### **3. Initialisierung der Tracking-Variablen**\n",
    "- `running_loss`: Akkumuliert den Gesamtverlust über die Batches in der aktuellen Epoche.\n",
    "- `correct_train`: Zählt die Anzahl der korrekten Vorhersagen, die das Modell während der Epoche gemacht hat.\n",
    "- `total_train`: Zählt die Gesamtzahl der in der aktuellen Epoche verarbeiteten Proben.\n",
    "#### **4. Batch-Schleife**\n",
    "- Die Schleife iteriert über die Trainingsdaten in Mini-Batches, die von `train_loader` bereitgestellt werden.\n",
    "- Eingaben\": Ein Stapel von Eingabedaten (z.B. Bilder).\n",
    "- Beschriftungen\": Die entsprechenden „ground-truth“-Bezeichnungen für die Eingaben.\n",
    "#### **5. Nullen der Gradienten**\n",
    "- Mit `optimizer.zero_grad()` werden die Gradienten der Modellparameter zurückgesetzt, bevor die Gradienten für den aktuellen Stapel berechnet werden.\n",
    "- Dies ist notwendig, weil Gradienten in PyTorch standardmäßig akkumulieren.\n",
    "#### **6. Vorwärtspass**\n",
    "- `outputs = model(inputs)` Lässt die Eingabedaten durch das Modell laufen, um Vorhersagen zu generieren.\n",
    "- `outputs`: Die Vorhersagen des Modells (`logits` im Fall von `CrossEntropyLoss`).\n",
    "#### **7. Berechnen des Verlusts**\n",
    "- `loss = criterion(outputs, labels)` berechnet den Verlust zwischen den Vorhersagen des Modells (`outputs`) und den „ground-truth labels“ (`labels`) unter Verwendung der angegebenen Verlustfunktion (`criterion`).\n",
    "\n",
    "Verlustformel für `CrossEntropyLoss`:\n",
    "$$\n",
    "\\mathcal{L}(x, y) = - \\sum_{i=1}^C y_i \\log(p_i)\n",
    "$$\n",
    "wobei:\n",
    "- $C$ die Anzahl der Klassen ist,\n",
    "- $y_i$ ist das Grundwahrheits-Label (one-hot kodiert),\n",
    "- $p_i$ ist die vorhergesagte Wahrscheinlichkeit für die Klasse $i$ (Ergebnis von `Softmax`).\n",
    "\n",
    "#### **8. Rückwärtspass**\n",
    "- `loss.backward()` berechnet die Gradienten des Verlustes in Bezug auf die Modellparameter mittels Backpropagation.\n",
    "- Die Gradienten werden im Attribut `.grad` der einzelnen Parameter gespeichert.\n",
    "#### **9. Modellparameter aktualisieren**\n",
    "- `optimizer.step()` aktualisiert die Modellparameter unter Verwendung der berechneten Gradienten und des Optimierungsalgorithmus (z.B. `Adam`, `SGD`).\n",
    "\n",
    "#### **10. Metriken aktualisieren**\n",
    "- `running_loss`: Akkumuliert den Gesamtverlust für die aktuelle Epoche, indem der Verlust für den aktuellen Stapel addiert wird.\n",
    "- `torch.max(outputs, 1)`: Ermittelt die vorhergesagte Klasse für jede Probe im Batch.\n",
    "- `total_train`: Verfolgt die Anzahl der bisher verarbeiteten Proben.\n",
    "- `correct_train`: Zählt die korrekt klassifizierten Proben durch Vergleich der Vorhersagen mit den „ground-truth labels“.\n",
    "\n",
    "#### **11. Berechnung von Epochenmetriken**\n",
    "- train_losses`: Speichert den durchschnittlichen Verlust für die Epoche.\n",
    "  $$ \\text{Durchschnittsverlust} = \\frac{\\text{Gesamtverlust in Epoche}}{\\text{Anzahl der Batches}} $$\n",
    "- `train_accuracies`: Speichert die Trainingsgenauigkeit für die Epoche.\n",
    "  $$ \\text{Genauigkeit} = \\frac{\\text{Anzahl der korrekten Vorhersagen}}{\\text{Gesamtzahl der Stichproben}} \\times 100 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementierung in PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import Accuracy\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1.0):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Metrics\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.train_acc(outputs, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.val_acc(outputs, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adadelta(self.parameters(), lr=self.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and dataset\n",
    "model = CNN()  # Assuming CNN is already defined\n",
    "train_loader = DataLoader(train_dataset, batch_size=500, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=500, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Create a CSV logger\n",
    "logger = CSVLogger(\"logs\", name=\"my_model\")\n",
    "\n",
    "# Define the PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=12,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    logger=logger,\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(LitModel(model), train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 📊 Load and Plot CSV Logs\n",
    "# ===========================\n",
    "\n",
    "# Load the CSV file into Pandas\n",
    "log_file = f\"logs/my_model/version_0/metrics.csv\"  # Update path if needed\n",
    "df = pd.read_csv(log_file)\n",
    "dg = df.groupby(\"epoch\").mean()\n",
    "dg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract epoch-wise values\n",
    "epochs = dg.index.values\n",
    "train_losses = dg[\"train_loss_epoch\"].values\n",
    "val_losses = dg[\"val_loss\"].values\n",
    "train_accs = dg[\"train_acc_epoch\"].values\n",
    "val_accs = dg[\"val_acc\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training & Validation Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, \"o-\", label=\"Train Loss\")\n",
    "plt.plot(epochs, val_losses, \"s-\", label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot Training & Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accs, \"o-\", label=\"Train Accuracy\")\n",
    "plt.plot(epochs, val_accs, \"s-\", label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
