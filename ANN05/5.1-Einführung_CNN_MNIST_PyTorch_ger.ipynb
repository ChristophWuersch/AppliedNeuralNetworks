{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> ¬© Christoph W√ºrsch, Fran√ßois Chollet </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN05/5.1-Einf√ºhrung_CNN_MNIST_PyTorch_ger.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Der MNIST-Datensatz wurde von **Yann LeCun**, **Corinna Cortes** und **Christopher Burges** im Jahr 1998 eingef√ºhrt. Der MNIST-Datensatz und die Arbeit von Yann LeCun mit LeNet-5 ebneten den Weg f√ºr die Entwicklung von Convolutional Neural Networks, die heute das R√ºckgrat des modernen Deep Learning bilden. Durch das Studium von MNIST erhalten die Studierenden ein grundlegendes Verst√§ndnis f√ºr die Funktionsweise von CNNs und ihre historische Bedeutung im Bereich der KI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f√ºr Ausf√ºhrung auf Google Colab auskommentieren und installieren\n",
    "!pip install -q -r https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN05/Bilder/Yann-1024x341.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN05/Bilder/Yann-1024x341.jpg\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es handelt sich um eine Ableitung des urspr√ºnglichen NIST-Datensatzes, der handgeschriebene Ziffern enth√§lt, die von\n",
    "\n",
    "- **Angestellten der Volksz√§hlungsbeh√∂rde** (saubere, weniger unterschiedliche Schreibstile).\n",
    "- **Highschool-Sch√ºlern** (unordentlicher, vielf√§ltiger Schreibstil).\n",
    "\n",
    "Die Sch√∂pfer von MNIST normalisierten und verarbeiteten diese Ziffern, um den Datensatz konsistenter und f√ºr Experimente zum maschinellen Lernen geeignet zu machen.\n",
    "In den sp√§ten 1980er Jahren demonstrierte Yann LeCun den ersten erfolgreichen Einsatz eines Convolutional Neural Network (CNN) f√ºr die Erkennung handgeschriebener Ziffern. Diese bahnbrechende Arbeit beinhaltete: LeCuns Modell mit der Bezeichnung **LeNet-5** bestand aus Faltungsschichten, Pooling-Schichten und vollst√§ndig verbundenen Schichten. Es wurde speziell f√ºr die Verarbeitung von Bildern und die Extraktion hierarchischer Merkmale entwickelt. LeNet-5 reduzierte die Anzahl der trainierbaren Parameter im Vergleich zu vollst√§ndig verkn√ºpften Netzwerken erheblich, indem es die Gewichtsteilung nutzte.\n",
    "\n",
    "Das Modell wurde f√ºr die Ziffernerkennung bei der Post eingesetzt, um Postleitzahlen auf Briefumschl√§gen automatisch zu lesen. Die Aufgabe erforderte ein hohes Ma√ü an Genauigkeit und Robustheit aufgrund der Variabilit√§t der Handschrift. \n",
    "Die Anwendung eines Convolutional Neural Network (CNN) auf den MNIST-Datensatz ist eine beliebte Methode, um die F√§higkeiten von CNNs f√ºr Bildklassifizierungsaufgaben kennenzulernen und zu demonstrieren. Der MNIST-Datensatz besteht aus 28√ó28 Graustufenbildern handgeschriebener Ziffern (0-9), mit einem Trainingssatz von 60.000 Beispielen und einem Testsatz von 10.000 Beispielen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden wird ein grundlegender Ansatz zur Anwendung eines CNN auf den MNIST-Datensatz mithilfe der Programmiersprache Python und PyTorch vorgestellt:\n",
    "1.  *Laden* und Vorverarbeiten der Daten: Der MNIST-Datensatz kann mit der Keras-Bibliothek geladen werden, und die Bilder k√∂nnen normalisiert werden, um Pixelwerte zwischen 0 und 1 zu erhalten.\n",
    "2. *Definieren Sie die Modellarchitektur*: Die Architektur sollte in der Regel Faltungsschichten, Pooling-Schichten und voll verkn√ºpfte Schichten umfassen.\n",
    "3. *Kompilieren des Modells*: Das Modell muss mit einer Verlustfunktion, einem Optimierer und einer Metrik zur Bewertung kompiliert werden.\n",
    "4. *Trainieren des Modells*: Das Modell kann mit der Keras-Funktion fit() auf dem Trainingssatz trainiert werden. Es ist wichtig, die Trainingsgenauigkeit und den Verlust zu √ºberwachen, um sicherzustellen, dass das Modell richtig konvergiert.\n",
    "5. *Evaluieren Sie das Modell*: Das trainierte Modell kann mit Hilfe der Keras-Funktion evaluate() auf der Testmenge bewertet werden. Die f√ºr Klassifizierungsaufgaben √ºblicherweise verwendete Bewertungsmetrik ist die Genauigkeit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden finden Sie einige Tipps und bew√§hrte Verfahren, die bei der Anwendung eines CNN auf den MNIST-Datensatz zu beachten sind:\n",
    "- Beginnen Sie mit einer einfachen Architektur und erh√∂hen Sie bei Bedarf schrittweise die Komplexit√§t.\n",
    "- Experimentieren Sie mit verschiedenen Aktivierungsfunktionen, Optimierern, Lernraten und Stapelgr√∂√üen, um die optimale Kombination f√ºr Ihre spezielle Aufgabe zu finden.\n",
    "- Verwenden Sie Regularisierungstechniken wie Dropout oder Gewichtsabnahme, um eine √úberanpassung zu verhindern.\n",
    "- Visualisieren Sie die vom Modell gelernten Filter und Feature-Maps, um Einblicke in seine Funktionsweise zu erhalten.\n",
    "- Vergleichen Sie die Leistung des CNN mit anderen Algorithmen des maschinellen Lernens wie Support Vector Machines oder Random Forests, um ein Gef√ºhl f√ºr die relative Leistung zu bekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),  # Normalize to [-1, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=500, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warum wird 0.5 zur Normalisierung von Daten auf [-1, 1] verwendet?\n",
    "Die Funktion ‚ÄûNormalisieren‚Äú in `PyTorch` ist wie folgt definiert:\n",
    "\n",
    "$$\n",
    "X_{\\text{norm}} = \\frac{X - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "wobei:\n",
    "- $\\mu$ der Mittelwert ist,\n",
    "- $\\sigma$ die Standardabweichung ist.\n",
    "\n",
    "F√ºr den MNIST-Datensatz:\n",
    "- Die Pixelwerte reichen von $[0, 255]$.\n",
    "- Bei der Umwandlung in Tensoren mit ‚ÄûToTensor()‚Äú werden die Pixelwerte auf $[0, 1]$ skaliert.\n",
    "\n",
    "Um diese Werte auf $[-1, 1]$ zu normalisieren, verwenden wir:\n",
    "- $\\mu = 0.5$: Dadurch wird der Bereich von $[0, 1]$ auf $[-0,5, 0,5]$ verschoben.\n",
    "- $\\sigma = 0.5$: Damit wird der Bereich von $[-0,5, 0,5]$ auf $[-1, 1]$ verschoben.\n",
    "\n",
    "#### Formel:\n",
    "F√ºr einen Eingabewert $x$:\n",
    "$$\n",
    "x_{\\text{norm}} = \\frac{x - 0.5}{0.5}\n",
    "$$\n",
    "\n",
    "#### Ergebnis:\n",
    "- Urspr√ºnglicher Pixelbereich ($[0, 255]$): Skaliert auf $[0, 1]$ durch `ToTensor()`.\n",
    "- Nach der Normalisierung: Transformiert nach $[-1, 1]$ mit `Normalize((0.5,), (0.5,))`.\n",
    "\n",
    "Diese Normalisierung wird h√§ufig verwendet, weil sie die Daten um $0$ mit einem konsistenten Bereich zentriert, was dazu beitr√§gt, dass neuronale Netze beim Training schneller konvergieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_mnist_digits(images, labels, num_images=10):\n",
    "    \"\"\"\n",
    "    Plots a selection of MNIST digits.\n",
    "\n",
    "    Parameters:\n",
    "    images (numpy.ndarray): Array of images.\n",
    "    labels (numpy.ndarray): Array of labels.\n",
    "    num_images (int): Number of images to display.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 2))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(torch.squeeze(images[i]), cmap=\"gray\")\n",
    "        plt.title(labels[i].numpy())\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "print_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "inputs, labels = next(iter(print_loader))  # Get the first batch\n",
    "\n",
    "plot_mnist_digits(inputs, labels, num_images=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_mnist_grid(images, labels, grid_size=(4, 4)):\n",
    "    \"\"\"\n",
    "    Plots a grid of MNIST digits with labels as insets.\n",
    "\n",
    "    Parameters:\n",
    "    images (torch.Tensor or numpy.ndarray): Array of images (shape: N x H x W).\n",
    "    labels (torch.Tensor or numpy.ndarray): Array of labels.\n",
    "    grid_size (tuple): Size of the grid (rows, cols).\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(\n",
    "        grid_size[0], grid_size[1], figsize=(grid_size[1] * 1.5, grid_size[0] * 1.5)\n",
    "    )\n",
    "\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < len(images):\n",
    "            ax.imshow(torch.squeeze(images[i]), cmap=\"gray\", aspect=\"auto\")\n",
    "            ax.text(\n",
    "                2,\n",
    "                5,\n",
    "                str(labels[i].item()),\n",
    "                fontsize=12,\n",
    "                color=\"red\",\n",
    "                bbox=dict(facecolor=\"white\", alpha=0.6),\n",
    "            )\n",
    "            ax.axis(\"off\")\n",
    "        else:\n",
    "            ax.axis(\"off\")  # Hide unused subplots\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)  # Reduce spacing\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 16\n",
    "print_loader = DataLoader(train_dataset, batch_size=grid_size**2, shuffle=True)\n",
    "images, labels = next(iter(print_loader))  # Get the first batch\n",
    "plot_mnist_grid(images, labels, grid_size=(grid_size, grid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)  # Output: [32, 26, 26]\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)  # Output: [64, 24, 24]\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3)  # Output: [64, 8, 8]\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 250)  # Adjusted for correct input size\n",
    "        self.fc2 = nn.Linear(250, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das CNN wurde entwickelt, um MNIST-Bilder (28x28 Graustufenbilder) in 10 Ziffernklassen (0-9) zu klassifizieren. Das Modell besteht aus den folgenden Komponenten:\n",
    "\n",
    "- **2 Convolutional Layers**\n",
    "- **1 Max-Pooling-Schicht**\n",
    "- **Dropout f√ºr Regularisierung**\n",
    "- **2 vollst√§ndig verkn√ºpfte (lineare) Schichten**\n",
    "\n",
    "\n",
    "Die Eingabegr√∂sse der MNIST-Bilder ist:\n",
    "\n",
    "$$\n",
    "\\text{Eingangsgr√∂sse} = [\\text{Stapelgr√∂sse}, 1, 28, 28]\n",
    "$$\n",
    "\n",
    "Hier:\n",
    "- Die Stapelgr√∂sse ist die Anzahl der Bilder, die gleichzeitig verarbeitet werden.\n",
    "- $1$ ist die Anzahl der Kan√§le (Graustufenbild).\n",
    "- $28 \\times 28$ ist die r√§umliche Aufl√∂sung des Bildes.\n",
    "\n",
    "\n",
    "##### **3.1 Faltungsschicht 1**\n",
    "\n",
    "- **Operation**: Wendet 32 Filter der Gr√∂sse $3 \\times 3$ an.\n",
    "- **Eingabegr√∂sse**: $[1, 28, 28]$\n",
    "- **Ausgangsgr√∂sse**: Berechnet als:\n",
    "  $$\n",
    "  \\text{Ausgabeh√∂he/-breite} = \\frac{\\text{Eingangsgr√∂sse} - \\text{Kerngr√∂sse} + 2 \\times \\text{Padding}}{\\text{Stride}} + 1\n",
    "  $$\n",
    "  Substituieren der Werte:\n",
    "  $$\n",
    "  \\text{Ausgabeh√∂he/-breite} = \\frac{28 - 3 + 2 \\times 0}{1} + 1 = 26\n",
    "  $$\n",
    "  Die Ausgabegr√∂sse wird zu:\n",
    "  $$\n",
    "  [\\text{Stapelgr√∂sse}, 32, 26, 26]\n",
    "  $$\n",
    "\n",
    "##### **3.2 Faltungsschicht 2**\n",
    "\n",
    "- **Operation**: Wendet 64 Filter der Gr√∂sse $3 \\times 3$ an.\n",
    "- **Eingabegr√∂sse**: $[32, 26, 26]$\n",
    "- **Ausgangsgr√∂sse**:\n",
    "  $$\n",
    "  \\text{Ausgabeh√∂he/-breite} = \\frac{26 - 3 + 2 \\times 0}{1} + 1 = 24\n",
    "  $$\n",
    "  Die Ausgabegr√∂sse wird zu:\n",
    "  $$\n",
    "  [\\text{Stapelgr√∂sse}, 64, 24, 24]\n",
    "  $$\n",
    "\n",
    "##### **3.3 Max-Pooling-Schicht**\n",
    "\n",
    "- **Operation**: Wendet eine $3 \\mal 3$ Pooling-Operation an.\n",
    "- **Eingabegr√∂sse**: $[64, 24, 24]$\n",
    "- **Ausgangsgr√∂sse**:\n",
    "  $$\n",
    "  \\text{Ausgabeh√∂he/-breite} = \\frac{24 - 3}{3} + 1 = 8\n",
    "  $$\n",
    "  Die Ausgabegr√∂sse wird zu:\n",
    "  $$\n",
    "  [\\text{Stapelgr√∂sse}, 64, 8, 8]\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### **3.4 Ebene abflachen**\n",
    "\n",
    "- **Operation**: Konvertiert den 3D-Tensor in einen 1D-Tensor f√ºr vollst√§ndig verbundene Schichten.\n",
    "- **Eingabegr√∂sse**: $[64, 8, 8]$\n",
    "- **Ausgabegr√∂sse**:\n",
    "  $$\n",
    "  \\text{Flattened size} = 64 \\times 8 \\times 8 = 4096\n",
    "  $$\n",
    "\n",
    "##### **3.5 Vollst√§ndig verkn√ºpfte Schicht 1**\n",
    "\n",
    "- **Operation**: Ordnet die 4096 Eingangsmerkmale 250 Neuronen zu.\n",
    "- **Eingangsgr√∂sse**: $4096$\n",
    "- **Ausgangsgr√∂sse**:\n",
    "  $$\n",
    "  [250]\n",
    "  $$\n",
    "\n",
    "##### **3.6 Vollst√§ndig verkn√ºpfte Schicht 2**\n",
    "\n",
    "- **Operation**: Verkn√ºpft die 250 Eingabemerkmale mit 10 Ausgabeneuronen (eine f√ºr jede Ziffernklasse).\n",
    "- **Eingangsgr√∂sse**: $250$\n",
    "- **Ausgangsgr√∂sse**:\n",
    "  $$\n",
    "  [\\text{Stapelgr√∂sse}, 10]\n",
    "  $$\n",
    "\n",
    "\n",
    "\n",
    "#### **4. Aktivierungsfunktionen**\n",
    "- **ReLU (Rectified Linear Unit)**: Wird in Faltungsschichten verwendet, um Nichtlinearit√§t einzuf√ºhren.\n",
    "- **Sigmoid**: Wird in der ersten vollverkn√ºpften Schicht angewendet, um die Ausgaben zu komprimieren.\n",
    "- **Softmax**: Wird intern nach der letzten Schicht (z. B. in `CrossEntropyLoss`) angewendet, um Logits in Wahrscheinlichkeiten umzuwandeln.\n",
    "\n",
    "\n",
    "\n",
    "#### **5. Vorw√§rtspass**\n",
    "Die Vorw√§rtsmethode verarbeitet die Eingabe durch die Schichten in der folgenden Reihenfolge:\n",
    "1. Faltungsschicht 1 mit ReLU-Aktivierung.\n",
    "2. Faltungsschicht 2 mit ReLU-Aktivierung.\n",
    "3. Max-Pooling-Schicht.\n",
    "4. Dropout-Schicht.\n",
    "5. Ebene abflachen.\n",
    "6. Vollst√§ndig verbundener Layer 1 mit Sigmoid-Aktivierung.\n",
    "7. Vollst√§ndig verbundene Schicht 2.\n",
    "\n",
    "\n",
    "#### **6. Zusammenfassung der Ausgabegr√∂ssen**\n",
    "| Schicht | Ausgabegr√∂sse |\n",
    "|-------------------------|---------------------------|\n",
    "| Eingabe | $[\\text{Stapelgr√∂sse}, 1, 28, 28]$ |\n",
    "| Faltungsschicht 1 | $[\\text{Stapelgr√∂sse}, 32, 26, 26]$|\n",
    "| Faltungsschicht 2 | $[\\text{Stapelgr√∂sse}, 64, 24, 24]$|\n",
    "| Max-Pooling-Schicht | $[\\text{Stapelgr√∂sse}, 64, 8, 8]$ |\n",
    "| Flatten | $[\\text{Stapelgr√∂sse}, 4096]$ |\n",
    "| Vollst√§ndig verbundene Schicht 1 | $[\\text{Stapelgr√∂sse}, 250]$ |\n",
    "| Vollst√§ndig verbundene Schicht 2 | $[\\text{Stapelgr√∂sse}, 10]$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "#!pip install torchsummary torchviz\n",
    "\n",
    "# Import required libraries\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot\n",
    "\n",
    "mymodel = CNN()  # Adjust device as per your requirement\n",
    "\n",
    "# Summarize the model\n",
    "summary(\n",
    "    mymodel, input_size=(1, 28, 28), device=\"cpu\"\n",
    ")  # Adjust input_size as per your model's requirement\n",
    "\n",
    "# Visualize the model architecture\n",
    "x = torch.randn(1, 1, 28, 28)  # Adjust input size as per your model's requirement\n",
    "y = mymodel(x)\n",
    "\n",
    "make_dot(y, params=dict(mymodel.named_parameters())).render(\n",
    "    \"model_architecture\", format=\"png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "# Load and display the image\n",
    "image = Image.open(\"model_architecture.png\")\n",
    "display(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tain on the GPU, we use CUDA 12.4\n",
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "\n",
    "# Select device: CUDA if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and move it to the selected device\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 12\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # Wrap train_loader with tqdm for progress bar\n",
    "    progress_bar = tqdm(\n",
    "        train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False\n",
    "    )\n",
    "\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move batch to CUDA\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update progress bar with loss info\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracies.append(100 * correct_train / total_train)\n",
    "\n",
    "    # ===========================\n",
    "    # Validation (Test) Phase\n",
    "    # ===========================\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed during validation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "    test_accuracies.append(100 * correct_test / total_test)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_losses[-1]:.4f} | Train Acc: {train_accuracies[-1]:.2f}% | Test Loss: {test_losses[-1]:.4f} | Test Acc: {test_accuracies[-1]:.2f}%\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label=\"Test Loss\", marker=\"s\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, label=\"Train Accuracy\", marker=\"o\")\n",
    "plt.plot(range(1, num_epochs + 1), test_accuracies, label=\"Test Accuracy\", marker=\"s\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Trainingsschleife ist f√ºr das Training des Modells √ºber mehrere Epochen hinweg unter Verwendung der bereitgestellten Trainingsdaten verantwortlich. Im Folgenden werden die wichtigsten Komponenten der Schleife im Detail erl√§utert:\n",
    "\n",
    "### Zusammenfassung der wichtigsten Schritte:\n",
    "1. **Null-Gradienten**: Zur√ºcksetzen der Gradienten vor der Verarbeitung eines neuen Stapels.\n",
    "2. **Vorw√§rtspass**: Berechnet Vorhersagen aus dem Modell.\n",
    "3. **Verlustberechnung**: Berechnung der Diskrepanz zwischen Vorhersagen und Beschriftungen.\n",
    "4. **R√ºckw√§rtspass**: Berechnung der Gradienten √ºber Backpropagation.\n",
    "5. **Parameter-Aktualisierung**: Anpassung der Modellparameter mit Hilfe des Optimierers.\n",
    "6. **Metrische Aktualisierung**: Verfolgung von Verlust und Genauigkeit w√§hrend des Trainings.\n",
    "\n",
    "Die Trainingsschleife wird f√ºr `num_epochs` wiederholt, um die Leistung des Modells iterativ zu verbessern.\n",
    "\n",
    "\n",
    "#### **1. Epochen-Schleife**\n",
    "- Diese Schleife durchl√§uft die Anzahl der Epochen, d. h. die Gesamtzahl der vollst√§ndigen Durchl√§ufe durch den gesamten Trainingsdatensatz.\n",
    "- Jede Epoche aktualisiert die Modellparameter, um den Verlust zu minimieren und die Vorhersagen zu verbessern.\n",
    "#### **2. Modell in den Trainingsmodus versetzen**\n",
    "- Mit `model.train()` wird das Modell in den Trainingsmodus versetzt. Dies stellt sicher, dass sich Schichten wie `Dropout` oder `BatchNorm` korrekt verhalten (z.B. das Aktivieren von Dropout w√§hrend des Trainings, aber nicht w√§hrend der Auswertung).\n",
    "#### **3. Initialisierung der Tracking-Variablen**\n",
    "- `running_loss`: Akkumuliert den Gesamtverlust √ºber die Batches in der aktuellen Epoche.\n",
    "- `correct_train`: Z√§hlt die Anzahl der korrekten Vorhersagen, die das Modell w√§hrend der Epoche gemacht hat.\n",
    "- `total_train`: Z√§hlt die Gesamtzahl der in der aktuellen Epoche verarbeiteten Proben.\n",
    "#### **4. Batch-Schleife**\n",
    "- Die Schleife iteriert √ºber die Trainingsdaten in Mini-Batches, die von `train_loader` bereitgestellt werden.\n",
    "- Eingaben\": Ein Stapel von Eingabedaten (z.B. Bilder).\n",
    "- Beschriftungen\": Die entsprechenden ‚Äûground-truth‚Äú-Bezeichnungen f√ºr die Eingaben.\n",
    "#### **5. Nullen der Gradienten**\n",
    "- Mit `optimizer.zero_grad()` werden die Gradienten der Modellparameter zur√ºckgesetzt, bevor die Gradienten f√ºr den aktuellen Stapel berechnet werden.\n",
    "- Dies ist notwendig, weil Gradienten in PyTorch standardm√§√üig akkumulieren.\n",
    "#### **6. Vorw√§rtspass**\n",
    "- `outputs = model(inputs)` L√§sst die Eingabedaten durch das Modell laufen, um Vorhersagen zu generieren.\n",
    "- `outputs`: Die Vorhersagen des Modells (`logits` im Fall von `CrossEntropyLoss`).\n",
    "#### **7. Berechnen des Verlusts**\n",
    "- `loss = criterion(outputs, labels)` berechnet den Verlust zwischen den Vorhersagen des Modells (`outputs`) und den ‚Äûground-truth labels‚Äú (`labels`) unter Verwendung der angegebenen Verlustfunktion (`criterion`).\n",
    "\n",
    "Verlustformel f√ºr `CrossEntropyLoss`:\n",
    "$$\n",
    "\\mathcal{L}(x, y) = - \\sum_{i=1}^C y_i \\log(p_i)\n",
    "$$\n",
    "wobei:\n",
    "- $C$ die Anzahl der Klassen ist,\n",
    "- $y_i$ ist das Grundwahrheits-Label (one-hot kodiert),\n",
    "- $p_i$ ist die vorhergesagte Wahrscheinlichkeit f√ºr die Klasse $i$ (Ergebnis von `Softmax`).\n",
    "\n",
    "#### **8. R√ºckw√§rtspass**\n",
    "- `loss.backward()` berechnet die Gradienten des Verlustes in Bezug auf die Modellparameter mittels Backpropagation.\n",
    "- Die Gradienten werden im Attribut `.grad` der einzelnen Parameter gespeichert.\n",
    "#### **9. Modellparameter aktualisieren**\n",
    "- `optimizer.step()` aktualisiert die Modellparameter unter Verwendung der berechneten Gradienten und des Optimierungsalgorithmus (z.B. `Adam`, `SGD`).\n",
    "\n",
    "#### **10. Metriken aktualisieren**\n",
    "- `running_loss`: Akkumuliert den Gesamtverlust f√ºr die aktuelle Epoche, indem der Verlust f√ºr den aktuellen Stapel addiert wird.\n",
    "- `torch.max(outputs, 1)`: Ermittelt die vorhergesagte Klasse f√ºr jede Probe im Batch.\n",
    "- `total_train`: Verfolgt die Anzahl der bisher verarbeiteten Proben.\n",
    "- `correct_train`: Z√§hlt die korrekt klassifizierten Proben durch Vergleich der Vorhersagen mit den ‚Äûground-truth labels‚Äú.\n",
    "\n",
    "#### **11. Berechnung von Epochenmetriken**\n",
    "- train_losses`: Speichert den durchschnittlichen Verlust f√ºr die Epoche.\n",
    "  $$ \\text{Durchschnittsverlust} = \\frac{\\text{Gesamtverlust in Epoche}}{\\text{Anzahl der Batches}} $$\n",
    "- `train_accuracies`: Speichert die Trainingsgenauigkeit f√ºr die Epoche.\n",
    "  $$ \\text{Genauigkeit} = \\frac{\\text{Anzahl der korrekten Vorhersagen}}{\\text{Gesamtzahl der Stichproben}} \\times 100 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementierung in PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import Accuracy\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1.0):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Metrics\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.train_acc(outputs, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.val_acc(outputs, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adadelta(self.parameters(), lr=self.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and dataset\n",
    "model = CNN()  # Assuming CNN is already defined\n",
    "train_loader = DataLoader(train_dataset, batch_size=500, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=500, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Create a CSV logger\n",
    "logger = CSVLogger(\"logs\", name=\"my_model\")\n",
    "\n",
    "# Define the PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=12,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    logger=logger,\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(LitModel(model), train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# üìä Load and Plot CSV Logs\n",
    "# ===========================\n",
    "\n",
    "# Load the CSV file into Pandas\n",
    "log_file = f\"logs/my_model/version_0/metrics.csv\"  # Update path if needed\n",
    "df = pd.read_csv(log_file)\n",
    "dg = df.groupby(\"epoch\").mean()\n",
    "dg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract epoch-wise values\n",
    "epochs = dg.index.values\n",
    "train_losses = dg[\"train_loss_epoch\"].values\n",
    "val_losses = dg[\"val_loss\"].values\n",
    "train_accs = dg[\"train_acc_epoch\"].values\n",
    "val_accs = dg[\"val_acc\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training & Validation Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, \"o-\", label=\"Train Loss\")\n",
    "plt.plot(epochs, val_losses, \"s-\", label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot Training & Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accs, \"o-\", label=\"Train Accuracy\")\n",
    "plt.plot(epochs, val_accs, \"s-\", label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
