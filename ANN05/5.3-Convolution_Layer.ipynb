{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN05/5.3-Convolution_Layer.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Faltungen für Bilder\n",
    "\n",
    "- Nachdem wir nun verstanden haben, wie Faltungsschichten in der Theorie funktionieren, sind wir nun bereit zu sehen, wie sie in der Praxis funktionieren.\n",
    "- Aufbauend auf unserer Motivation, Faltungsneuronale Netze als effiziente Architekturen zur Erforschung von Strukturen in Bilddaten, bleiben wir bei Bildern als laufendes Beispiel.\n",
    "\n",
    "\n",
    "## Die Kreuzkorrelation\n",
    "\n",
    "- Streng genommen ist die Bezeichnung *Faltungsschichten* falsch, da die Operationen, die sie durchführt genauer als Kreuzkorrelationen definiert ist.\n",
    "- Basierend auf unserer Beschreibung von Faltungsschichten werden in einer solchen Schicht ein Eingangstensor und ein Kernel-Tensor durch eine (**Kreuzkorrelation**) zu einem Ausgangstensor kombiniert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Lassen wir die Kanäle erst einmal ausser Acht und sehen wir uns an, wie das \n",
    "mit zweidimensionalen Daten und versteckten Repräsentationen funktioniert.\n",
    "\n",
    "- In der folgenden Abbildung, ist die Eingabe ein zweidimensionaler Tensor mit einer Höhe von 3 und einer Breite von 3.\n",
    "- Wir markieren die Form des Tensors als $3 \\times 3$ oder ($3$, $3$).\n",
    "- Die Höhe und Breite des Kerns sind beide 2.\n",
    "- Die Form des *Kernelfensters* (oder *Faltungsfensters*) ist durch die Höhe und Breite des Kerns gegeben (hier ist es $2 \\times 2$).\n",
    "\n",
    "<img src=\"Bilder/correlation.svg\" width=\"640\" height=\"440\" align=\"center\"/>\n",
    "\n",
    "Zweidimensionale Kreuzkorrelation: Die schattierten Bereiche sind das erste Ausgabeelement sowie die Eingabe- und Kernel-Tensorelemente, die für die Ausgabeberechnung verwendet werden: $0\\times0+1\\times1+3\\times2+4\\times3=19$.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Bei der zweidimensionalen Kreuzkorrelationsoperation beginnen wir mit dem Faltungsfenster, das sich an der oberen linken Ecke des Eingabetensorsund schieben es über den Eingabetensor, sowohl von links nach rechts als auch von oben nach unten.\n",
    "- Wenn das Faltungsfenster an eine bestimmte Position gleitet, werden der in diesem Fenster enthaltene Eingabe-Subtensor und der Kernel-Tensor elementweise multipliziert und der resultierende Tensor wird summiert was einen einzigen skalaren Wert ergibt.\n",
    "- Dieses Ergebnis gibt den Wert des Ausgangstensors an der entsprechenden Stelle. Hier hat der Ausgangstensor eine Höhe von 2 und eine Breite von 2 und die vier Elemente werden abgeleitet aus der zweidimensionalen Kreuzkorrelationsoperation:\n",
    "\n",
    "$$\n",
    "0\\cdot0+1\\cdot1+3\\cdot2+4\\cdot3=19,\\\\\n",
    "1\\cdot0+2\\cdot1+4\\cdot2+5\\cdot3=25,\\\\\n",
    "3\\cdot0+4\\cdot1+6\\cdot2+7\\cdot3=37,\\\\\n",
    "4\\cdot0+5\\cdot1+7\\cdot2+8\\cdot3=43.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Beachten Sie, dass entlang jeder Achse die Ausgabegrösse etwas kleiner ist als die Eingabegrösse.\n",
    "- Da der Kernel eine Breite und Höhe grösser als eins hat, können wir die Kreuzkorrelation nur für Stellen richtig berechnen, an denen der Kernel vollständig in das Bild passt.\n",
    "- Die Ausgabegrösse ist gegeben durch die Eingabegrösse $n_h \\times n_w$ abzüglich der Grösse des Faltungskerns $k_h \\times k_w$ über\n",
    "\n",
    "$$(n_h-k_h+1) \\times (n_w-k_w+1).$$\n",
    "\n",
    "Dies ist der Fall, da wir genügend Platz benötigen, um den Faltungs-Kernel über das Bild zu \"verschieben\".\n",
    "Später werden wir sehen, wie man die Grösse durch Auffüllen des Bildes mit Nullen am Rande des Bildes unverändert lassen kann, \n",
    "so dass genügend Platz zum Verschieben des Kerns vorhanden ist. \n",
    "\n",
    "Als nächstes implementieren wir diesen Prozess in der Funktion `corr2d`, die einen Eingabetensor `X` und einen Kernel-Tensor `K` annimmt akzeptiert und einen Ausgangstensor `Y` zurückgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 4,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def corr2d(X, K):\n",
    "    \"\"\"Compute 2D cross-correlation in PyTorch.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))  # Initialize output tensor\n",
    "\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = torch.sum(X[i:i + h, j:j + w] * K)  # Element-wise multiplication and sum\n",
    "\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 5,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wir können den Eingabe-Tensor `X` und den Kernel-Tensor `K` aus der obigen Abbildung konstruieren\n",
    "um die Rechnung der zweidimensionalen Kreuzkorrelationsoperation zu überprüfen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 6,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def corr2d(X, K):\n",
    "    \"\"\"Compute 2D cross-correlation in PyTorch.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))  # Initialize output tensor\n",
    "\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = torch.sum(X[i:i + h, j:j + w] * K)  # Element-wise multiplication and sum\n",
    "\n",
    "    return Y\n",
    "\n",
    "# Define input tensors and kernels\n",
    "X = torch.tensor([[0.0, 1.0, 2.0], \n",
    "                  [3.0, 4.0, 5.0], \n",
    "                  [6.0, 7.0, 8.0]])\n",
    "\n",
    "K = torch.tensor([[+1.0, -1.0], \n",
    "                  [-1.0, 1.0]])\n",
    "\n",
    "# Compute cross-correlation\n",
    "result1 = corr2d(X, K)\n",
    "print(\"Result 1:\\n\", result1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Second input and kernels\n",
    "X = torch.tensor([[0.0, 1.0, 1.0, 0.0], \n",
    "                  [0.0, 1.0, 1.0, 0.0], \n",
    "                  [0.0, 1.0, 1.0, 0.0],\n",
    "                  [0.0, 1.0, 1.0, 0.0]])\n",
    "\n",
    "Kv = torch.tensor([[+1.0, +1.0], \n",
    "                   [-1.0, -1.0]])\n",
    "\n",
    "Kh = torch.tensor([[+1.0, -1.0], \n",
    "                   [+1.0, -1.0]])\n",
    "\n",
    "K45 = torch.tensor([[+1.0, -1.0, 0.0], \n",
    "                    [0.0, +1.0, -1.0],\n",
    "                    [0.0,  0.0, +1.0]])\n",
    "\n",
    "# Compute cross-correlation with different kernels\n",
    "result2 = corr2d(X, Kh)\n",
    "print(\"\\nResult 2:\\n\", result2)\n",
    "\n",
    "result3 = corr2d(X, Kv)\n",
    "print(\"\\nResult 3:\\n\", result3)\n",
    "\n",
    "result4 = corr2d(X, K45)\n",
    "print(\"\\nResult 4:\\n\", result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2d(X, Kv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 7,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Faltungsschichten\n",
    "\n",
    "- Eine Faltungsschicht führt eine Kreuzkorrelation zwischen der Eingabe und dem Kernel und fügt einen skalaren Bias (Offset) hinzu, um eine Ausgabe zu erzeugen.\n",
    "- Die beiden Parameter einer Faltungsschicht sind der Kernel und die skalare Bias.\n",
    "- Beim Trainieren von Modellen, die auf Faltungsschichten basieren, werden die Kernel normalerweise zufällig initialisiert,\n",
    "genau wie bei einer voll verknüpften Schicht.\n",
    "\n",
    "Wir sind nun bereit, **eine zweidimensionale Faltungsschicht zu implementieren**\n",
    "basierend auf der oben definierten Funktion `corr2d`.\n",
    "\n",
    "In der `__init__` Konstruktorfunktion, deklarieren wir `weight` und `bias` als die beiden Modellparameter.\n",
    "Die Vorwärtsvermehrungsfunktion ruft die Funktion `corr2d` auf und fügt den Bias hinzu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 10,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        \"\"\"\n",
    "        Custom 2D convolution layer (without built-in nn.Conv2d).\n",
    "        Parameters:\n",
    "        - kernel_size (tuple): Shape of the convolution kernel (height, width).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Define the kernel (weight) and bias explicitly\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))  # Learnable weight\n",
    "        self.bias = nn.Parameter(torch.randn(1))  # Learnable bias\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass using manual 2D cross-correlation.\n",
    "        Parameters:\n",
    "        - X (torch.Tensor): Input tensor (image).\n",
    "        Returns:\n",
    "        - torch.Tensor: Output after convolution.\n",
    "        \"\"\"\n",
    "        return self.corr2d(X, self.weight) + self.bias\n",
    "\n",
    "    def corr2d(self, X, K):\n",
    "        \"\"\"Compute 2D cross-correlation (convolution without flipping).\"\"\"\n",
    "        h, w = K.shape\n",
    "        Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))  # Output size\n",
    "\n",
    "        for i in range(Y.shape[0]):\n",
    "            for j in range(Y.shape[1]):\n",
    "                Y[i, j] = torch.sum(X[i:i + h, j:j + w] * K)\n",
    "\n",
    "        return Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 11,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In $h \\times w$-Faltung oder einem $h \\times w$-Faltungskern, sind die Höhe und die Breite des Faltungskerns $h$ bzw. $w$.\n",
    "- Wir bezeichnen auch eine Faltungsschicht mit einem $h \\times w$ Faltungskern einfach als $h \\times w$-Faltungsschicht.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objektkanten-Erkennung in Bildern\n",
    "\n",
    "Nehmen wir uns einen Moment Zeit, um eine einfache Anwendung einer Faltungsschicht zu analysieren:\n",
    "**Erkennung des Kante eines Objekts in einem Bild** indem wir den Ort der Pixelveränderung finden.\n",
    "\n",
    "Zunächst konstruieren wir ein \"Bild\" aus $6 \\times 8$ Pixeln.\n",
    "Die mittleren vier Spalten sind schwarz (0) und der Rest ist weiss (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 13,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a 6x8 tensor filled with ones\n",
    "X = torch.ones((6, 8))\n",
    "\n",
    "# Set columns 2 to 5 to zero (equivalent to X[:, 2:6] in TensorFlow)\n",
    "X[:, 2:6] = 0\n",
    "\n",
    "# Print the result\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 14,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Als nächstes konstruieren wir einen Kernel `K` mit einer Höhe von 1 und einer Breite von 2.\n",
    "- Wenn wir die Kreuzkorrelationsoperation mit der Eingabe durchführen, wenn die horizontal benachbarten Elemente gleich sind,\n",
    "andernfalls ist die Ausgabe ungleich Null.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 15,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define the horizontal kernel\n",
    "K_horizontal = torch.tensor([[-1.0, -1.0], \n",
    "                             [+1.0, +1.0]])\n",
    "\n",
    "# Define the vertical kernel\n",
    "K_vertical = torch.tensor([[+1.0, -1.0], \n",
    "                           [+1.0, -1.0]])\n",
    "\n",
    "# Define the 45-degree diagonal kernel\n",
    "K_45 = torch.tensor([[+1.0, 0.0], \n",
    "                     [0.0, -1.0]])\n",
    "\n",
    "# Print the tensors\n",
    "print(\"K_horizontal:\\n\", K_horizontal)\n",
    "print(\"\\nK_vertical:\\n\", K_vertical)\n",
    "print(\"\\nK_45:\\n\", K_45)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wir sind bereit, die Kreuzkorrelationsoperation durchzuführen\n",
    "mit den Argumenten \"X\" (unsere Eingabe) und \"K\" (unser Kern).\n",
    "Wie Sie sehen können, **wir erkennen 1 für die Kante von Weiss nach Schwarz\n",
    "und -1 für die Kante von Schwarz nach Weiss.**\n",
    "\n",
    "Alle anderen Ausgaben haben den Wert 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 17,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "Y = corr2d(X, K_vertical)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = corr2d(X, K_horizontal)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 18,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Wir können nun den Kernel auf das transponierte Bild anwenden.\n",
    "- Wie erwartet, verschwindet er. **Der Kernel \"K\" erkennt nur vertikale Kanten**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 19,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "corr2d(X.T, K_horizontal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 28,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kreuzkorrelation und Faltung\n",
    "\n",
    "Um das Ergebnis der strikten *Faltungsoperation* zu erhalten, müssen wir nur den zweidimensionalen Kernel-Tensor horizontal und vertikal spiegeln und dann die *Kreuzkorrelation* mit dem Eingabetensor durchführen.\n",
    "\n",
    "- Es ist bemerkenswert, dass beim Deep Learning die Kernel aus den Daten gelernt werden, die Ausgaben von Faltungsschichten unberührt bleiben unabhängig davon, ob diese Schichten entweder die strengen Faltungsoperationen oder die Kreuzkorrelationsoperationen durchführen.\n",
    "\n",
    "- Im Einklang mit der Standardterminologie der Deep-Learning-Literatur bezeichnen wir die Kreuzkorrelationsoperation weiterhin als als Faltung bezeichnen, auch wenn sie streng genommen etwas anderes ist.\n",
    "\n",
    "- Ausserdem verwenden wir den Begriff *Element*, um uns auf einen Eintrag (oder eine Komponente) eines beliebigen Tensors, der eine Schichtdarstellung oder einen Faltungskern darstellt.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Merkmalskarte (feature map) und rezeptives Feld\n",
    "\n",
    "Die Ausgabe einer Faltungsschicht wird manchmal als **Feature Map** bezeichnet, da sie als\n",
    "eine gelernte Repräsentation (Merkmal) in den räumlichen Dimensionen (z.B. Breite und Höhe) betrachtet werden kann, welche an die nachfolgende Schicht weitergeben wird.\n",
    "\n",
    "- Das *rezeptive Feld* (receptive field) eines CNNs besteht aus allen Elementen (aus allen vorhergehenden Schichten), die die Berechnung von $x$ während der Vorwärtspropagation beeinflussen können beeinflussen können.\n",
    "- Das rezeptive Feld kann grösser sein kann als die tatsächliche Grösse der Eingabe.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lassen Sie uns weiterhin das obige Besipiel verwenden, um das rezeptive Feld zu erklären.\n",
    "\n",
    "- Mit dem $2 \\times 2$ Faltungs-Kernel, besteht das rezeptive Feld des schattierten Ausgangselements (mit dem Wert $19$) die vier Elemente im schattierten Teil der Eingabe.\n",
    "- Bezeichnen wir nun die $2 \\times 2$ Ausgabe als $\\mathbf{Y}$ und betrachten ein tieferes CNN mit einer zusätzlichen $2 \\times 2$ Faltungsschicht, die $\\mathbf{Y}$ als seine Eingabe nimmt und ein einzelnes Element $z$ ausgibt.\n",
    "- In diesem Fall das rezeptive Feld von $z$ auf $\\mathbf{Y}$ alle vier Elemente von $\\mathbf{Y}$ ein, während das rezeptive Feld auf dem Eingang alle neun Eingangselemente umfasst.\n",
    "\n",
    "Folglich, wenn ein Element in einer Merkmalskarte ein grösseres rezeptives Feld benötigt\n",
    "um Eingangsmerkmale in einem grösseren Bereich zu erkennen, können wir ein tieferes Netz aufbauen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "* Die Kernberechnung einer zweidimensionalen Faltungsschicht ist eine zweidimensionale Kreuzkorrelationsoperation. In ihrer einfachsten Form führt sie eine Kreuzkorrelationsoperation an den zweidimensionalen Eingabedaten und dem Kernel durch und fügt dann einen Bias (Offset) hinzu.\n",
    "* Wir können einen Kernel entwerfen, um Kanten in Bildern zu erkennen.\n",
    "* Wir können die Parameter des Kernels aus den Daten lernen.\n",
    "* Mit Kerneln, die aus Daten gelernt wurden, bleiben die Ausgaben von Faltungsschichten unabhängig von den durchgeführten Operationen dieser Schichten (entweder strenge Faltung oder Kreuzkorrelation) unberührt.\n",
    "* Wenn ein Element in einer Merkmalskarte ein grösseres rezeptives Feld benötigt, um breitere Merkmale in der Eingabe zu erkennen, kann ein tieferes Netz in Betracht gezogen werden.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Übungen (optional)\n",
    "\n",
    "1. Konstruieren Sie ein Bild `X` mit diagonalen Kanten.\n",
    "    - A. Was passiert, wenn man den Kernel `K` aus diesem Abschnitt darauf anwendet?\n",
    "    - B. Was geschieht, wenn man `X` transponiert?\n",
    "    - C. Was passiert, wenn man `K` transponiert?\n",
    "2. Welche Fehlermeldung erhalten Sie, wenn Sie versuchen, den Gradienten für die Klasse \"Conv2D\", die wir erstellt haben, automatisch zu finden?\n",
    "3. Wie stellt man eine Kreuzkorrelationsoperation als Matrixmultiplikation dar, indem man den Eingabe- und den Kerneltensor ändert?\n",
    "4. Entwerfen Sie einige Kernel manuell.\n",
    "    - A. Wie sieht die Form eines Kernels für die zweite Ableitung aus?\n",
    "    - B. Wie lautet der Kernel für ein Integral?\n",
    "    - C. Wie groß muss ein Kernel mindestens sein, um eine Ableitung vom Grad $d$ zu erhalten?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
