{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN05/5.5-Channels.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiple Input and Multiple Output Channels\n",
    "\n",
    "\n",
    "- Farbbilder haben die Standard-RGB-Kanäle, um den Anteil von Rot, Grün und Blau anzugeben.\n",
    "- Bis jetzt haben wir alle unsere numerischen Beispiele vereinfacht, indem wir nur mit einem einzigen Eingabe- und einem einzigen Ausgabekanal gearbeitet haben.\n",
    "- Dies hat es uns ermöglicht, unsere Eingänge, Faltungskerne, und Ausgänge jeweils als zweidimensionale Tensoren zu betrachten.\n",
    "\n",
    "Wenn wir Kanäle in den Mix einbeziehen, werden unsere Eingaben und versteckten Repräsentationen\n",
    "zu dreidimensionalen Tensoren. \n",
    "\n",
    "Zum Beispiel hat jedes **RGB-Eingabebild die Form $3\\times h\\times w$.** Wir bezeichnen diese Achse mit einer Grösse von 3 als die *Kanaldimension* (*channel dimension*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mehrere Eingangskanäle\n",
    "\n",
    "- Wenn die Eingabedaten mehrere Kanäle enthalten, müssen wir einen Faltungs-Kernel mit der gleichen Anzahl von Eingangskanälen wie die Eingabedaten konstruieren, damit er eine Kreuzkorrelation mit den Eingabedaten durchführen kann.\n",
    "- Angenommen, die Anzahl der Kanäle für die Eingabedaten ist $c_i$, dann muss die Anzahl der Eingangskanäle des Faltungskerns ebenfalls $c_i$ betragen.\n",
    "- Wenn die Fensterform unseres Faltungskerns $k_h\\times k_w$ ist, dann können wir, wenn $c_i=1$ ist, unseren Faltungs-Kernel als einen zweidimensionalen Tensor der Form $k_h\\times k_w$ betrachten.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wenn jedoch $c_i>1$, brauchen wir einen Kernel der für *jeden* Eingangskanal einen Tensor der Form $k_h\\times k_w$ enthält. Die Verkettung dieser $c_i$-Tensoren zusammen ergibt einen Faltungs-Kernel der Form $c_i\\times k_h\\times k_w$.\n",
    "\n",
    "**Da der Eingang und der Faltungskern jeweils $c_i$ Kanäle haben, können wir für jeden Kanal eine Kreuzkorrelation\n",
    "auf dem 2D Tensor der Eingabe und dem 2D Tensor des Faltungskerns durchführen, wobei die $c_i$ Ergebnisse addiert werden (Summierung über die Kanäle), um einen 2D Tensor zu erhalten.**\n",
    "\n",
    "Dies ist das Ergebnis einer zweidimensionalen Kreuzkorrelation zwischen einem Mehrkanaleingang und\n",
    "einem Faltungs-Kernel mit mehreren Eingangskanälen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In der nächsten Abbildung zeigen wir ein Beispiel\n",
    "für eine zweidimensionale Kreuzkorrelation mit zwei Eingangskanälen.\n",
    "Die schattierten Bereiche sind das erste Ausgabeelement sowie die Eingabe- und Kernel-Tensorelemente, die für die Ausgabeberechnung verwendet werden: $(1\\cdot 1+2\\cdot2+4\\cdot3+5\\cdot4)+(0\\cdot0+1\\cdot1+3\\cdot2+4\\cdot3)=56$.\n",
    "\n",
    "<img src=\"Bilder/conv-multi-in.svg\" width=\"440\" height=\"340\" align=\"center\"/>\n",
    "\n",
    "Um sicherzustellen, dass wir wirklich verstehen, was hier vor sich geht,\n",
    "können wir **Kreuzkorrelationsoperationen mit mehreren Eingangskanälen** selbst durchführen.\n",
    "Beachten Sie, dass wir lediglich eine Kreuzkorrelationsoperation pro Kanal durchführen und dann die Ergebnisse addieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 4,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def corr2d(X, K):\n",
    "    \"\"\"Compute 2D cross-correlation (convolution without flipping).\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))  # Output size\n",
    "\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = torch.sum(X[i:i + h, j:j + w] * K)\n",
    "\n",
    "    return Y\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    \"\"\"\n",
    "    Compute cross-correlation with multiple input channels.\n",
    "\n",
    "    Parameters:\n",
    "    - X (torch.Tensor): Multi-channel input tensor (C_in, H, W)\n",
    "    - K (torch.Tensor): Multi-channel kernel (C_in, kH, kW)\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Output after summing over all channels.\n",
    "    \"\"\"\n",
    "    # Compute the sum of 2D correlations over all input channels\n",
    "    return torch.stack([corr2d(x, k) for x, k in zip(X, K)], dim=0).sum(dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 5,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Wir können den Eingabe-Tensor `X` und den Kernel-Tensor `K` konstruieren\n",
    "entsprechend den Werten in obiger Figur zu konstruieren, um **die Ausgabe** der Kreuzkorrelationsoperation zu validieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 6,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "# Define multi-channel input tensor X (2 input channels, 3x3)\n",
    "X = torch.tensor([[[0.0, 1.0, 2.0], \n",
    "                   [3.0, 4.0, 5.0], \n",
    "                   [6.0, 7.0, 8.0]],\n",
    "\n",
    "                  [[1.0, 2.0, 3.0], \n",
    "                   [4.0, 5.0, 6.0], \n",
    "                   [7.0, 8.0, 9.0]]])  # Shape: (2, 3, 3)\n",
    "\n",
    "# Define kernel tensor K (2 input channels, 2x2 kernel)\n",
    "K = torch.tensor([[[0.0, 1.0], \n",
    "                   [2.0, 3.0]],\n",
    "\n",
    "                  [[1.0, 2.0], \n",
    "                   [3.0, 4.0]]])  # Shape: (2, 2, 2)\n",
    "\n",
    "# Perform cross-correlation\n",
    "output = corr2d_multi_in(X, K)\n",
    "\n",
    "# Print the result\n",
    "print(\"Output:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 7,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mehrere Ausgangskanäle\n",
    "\n",
    "- Unabhängig von der Anzahl der Eingangskanäle, hatten wir immer bisher nur einen Ausgangskanal.\n",
    "- In den gängigsten Architekturen neuronaler Netze, wird die Kanaldimension je höher wir im neuronalen Netz aufsteigen in der Regel erhöht. Man gewinnt **Kanaltiefe, und reduziert gleichzeitig die räumliche Auflösung durch Donwsampling**, je weiter wir im Netz aufsteigen.\n",
    "- Intuitiv könnte man sich vorstellen, dass jeder Kanal auf eine andere Gruppe von Merkmalen reagiert.\n",
    "- Die Realität ist etwas komplizierter, da die Repräsentationen nicht unabhängig voneinander gelernt werden, sondern vielmehr so optimiert werden, dass sie gemeinsam nützlich sind.\n",
    "- Es kann also sein, dass nicht ein einzelner Kanal einen Kantendetektor erlernt, sondern dass eine bestimmte Richtung im Kanalraum der Erkennung von Kanten entspricht.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bezeichnen Sie mit $c_i$ und $c_o$ die Anzahl der Eingabe- bzw. Ausgabekanäle, und lassen Sie $k_h$ und $k_w$ die Höhe und Breite des Kernels sein.\n",
    "- Um eine Ausgabe mit mehreren Kanälen zu erhalten, können wir einen Kernel-Tensor der Form $c_i\\times k_h\\times k_w$ für *jeden* Ausgabekanal erstellen.\n",
    "- Wir konkatenieren sie auf der Dimension des Ausgangskanals, so dass die Form des Faltungskerns\n",
    "$c_o\\times c_i\\times k_h\\times k_w$ ist.\n",
    "\n",
    "**Bei Kreuzkorrelationsoperationen, wird das Ergebnis für jeden Ausgangskanal aus dem Faltungs-Kernel berechnet, der diesem Ausgangskanal entspricht und nimmt Eingaben von allen Kanälen im Eingabetensor entgegen.**\n",
    "\n",
    "Wir implementieren eine Kreuzkorrelationsfunktion\n",
    "zur **Berechnung der Ausgabe mehrerer Kanäle** wie unten gezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 8,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # Iterate through the 0th dimension of `K`, and each time, perform\n",
    "    # cross-correlation operations with input `X`. All of the results are\n",
    "    # stacked together\n",
    "    return tf.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 9,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Wir konstruieren einen Faltungs-Kernel mit 3 Ausgangskanälen\n",
    "durch Verkettung des Kernel-Tensors `K` mit `K+1`\n",
    "(plus eins für jedes Element in `K`) und `K+2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 10,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "K = tf.stack((K, K + 1, K + 2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 11,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Im Folgenden führen wir die Kreuzkorrelation auf den Eingabetensor `X` mit dem Kernel-Tensor `K` aus.\n",
    "Die Ausgabe enthält nun 3 Kanäle. \n",
    "\n",
    "Das Ergebnis des ersten Kanals ist konsistent mit dem Ergebnis des vorherigen Eingangstensors `X`\n",
    "und dem Multi-Input-Single-Output-Kernel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 12,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
