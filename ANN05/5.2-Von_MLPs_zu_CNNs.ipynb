{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN05/5.2-Von_MLPs_zu_CNNs.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Von MLPs zu CNNs\n",
    "\n",
    "\n",
    "Die Modelle, die wir bisher diskutiert haben sind valide Optionen, wenn wir es mit **tabellarischen Daten** zu tun haben.\n",
    "- Mit tabellarisch meinen wir, dass die Daten aus aus Zeilen, die den Beispielen entsprechen und Spalten, die den Merkmalen entsprechen (tidy data).\n",
    "- Bei tabellarischen Daten gehen wir davon aus, dass die gesuchten Muster **Wechselwirkungen zwischen den Merkmalen** darstellen, aber wir gehen nicht von einer Struktur *a priori* aus darüber an, wie die Merkmale interagieren.\n",
    "- Momentan fehlt uns das Wissen für die Konstruktion ausgefeilterer Architekturen. In diesen Fällen kann  ein **MLP** das Beste sein, was wir tun können. Doch bei hochdimensionalen Wahrnehmungsdaten können solche strukturlosen Netze unhandlich oder undurchführbar werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Ein Beispiel:** Nehmen Sie an, wir sammeln einen annotierten Datensatz von Ein-Megapixel-Fotos von Katzen und Hunden und möchten mit diesen Daten einen MLP-Klassifizierer bauen. \n",
    "- Das bedeutet, dass jede Eingabe in das Netz eine Million Dimensionen hat. Selbst eine aggressive Reduzierung auf eintausend versteckte Dimensionen würde eine **voll vernetzte Schicht erfordern mit $10^6 \\times 10^3 = 10^9$ Parametern !** \n",
    "- Es sei denn, wir haben viele GPUs, ein Talent für verteilte Optimierung, und eine außergewöhnliche Menge an Geduld, kann sich das Lernen der Parameter dieses Netzes sich als undurchführbar erweisen.\n",
    "\n",
    "Und doch sind heute sowohl Menschen als auch Computer in der Lage in der Lage, Katzen und Hunde recht gut zu unterscheiden,\n",
    "was scheinbar im Widerspruch zu diesen Intuitionen steht. Das liegt daran, dass Bilder eine reichhaltige Struktur aufweisen\n",
    "die sowohl Menschen als auch von und maschinelle Lernmodelle gleichermaßen nutzen können.\n",
    "Faltungsneuronale Netze (CNNs) sind eine kreativer Weg, den das maschinelle Lernen eingeschlagen hat, um einige der bekannten **Strukturen in natürlichen Bildern** zu nutzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Invarianz\n",
    "\n",
    "- Stellen Sie sich vor, Sie möchten ein Objekt in einem Bild erkennen.\n",
    "- Es scheint vernünftig, dass jede Methode, die wir zur Erkennung von Objekten verwenden, sich nicht zu sehr um die genauen Position des Objekts im Bild kümmert (**Translationsinvarianz**).\n",
    "- Im Idealfall sollte unser System dieses Wissen ausnutzen. Schweine fliegen normalerweise nicht und Flugzeuge schwimmen normalerweise nicht. Nichtsdestotrotz sollten wir ein Schwein erkennen, wenn es am oberen Rand des Bildes erscheint.\n",
    "\n",
    "Hier können wir uns ein wenig vom Kinderspiel \"Wo ist Waldo?\" inspirieren lassen. \n",
    "\n",
    "Das Spiel besteht aus einer Reihe von chaotischen Szenen, die vor Aktivitäten strotzen. Waldo taucht irgendwo in jeder Szene auf, typischerweise lauert er an einem unwahrscheinlichen Ort. Das Ziel des Lesers ist es, ihn zu finden.\n",
    "Trotz seines charakteristischen Outfits, kann dies erstaunlich schwierig sein, aufgrund der großen Anzahl von Ablenkungen.\n",
    "Doch *wie Waldo aussieht* hängt nicht davon ab, *wo sich Waldo befindet*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wir könnten das Bild mit einem Waldo-Detektor durchforsten der jedem Fleck eine Punktzahl zuweisen könnte,\n",
    "der die Wahrscheinlichkeit angibt, dass der Fleck Waldo enthält.\n",
    "CNNs systematisieren diese Idee der *Translationsinvarianz*, und nutzen sie, um nützliche Darstellungen mit weniger Parametern zu lernen.\n",
    "\n",
    "<img src=\"Bilder/where-wally-walker-books.jpg\" width=\"640\" height=\"440\" align=\"center\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Anforderungen: Translationsinvarianz und Lokalität\n",
    "\n",
    "Wir können diese Intuitionen nun konkreter machen, indem wir einige Anforderungen aufzählen, die unser Design leiten sollen\n",
    "eines neuronalen Netzes, das für die Computer Vision geeignet ist:\n",
    "\n",
    "1. In den ersten Schichten sollte unser Netz ähnlich auf denselben Fleck reagieren, unabhängig davon, wo er im Bild erscheint. Dieses Prinzip wird **Translationsinvarianz** genannt.\n",
    "2. Die frühesten Schichten des Netzes sollten sich auf lokale Regionen konzentrieren, ohne Rücksicht auf den Inhalt des Bildes in entfernten Regionen. Dies ist das Prinzip der **Lokalität**. Letztendlich können diese lokalen Repräsentationen aggregiert werden, um Vorhersagen auf der gesamten Bildebene zu treffen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Beschränkung des MLP\n",
    "\n",
    "Für den Anfang können wir einen MLP betrachten mit zweidimensionalen Bildern $\\mathbf{X}$ als Eingaben und ihren unmittelbaren versteckten Repräsentationen $\\mathbf{H}$, die in der Mathematik als Matrizen und im Code als zweidimensionale Tensoren dargestellt werden, wobei sowohl $\\mathbf{X}$ als auch $\\mathbf{H}$ die gleiche Form haben.\n",
    "\n",
    "Wir stellen uns nun vor, dass nicht nur die Eingaben, sondern sondern auch die verborgenen Repräsentationen als räumlich strukturiert.\n",
    "\n",
    "Bezeichnen $[\\mathbf{X}]_{i, j}$ und $[\\mathbf{H}]_{i, j}$ die Pixel an der Stelle ($i$, $j$)\n",
    "im Eingabebild bzw. in der versteckten Darstellung. Damit jede der versteckten Einheiten\n",
    "Input von jedem der Eingangspixel erhält, würden wir von der Verwendung von Gewichtsmatrizen zur Darstellung unserer Parameter\n",
    "als Gewichtstensoren vierter Ordnung $\\mathsf{W}$ darstellen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nehmen wir an, dass $\\mathbf{U}$ Offsets (bias terms) enthält,\n",
    "könnten wir die voll verknüpfte Schicht formal ausdrücken als\n",
    "\n",
    "$$\\begin{aligned} \\left[\\mathbf{H}\\right]_{i, j} &= [\\mathbf{U}]_{i, j} + \\sum_k \\sum_l[\\mathsf{W}]_{i, j, k, l}  [\\mathbf{X}]_{k, l}\\\\ &= [\\mathbf{U}]_{i, j} +\n",
    "\\sum_a \\sum_b [\\mathsf{V}]_{i, j, a, b} [\\mathbf{X}]_{i+a, j+b}.\\end{aligned},$$\n",
    "\n",
    "wobei der Wechsel von $\\mathsf{W}$ zu $\\mathsf{V}$ vorerst rein kosmetisch ist, da es eine Eins-zu-Eins-Entsprechung\n",
    "zwischen den Koeffizienten der beiden Tensoren vierter Ordnung besteht.\n",
    "\n",
    "Wir indexieren einfach die Indizes $(k, l)$ neu so dass $k = i+a$ und $l = j+b$.\n",
    "Mit anderen Worten: Wir setzen $[\\mathsf{V}]_{i, j, a, b} = [\\mathsf{W}]_{i, j, i+a, j+b}$.\n",
    "Die Indizes $a$ und $b$ laufen sowohl über positive als auch negative Offsets,\n",
    "und decken das gesamte Bild ab.\n",
    "Für jede beliebige Stelle ($i$, $j$) in der verborgenen Darstellung $[\\mathbf{H}]_{i, j}$,\n",
    "berechnen wir seinen Wert durch Summation über die Pixel in $x$,\n",
    "die um $(i, j)$ zentriert und mit $[\\mathsf{V}]_{i, j, a, b}$ gewichtet sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Translationsinvarianz\n",
    "\n",
    "Nun wollen wir uns auf das erste Prinzip berufen, das oben aufgestellt wurde: die Translationsinvarianz.\n",
    "Dies impliziert, dass eine Verschiebung der Eingabe $\\mathbf{X}$ einfach zu einer Verschiebung in der verborgenen Darstellung $\\mathbf{H}$ führen sollte.\n",
    "Dies ist nur möglich, wenn $\\mathsf{V}$ und $\\mathbf{U}$ tatsächlich nicht von $(i, j)$ abhängen,\n",
    "d.h. wir haben $[\\mathsf{V}]_{i, j, a, b} = [\\mathbf{V}]_{a, b}$ und $\\mathbf{U}$ ist eine Konstante, sagen wir $u$.\n",
    "Daher können wir die Definition für $\\mathbf{H}$ vereinfachen:\n",
    "\n",
    "$$[\\mathbf{H}]_{i, j} = u + \\sum_a\\sum_b [\\mathbf{V}]_{a, b} [\\mathbf{X}]_{i+a, j+b}.$$\n",
    "\n",
    "\n",
    "Dies ist eine *Faltung*!\n",
    "Wir gewichten effektiv Pixel an $(i+a, j+b)$\n",
    "in der Nähe der Position $(i, j)$ mit den Koeffizienten $[\\mathbf{V}]_{a, b}$\n",
    "um den Wert $[\\mathbf{H}]_{i, j}$ zu erhalten.\n",
    "Man beachte, dass $[\\mathbf{V}]_{a, b}$ viel weniger Koeffizienten benötigt als $[\\mathsf{V}]_{i, j, a, b}$, da es\n",
    "nicht mehr von der Position innerhalb des Bildes abhängt.\n",
    "Wir haben bedeutende Fortschritte gemacht!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lokalität\n",
    "\n",
    "Nun wollen wir uns auf den zweiten Grundsatz berufen: die Lokalität.\n",
    "Wie oben begründet, glauben wir, dass wir nicht nicht sehr weit vom Ort $(i, j)$ wegschauen müssen\n",
    "um relevante Informationen zu erhalten um zu beurteilen, was an $[\\mathbf{H}]_{i, j}$ vor sich geht.\n",
    "Das bedeutet, dass ausserhalb eines Bereichs $|a|> \\Delta$ oder $|b| > \\Delta$,\n",
    "wir $[\\mathbf{V}]_{a, b} = 0$ setzen sollten.\n",
    "\n",
    "Äquivalent dazu können wir $[\\mathbf{H}]_{i, j}$ umschreiben als\n",
    "\n",
    "$$[\\mathbf{H}]_{i, j} = u + \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} [\\mathbf{V}]_{a, b} [\\mathbf{X}]_{i+a, j+b}. \\tag{1}$$\n",
    "\n",
    "Beachten Sie, dass (1), kurz gesagt, eine *Faltungsschicht* ist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Faltungskerne \n",
    "\n",
    "*Konvolutionelle neuronale Netze* (CNNs) sind eine spezielle Familie von neuronalen Netzen, die Faltungsschichten enthalten.\n",
    "\n",
    "In der Deep-Learning-Forschungsgemeinschaft,  wird $\\mathbf{V}$ als *Faltungskern* oder *Filter* bezeichnet. \n",
    "\n",
    "Wenn die lokale Region klein ist, kann der Unterschied im Vergleich zu einem vollständig verbundenen Netz dramatisch sein.\n",
    "Während wir früher möglicherweise Milliarden von Parametern benötigt haben, um nur eine einzige Schicht in einem Bildverarbeitungsnetz darzustellen, brauchen wir jetzt in der Regel nur noch ein paar hundert, ohne dass sich die Dimensionalität der Eingänge der Eingaben oder der versteckten Repräsentationen.\n",
    "\n",
    "\n",
    "Der Preis für diese drastische Reduzierung der Parameter ist, dass unsere Merkmale jetzt nicht mehr übersetzungsinvariant sind\n",
    "und dass unsere Schicht nur noch lokale Informationen aufnehmen kann,\n",
    "wenn sie den Wert jeder versteckten Aktivierung bestimmt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Inductive Bias - Hypothesen des Datenmodells\n",
    "\n",
    "- Jegliches Lernen hängt davon ab, dass man eine induktive Hypothese auferlegt, wie die Daten als Modell generiert werden könneten. \n",
    "- Wenn diese Hypothese mit der Realität übereinstimmt, erhalten wir stichprobeneffiziente Modelle, die sich gut auf ungesehene Daten verallgemeinern lassen.\n",
    "- Wenn dieser induktive Bias jedoch nicht mit der Realität übereinstimmt, könnten unsere Modelle sogar Schwierigkeiten haben, sich an unsere Trainingsdaten anzupassen (z. B. wenn sich herausstellt, dass Bilder nicht translationsinvariant sind). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## \"Wo ist Waldo?\" revisited\n",
    "\n",
    "Kehren wir zu unserem Waldo-Detektor zurück und sehen wir uns an, wie dieser aussieht.\n",
    "- Die Faltungsschicht wählt Fenster mit einer bestimmten Grösse und gewichtet die Intensitäten gemäss dem Filter $\\mathsf{V}$, wie in der folgenden Abbilding gezeigt.\n",
    "- Unser Ziel könnte es sein, ein Modell zu lernen, bei dem wo immer die \"Waldoness\" am höchsten ist, wir einen Peak in den Darstellungen der verborgenen Schicht finden sollten.\n",
    "\n",
    "<img src=\"Bilder/waldo-mask.jpg\" width=\"640\" height=\"440\" align=\"center\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Kanäle (channles)\n",
    "\n",
    "Es gibt nur ein Problem mit diesem Ansatz. \n",
    "\n",
    "- Bis jetzt haben wir geflissentlich ignoriert, dass Bilder aus aus 3 Kanälen bestehen: Rot, Grün und Blau.\n",
    "- In Wirklichkeit sind Bilder keine zweidimensionalen Objekte, sondern vielmehr Tensoren dritter Ordnung, die durch eine Höhe, eine Breite und einen Kanal gekennzeichnet sind, z. B. mit der Form $1024 \\times 1024 \\times 3$ Pixel.\n",
    "- Während die ersten beiden dieser Achsen räumliche Beziehungen betreffen, kann die dritte als Zuweisung einer mehrdimensionale Darstellung zu jeder Pixelposition interpretiert werden.\n",
    "\n",
    "Wir indizieren $\\mathsf{X}$ also als $[\\mathsf{X}]_{i, j, k}$.\n",
    "\n",
    "Der Faltungsfilter muss sich entsprechend anpassen. Anstelle von $[\\mathbf{V}]_{a,b}$ haben wir nun $[\\mathsf{V}]_{a,b,c}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Da unsere Eingabe aus einem **Tensor dritter Ordnung** besteht, erweist es sich als eine gute Idee, unsere verborgenen Repräsentationen in ähnlicher Weise als Tensoren dritter Ordnung $\\mathsf{H}$ zu formulieren.\n",
    "- Mit anderen Worten: Anstatt nur eine einzige verborgene Darstellung zu haben, die jeder räumlichen Position entspricht, wollen wir einen ganzen Vektor von verborgenen Repräsentationen entsprechend jeder räumlichen Position.\n",
    "\n",
    "Man könnte sich die verborgenen Repräsentationen als eine Reihe von übereinander gestapelten zweidimensionalen Gittern (Matrizen) vorstellen. \n",
    "- Wie bei den Eingaben werden diese manchmal als *Kanäle* (**channels**) bezeichnet.\n",
    "- Manchmal werden sie auch **Merkmalskarten** genannt, da jede Schicht einen räumlichen Satz der gelernten Merkmale an die nachfolgende Schicht weitergibt. Intuitiv könnte man sich vorstellen, dass in den unteren Schichten, die näher an den Eingängen liegen, einige Kanäle auf die Erkennung von Kanten spezialisiert sind, während andere Texturen erkennen könnten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Um mehrere Kanäle sowohl in den Eingaben ($\\mathsf{X}$) als auch in den versteckten Darstellungen ($\\mathsf{H}$) zu unterstützen,\n",
    "können wir eine vierte Koordinate zu $\\mathsf{V}$ hinzufügen: $[\\mathsf{V}]_{a, b, c, d}$.\n",
    "Setzt man alles zusammen, so erhält man:\n",
    "\n",
    "$$[\\mathsf{H}]_{i,j,d} = \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} \\sum_c [\\mathsf{V}]_{a, b, c, d} [\\mathsf{X}]_{i+a, j+b, c},$$\n",
    ":eqlabel:`eq_conv-Schicht-Kanäle`\n",
    "\n",
    "wobei $d$ die Ausgangskanäle in den verborgenen Darstellungen $\\mathsf{H}$ indiziert. Die nachfolgende Faltungsschicht nimmt einen Tensor dritter Ordnung, $\\mathsf{H}$, als Eingabe.\n",
    "Allgemeiner formuliert,\n",
    ":eqref:`eq_conv-layer-channels` ist\n",
    "die Definition einer Faltungsschicht für mehrere Kanäle, wobei $\\mathsf{V}$ ein Kernel oder Filter der Schicht ist.\n",
    "\n",
    "Es gibt noch viele Operationen, die wir angehen müssen.\n",
    "Zum Beispiel müssen wir herausfinden, wie wir alle versteckten Repräsentationen\n",
    "zu einer einzigen Ausgabe kombinieren, z. B. ob es *irgendwo* im Bild einen Waldo gibt.\n",
    "Wir müssen auch entscheiden, wie wir die Dinge effizient berechnen können,\n",
    "wie man mehrere Schichten kombinieren kann,\n",
    "geeignete Aktivierungsfunktionen,\n",
    "und wie man vernünftige Designentscheidungen trifft\n",
    "um Netzwerke zu entwickeln, die in der Praxis effektiv sind.\n",
    "Diesen Fragen widmen wir uns im weiteren Verlauf des Kapitels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "* **Translationsinvarianz** in Bildern bedeutet, dass alle Bereiche eines Bildes auf die gleiche Weise behandelt werden.\n",
    "* **Lokalität** bedeutet, dass nur eine kleine Nachbarschaft von Pixeln verwendet wird, um die entsprechenden versteckten Darstellungen zu berechnen.\n",
    "* In der Bildverarbeitung benötigen Faltungsschichten in der Regel viel weniger Parameter als voll verknüpfte Schichten.\n",
    "* CNNS sind eine spezielle Familie von neuronalen Netzen, die Faltungsschichten enthalten.\n",
    "* Kanäle am Eingang und Ausgang ermöglichen es unserem Modell, mehrere Aspekte eines Bildes an jeder räumlichen Position zu erfassen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Übungen (optional)\n",
    "\n",
    "1. Nehmen Sie an, dass die Grösse des Faltungskerns $\\Delta = 0$ ist.\n",
    "   Zeigen Sie, dass in diesem Fall der Faltungskern ein MLP unabhängig für jeden Satz von Kanälen implementiert.\n",
    "2. Warum ist Translationsinvarianz vielleicht doch keine so gute Idee?\n",
    "3. Mit welchen Problemen müssen wir uns auseinandersetzen, wenn wir entscheiden, wie versteckte Repräsentationen zu behandeln sind, die den Pixelpositionen an den Rändern eines Bildes entsprechen?\n",
    "4. Beschreiben Sie eine Faltungsschicht für Audio-Daten.\n",
    "5. Glauben Sie, dass Faltungsschichten auch für Textdaten geeignet sind? Warum oder warum nicht?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
