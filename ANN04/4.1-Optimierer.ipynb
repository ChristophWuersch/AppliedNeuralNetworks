{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\"  align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN04/4.1-Optimierer.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Trainieren von Neuronalen Netzwerken\n",
    "\n",
    "- [Quelle: Sebastian Ruder](https://ruder.io/optimizing-gradient-descent/index.html#visualizationofalgorithms)\n",
    "- [Sebastian Ruder (2016): An overview of gradient descent optimisation algorithms, arXiv preprint arXiv:1609.04747](https://arxiv.org/abs/1609.04747)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Klassische Backpropagation\n",
    "\n",
    "Backpropagation ist eine der gängigsten Methoden zum Trainieren eines neuronalen Netzwerks.  Die Backpropagation wurde von Rumelhart, Hinton und Williams (1986) eingeführt und ist auch heute noch beliebt.  Programmierer trainieren häufig tiefe neuronale Netze mit Backpropagation, weil sie sehr gut skaliert, wenn sie auf grafischen Verarbeitungseinheiten (GPUs) ausgeführt wird. Um diesen Algorithmus für neuronale Netze zu verstehen, müssen wir untersuchen, wie man ihn trainiert und wie er ein Muster verarbeitet.\n",
    "\n",
    "Die klassische Backpropagation wurde erweitert und modifiziert, sodass viele verschiedene Trainingsalgorithmen entstanden sind.  In diesem Kapitel werden wir die am häufigsten verwendeten Trainingsalgorithmen für neuronale Netze besprechen. Wir beginnen mit der klassischen Backpropagation und beenden das Kapitel dann mit dem stochastischen Gradientenabstieg (SGD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Backpropagation ist die primäre Methode, mit der die Gewichte eines neuronalen Netzwerks während des Trainings bestimmt werden. Backpropagation funktioniert durch die Berechnung eines Gewichtsänderungsbetrags ($v_t$) für jedes Gewicht ($\\theta$, theata) im neuronalen Netzwerk.  Dieser Wert wird nach folgender Gleichung von jedem Gewicht subtrahiert: \n",
    "\n",
    "$$ \\theta_t = \\theta_{t-1} - v_t $$\n",
    "\n",
    "Dieser Vorgang wird für jede Iteration ($t$) wiederholt.  Wie die Gewichtsänderung berechnet wird, hängt vom Trainingsalgorithmus ab.  Die klassische Backpropagation berechnet einfach einen Gradienten ($\\nabla$, nabla) für jedes Gewicht im neuronalen Netz in Bezug auf die Fehlerfunktion ($J$) des neuronalen Netzes.  Der Gradient wird mit einer Lernrate ($\\eta$, eta) skaliert.\n",
    "\n",
    "$$ v_t = \\eta \\nabla_{\\theta_{t-1}} J(\\theta_{t-1}) $$\n",
    "\n",
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lernrate $\\eta$\n",
    "\n",
    "Die **Lernrate** $\\eta$ ist ein wichtiges Konzept für das Backpropagationstraining.  Die Einstellung der Lernrate kann komplex sein:\n",
    "\n",
    "* Eine zu niedrige Lernrate konvergiert in der Regel zu einer guten Lösung; der Prozess wird jedoch sehr langsam sein.\n",
    "* Eine zu hohe Lernrate führt entweder zu einem Totalausfall oder konvergiert zu einem höheren Fehler als eine bessere Lernrate.\n",
    "\n",
    "Gängige Werte für die Lernrate sind: 0,1, 0,01, 0,001, usw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "**Backpropagation** ist ein Typ des Gradientenabstiegs, und in vielen Texten werden diese beiden Begriffe synonym verwendet.  Gradientenabstieg bezieht sich auf die Berechnung eines Gradienten für jedes Gewicht im neuronalen Netzwerk für jedes Trainingselement. Da das neuronale Netzwerk nicht den erwarteten Wert für ein Trainingselement ausgibt, gibt der Gradient der einzelnen Gewichte einen Hinweis darauf, wie die einzelnen Gewichte geändert werden müssen, um die erwartete Ausgabe zu erzielen. Wenn das neuronale Netzwerk genau den erwarteten Wert ausgeben würde, wäre der Gradient für jede Gewichtung 0, was bedeutet, dass keine Änderung an der Gewichtung erforderlich ist.\n",
    "\n",
    "Der Gradient ist die Ableitung der Fehlerfunktion bei dem aktuellen Wert des Gewichts.  Die Fehlerfunktion misst den Abstand der Ausgabe des neuronalen Netzwerks von der erwarteten Ausgabe. Tatsächlich können wir den Gradientenabstieg verwenden, ein Prozess, bei dem der Gradientenwert jedes Gewichts noch niedrigere Werte der Fehlerfunktion erreichen kann. \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Gradient = partielle Ableitung jedes Gewichts im neuronalen Netzwerk**\n",
    "\n",
    "In Bezug auf die Fehlerfunktion ist der Gradient im Wesentlichen die partielle Ableitung jedes Gewichts im neuronalen Netzwerk.  Jedes Gewicht hat einen Gradienten, der die Steigung der Fehlerfunktion ist. Ein Gewicht ist eine Verbindung zwischen zwei Neuronen.  Durch die Berechnung des Gradienten der Fehlerfunktion kann die Trainingsmethode bestimmen, ob sie das Gewicht erhöhen oder verringern sollte. Durch diese Bestimmung wird wiederum der Fehler des neuronalen Netzwerks verringert.  Der Fehler ist die Differenz zwischen der erwarteten Ausgabe und der tatsächlichen Ausgabe des neuronalen Netzes.  Viele verschiedene Trainingsmethoden, sogenannte Propagations-Trainingsalgorithmen, verwenden Gradienten. In allen von ihnen teilt das Vorzeichen des Gradienten dem neuronalen Netz die folgenden Informationen mit:\n",
    "\n",
    "* Null-Gradient - Das Gewicht trägt nicht zum Fehler des neuronalen Netzwerks bei.\n",
    "* Negativer Gradient - Das Gewicht sollte erhöht werden, um einen geringeren Fehler zu erreichen.\n",
    "* Positiver Gradient - Das Gewicht sollte verringert werden, um einen geringeren Fehler zu erreichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Momentum Backpropagation\n",
    "\n",
    "Das Momentum fügt der Berechnung von $v_t$ einen weiteren Term hinzu:\n",
    "\n",
    "$$ v_t = \\eta \\nabla_{\\theta_{t-1}} J(\\theta_{t-1}) + \\lambda v_{t-1} $$\n",
    "\n",
    "Wie die Lernrate fügt Momentum einen weiteren Trainingsparameter hinzu, der den Effekt von Momentum skaliert.  Momentum-Backpropagation hat zwei Trainingsparameter: Lernrate ($\\eta$, eta) und Momentum ($\\lambda$, lambda).  Momentum addiert einfach den skalierten Wert der vorherigen Gewichtsänderung ($v_{t-1}$) zur aktuellen Gewichtsänderung ($v_t$).\n",
    "\n",
    "Dies hat den Effekt, dass eine zusätzliche Kraft hinter einer Richtung, in die sich ein Gewicht bewegt hat, hinzugefügt wird.  Abbildung 4.MTM zeigt, wie dies dem Gewicht erlauben könnte, einem lokalen Minima zu entkommen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Abbildung 4.MTM: Momentum**\n",
    "![Momentum](Bilder/class_5_momentum.png \"Momentum\")\n",
    "\n",
    "Ein sehr gängiger Wert für das Momentum ist 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Batch- und Online-Backpropagation\n",
    "\n",
    "Wie oft sollten die Gewichte eines neuronalen Netzes aktualisiert werden?  Es können Gradienten für ein Trainingssatzelement berechnet werden.  Diese Gradienten können auch zu Stapeln summiert werden und die Gewichte werden einmal pro Stapel aktualisiert.\n",
    "\n",
    "- **Online-Training** - Aktualisieren Sie die Gewichte basierend auf Gradienten, die für ein einzelnes Trainingssatzelement berechnet wurden.\n",
    "- **Batch Training** - Aktualisieren Sie die Gewichte basierend auf der Summe der Gradienten über alle Elemente des Trainingssatzes.\n",
    "- **Batch Size** - Aktualisiert die Gewichte basierend auf der Summe einer bestimmten Stapelgrösse von Trainingssatzelementen.\n",
    "- **Mini-Batch-Training** - Das Gleiche wie die Stapelgröße, aber mit einer sehr kleinen Stapelgrösse.  Mini-Batches sind sehr beliebt und liegen oft im Bereich von 32-64 Elementen.\n",
    "\n",
    "Da die Stapelgrösse (batch size) kleiner ist als die Grösse des kompletten Trainingssatzes, kann es mehrere Stapel benötigen, um den Trainingssatz vollständig zu durchlaufen.  \n",
    "\n",
    "* **Schritt/Iteration** - Die Anzahl der verarbeiteten Batches.\n",
    "* **Epoche** - Die Anzahl, wie oft der komplette Trainingssatz verarbeitet wurde.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Stochastischer Gradientenabstieg (SGD)\n",
    "\n",
    "Der stochastische Gradientenabstieg (stochastic gradient descent, SGD) ist derzeit einer der beliebtesten Trainingsalgorithmen für neuronale Netzwerke.  Er funktioniert sehr ähnlich wie das Batch/Mini-Batch-Training, außer dass die Batches aus einer zufälligen Menge von Trainingselementen bestehen.\n",
    "\n",
    "Dies führt zu einer sehr unregelmäßigen Fehlerkonvergenz während des Trainings, wie in Abbildung 4.SGD dargestellt.\n",
    "\n",
    "**Abbildung 4.SGD: SGD-Fehler**\n",
    "<img src=\"Bilder/sgd_var.png\" width=\"440\" height=\"240\" align=\"center\"/>\n",
    "[Quelle](https://gaurush.com/assets/docs/ece_566.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Da das neuronale Netz jedes Mal auf einer Zufallsstichprobe des kompletten Trainingssatzes trainiert wird, macht der Fehler keinen glatten Übergang nach unten.  In der Regel sinkt der Fehler jedoch.\n",
    "\n",
    "Zu den Vorteilen von SGD gehören:\n",
    "\n",
    "1. **Berechnungseffizient**.  Selbst bei einer sehr großen Trainingsmenge kann jeder Trainingsschritt relativ schnell sein.\n",
    "2. **Verringert die Überanpassung**, da in jedem Schritt nur ein Teil des Trainingssatzes bearbeitet wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Andere Techniken\n",
    "\n",
    "Ein Problem mit einfachen Backpropagation-Trainingsalgorithmen ist, dass sie sehr empfindlich auf die Lernrate und das Momentum reagieren.  Dies ist schwierig, weil:\n",
    "\n",
    "* Die Lernrate muss klein genug eingestellt werden, um ein genaues neuronales Netzwerk zu trainieren.\n",
    "* Das Momentum muss groß genug sein, um lokale Minima zu überwinden, aber klein genug, um das Training nicht zu destabilisieren.\n",
    "* Eine einzige Lernrate/ein einziges Momentum ist oft nicht gut genug für den gesamten Trainingsprozess. Es ist oft sinnvoll, die Lernrate automatisch zu verringern, wenn das Training fortschreitet.\n",
    "* Alle Gewichte teilen sich eine einzige Lernrate/einen einzigen Impuls.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Andere Trainingstechniken:\n",
    "\n",
    "* **Resilient Propagation** - Verwenden Sie nur die Größe des Gradienten und erlauben Sie jedem Neuron, mit seiner eigenen Rate zu lernen.  Keine Notwendigkeit für Lernrate/Momentum; funktioniert jedoch nur im vollen Batch-Modus.\n",
    "* **Nesterov beschleunigter Gradient** - Hilft, das Risiko der Wahl eines schlechten Mini-Batch zu mindern.\n",
    "* **Adagrad** - Ermöglicht ein automatisch abklingendes Lernraten- und Impulskonzept pro Gewicht.\n",
    "* **Adadelta** - Erweiterung von Adagrad, die versucht, die aggressive, monoton abfallende Lernrate zu reduzieren.\n",
    "**Nicht-Gradienten-Methoden** - Nicht-Gradienten-Methoden können *gelegentlich* nützlich sein, sind aber selten besser als gradientenbasierte Backpropagation-Methoden.  Dazu gehören: [Simulated Annealing](https://en.wikipedia.org/wiki/Simulated_annealing), [Genetische Algorithmen](https://en.wikipedia.org/wiki/Genetic_algorithm), [Partikelschwarm-Optimierung](https://en.wikipedia.org/wiki/Particle_swarm_optimization), [Nelder Mead](https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method), und [viele weitere](https://en.wikipedia.org/wiki/Category:Optimization_algorithms_and_methods)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ADAM Update\n",
    "\n",
    "ADAM ist der erste Trainingsalgorithmus, den Sie ausprobieren sollten.  Er ist sehr effektiv.  Kingma und Ba (2014) haben die Adam-Update-Regel eingeführt, die ihren Namen von den adaptiven Momentschätzungen ableitet, die sie verwendet. [[Cite:kingma2014adam]](https://arxiv.org/abs/1412.6980) Adam schätzt das erste (Mittelwert) und zweite (Varianz) Moment, um die Gewichtskorrekturen zu bestimmen.  Adam beginnt mit einem exponentiell abklingenden Durchschnitt der vergangenen Gradienten (m):\n",
    "\n",
    "$$ m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t $$\n",
    "\n",
    "Dieser Mittelwert erfüllt ein ähnliches Ziel wie die klassische Impulsaktualisierung; sein Wert wird jedoch automatisch auf der Grundlage des aktuellen Gradienten ($g_t$) berechnet.  Die Aktualisierungsregel berechnet dann das zweite Moment ($v_t$):\n",
    "\n",
    "$$ v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Die Werte $m_t$ und $v_t$ sind Schätzungen des ersten Moments (des Mittelwerts) bzw. des zweiten Moments (der unzentrierten Varianz) der Gradienten.  Sie werden jedoch in den ersten Trainingszyklen eine starke Verzerrung gegen Null haben.  Die Verzerrung des ersten Moments wird wie folgt korrigiert.\n",
    "\n",
    "$$ \\hat{m}_t = \\frac{m_t}{1-\\beta^t_1} $$\n",
    "\n",
    "In ähnlicher Weise wird auch das zweite Moment korrigiert:\n",
    "\n",
    "$$ \\hat{v}_t = \\frac{v_t}{1-\\beta_2^t} $$\n",
    "\n",
    "Diese verzerrungskorrigierten Schätzungen des ersten und zweiten Moments werden auf die ultimative Adam-Aktualisierungsregel angewandt, wie folgt:\n",
    "\n",
    "$$ \\theta_t = \\theta_{t-1} - \\frac{\\alpha \\cdot \\hat{m}_t}{\\sqrt{\\hat{v}_t}+\\eta} \\hat{m}_t $$\n",
    "\n",
    "Adam ist sehr tolerant gegenüber der anfänglichen Lernrate (\\alpha) und anderen Trainingsparametern. Kingma und Ba (2014) schlagen Standardwerte von 0.9 für $\\beta_1$, 0.999 für $\\beta_2$ und 10-8 für $\\eta$ vor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Methoden im Vergleich\n",
    "\n",
    "Das folgende Bild zeigt, wie jeder dieser Algorithmen trainiert (Bildnachweis: [author](Alec Radford), [where I found it](http://sebastianruder.com/optimizing-gradient-descent/index.html#visualizationofalgorithms) ):\n",
    "\n",
    "<img src=\"Bilder/contours_evaluation_optimizers.gif\" width=\"440\" height=\"240\" align=\"center\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir importieren zunächst alle notwendigen Bibliotheken für die Datenverarbeitung, Visualisierung, den Aufbau des neuronalen Netzes mit PyTorch sowie PyTorch Lightning für das Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir lesen den Datensatz aus der CSV-Datei ein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Datenvorbereitung\n",
    "# -------------------------\n",
    "# CSV einlesen (verwende den gleichen Datensatz)\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=[\"NA\", \"?\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Spalten job, area und product werden Dummies erstellt, sodass diese in das Modell als numerische Features eingehen können. Anschliessend wird die ursprüngliche Spalte entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeuge Dummies fuer 'job'\n",
    "df = pd.concat([df, pd.get_dummies(df[\"job\"], prefix=\"job\")], axis=1)\n",
    "df.drop(\"job\", axis=1, inplace=True)\n",
    "\n",
    "# Erzeuge Dummies fuer 'area'\n",
    "df = pd.concat([df, pd.get_dummies(df[\"area\"], prefix=\"area\")], axis=1)\n",
    "df.drop(\"area\", axis=1, inplace=True)\n",
    "\n",
    "# Erzeuge Dummies fuer 'product'\n",
    "df = pd.concat([df, pd.get_dummies(df[\"product\"], prefix=\"product\")], axis=1)\n",
    "df.drop(\"product\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fehlende Werte in der Spalte income werden durch den Median ersetzt. Anschliessend werden die Spalten income, aspect, save_rate und subscriptions standardisiert, um vergleichbare Wertebereiche zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fehlende Werte in 'income' mit dem Median auffuellen\n",
    "med = df[\"income\"].median()\n",
    "df[\"income\"] = df[\"income\"].fillna(med)\n",
    "\n",
    "# Standardisiere ausgewählte Spalten\n",
    "df[\"income\"] = zscore(df[\"income\"])\n",
    "df[\"aspect\"] = zscore(df[\"aspect\"])\n",
    "df[\"save_rate\"] = zscore(df[\"save_rate\"])\n",
    "df[\"subscriptions\"] = zscore(df[\"subscriptions\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Merkmale (Features) werden definiert, indem alle Spalten außer age und id verwendet werden. Die Zielvariable (age) wird separat extrahiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere Merkmale (x) und Zielvariable (y)\n",
    "x_columns = df.columns.drop(\"age\").drop(\"id\")\n",
    "x = df[x_columns].values.astype(\"float32\")\n",
    "y = df[\"age\"].values.astype(\"float32\").reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz wird mit train_test_split in Trainings- und Validierungsdaten aufgeteilt. Anschliessend werden die Daten in Torch-Tensoren konvertiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen in Trainings- und Validierungsdaten\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Konvertiere zu Torch-Tensoren\n",
    "x_train = torch.tensor(x_train)\n",
    "y_train = torch.tensor(y_train)\n",
    "x_val = torch.tensor(x_val)\n",
    "y_val = torch.tensor(y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das Training effizient zu gestalten, werden TensorDatasets und DataLoader erstellt, die die Daten in Batches bereitstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle TensorDatasets und DataLoader\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "val_ds = TensorDataset(x_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir definieren ein einfaches Regressionsmodell, das zwei versteckte Schichten (mit 25 bzw. 10 Neuronen) und eine Ausgabeschicht besitzt. Als Verlustfunktion wird der mittlere quadratische Fehler (MSELoss) verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Modell mit PyTorch Lightning\n",
    "# -------------------------\n",
    "class RegressionModel(pl.LightningModule):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1),\n",
    "        )\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird das Modell mit der entsprechenden Eingabedimension initialisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanziiere das Modell\n",
    "input_dim = x_train.shape[1]\n",
    "model = RegressionModel(input_dim=input_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der EarlyStopping-Callback überwacht den Validierungsverlust (val_loss) und stoppt das Training, wenn sich dieser über 5 aufeinanderfolgende Epochen nicht um mindestens 1e-3 verbessert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# EarlyStopping Callback\n",
    "# -------------------------\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=1e-3, patience=5, verbose=True, mode=\"min\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Training wird mit dem Trainer von PyTorch Lightning gestartet, wobei maximal 5000 Epochen angesetzt werden. Der Fortschritt wird angezeigt und der Callback wird integriert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Training\n",
    "# -------------------------\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    callbacks=[early_stop_callback],\n",
    "    logger=False,\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach dem Training werden Vorhersagen auf den Validierungsdaten erzeugt und mit den tatsächlichen Werten in einem Plot verglichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Vorhersagen und Plotten der Regression\n",
    "# -------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(x_val).squeeze().numpy()\n",
    "    y_val_np = y_val.squeeze().numpy()\n",
    "\n",
    "\n",
    "def chart_regression(pred, y, sort=True):\n",
    "    t = pd.DataFrame({\"pred\": pred, \"y\": y})\n",
    "    if sort:\n",
    "        t.sort_values(by=[\"y\"], inplace=True)\n",
    "    plt.plot(t[\"y\"].tolist(), label=\"expected\")\n",
    "    plt.plot(t[\"pred\"].tolist(), label=\"prediction\")\n",
    "    plt.xlabel(\"index\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "chart_regression(predictions, y_val_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "ger",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "ger",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
