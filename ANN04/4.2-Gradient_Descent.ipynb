{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\"  align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN04/4.2-Gradient_Descent.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# für Ausführung auf Google Colab auskommentieren und installieren\n",
    "%pip install -q -r https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/main/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient Descent\n",
    "\n",
    "\n",
    "In diesem Abschnitt werden wir die grundlegenden Konzepte des *Gradientenabstiegs* vorstellen.\n",
    "- Obwohl er beim Deep Learning nur selten direkt verwendet wird, ist ein Verständnis des Gradientenabstiegs der Schlüssel zum Verständnis der stochastischen Gradientenabstiegsalgorithmen. \n",
    "- So kann das Optimierungsproblem beispielsweise aufgrund einer zu hohen Lernrate divergieren. Dieses Phänomen kann bereits beim Gradientenabstieg beobachtet werden. Ebenso ist die Vorkonditionierung eine gängige Technik beim Gradientenabstieg, die sich auch auf fortgeschrittenere Algorithmen überträgt.\n",
    "\n",
    "Lassen Sie uns mit einem einfachen Spezialfall beginnen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Eindimensionaler Gradientenabstieg\n",
    "\n",
    "Der eindimensionale Gradientenabstieg ist ein hervorragendes Beispiel, um zu erklären, warum der Gradientenabstiegsalgorithmus den Wert der Zielfunktion verringern kann. Betrachten wir eine kontinuierlich differenzierbare reellwertige Funktion $f: \\mathbb{R} \\rightarrow \\mathbb{R}$. Unter Verwendung einer Taylor-Erweiterung erhalten wir\n",
    "\n",
    "$$f(x + \\epsilon) = f(x) + \\epsilon f'(x) + \\mathcal{O}(\\epsilon^2). \\tag{1}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Das heisst, bei der Approximation erster Ordnung ist $f(x+\\epsilon)$ durch den Funktionswert $f(x)$ und die erste Ableitung $f'(x)$ nach $x$ gegeben. Es ist nicht unvernünftig anzunehmen, dass für kleine $\\epsilon$ eine Bewegung in Richtung des negativen Gradienten den Funktionswert $f$ verringert. Der Einfachheit halber wählen wir eine feste Schrittweite $\\eta > 0$ und wählen $\\epsilon = -\\eta f'(x)$. Wenn wir dies in die obige Taylorentwicklung einsetzen, erhalten wir\n",
    "\n",
    "$$f(x - \\eta f'(x)) = f(x) - \\eta f'^2(x) + \\mathcal{O}(\\eta f'^2(x)). \\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wenn die Ableitung $f'(x) \\neq 0$ nicht verschwindet, kommen wir weiter, da $\\eta f'^2(x)>0$. Außerdem können wir $\\eta$ immer so klein wählen, dass die Terme höherer Ordnung irrelevant werden. Wir kommen also zu\n",
    "\n",
    "$$f(x - \\eta f'(x)) \\lessapprox f(x). \\tag{3}$$\n",
    "\n",
    "Das bedeutet, dass, wenn wir\n",
    "\n",
    "$$x \\leftarrow x - \\eta f'(x)$$\n",
    "\n",
    "verwenden, um $x$ zu iterieren, kann der Wert der Funktion $f(x)$ sinken. Daher wählen wir beim Gradientenabstieg zunächst einen Anfangswert $x$ und eine Konstante $\\eta > 0$ und iterieren damit kontinuierlich $x$ bis zum Erreichen der Stop-Bedingung, z.B. wenn die Grösse des Gradienten $|f'(x)|$ klein genug ist oder die Anzahl der Iterationen einen bestimmten Wert erreicht hat.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Der Einfachheit halber wählen wir die Zielfunktion $f(x)=x^2$, um zu veranschaulichen, wie man den Gradientenabstieg implementiert. Obwohl wir wissen, dass $x=0$ die Lösung zur Minimierung von $f(x)$ ist, verwenden wir diese einfache Funktion, um zu beobachten, wie sich $x$ verändert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests\n",
    "# !pip install autograd\n",
    "# !git clone https://github.com/dsgiitr/d2l-pytorch.git\n",
    "# Homepage\n",
    "# https://d2l.ai/\n",
    "\n",
    "# %pip install d2l # geht nur mit 3.11.9 python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 3,
    "slideshow": {
     "slide_type": "-"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "# pip install -U d2l\n",
    "# !pip install requests\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import d2l\n",
    "\n",
    "sys.path.insert(0, \"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 4,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2  # objective function\n",
    "\n",
    "\n",
    "def gradf(x):\n",
    "    return 2 * x  # its derivative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 5,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Als nächstes verwenden wir $x=10$ als Anfangswert und nehmen $\\eta=0.2$ an. Wenn wir den Gradientenabstieg verwenden, um $x$ 10 Mal zu iterieren, können wir sehen, dass sich der Wert von $x$ schließlich der optimalen Lösung nähert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 6,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def gd(eta):\n",
    "    x = 10\n",
    "    results = [x]\n",
    "    for i in range(10):\n",
    "        x -= eta * gradf(x)\n",
    "        results.append(x)\n",
    "    print(\"epoch 10, x:\", x)\n",
    "    return results\n",
    "\n",
    "\n",
    "res = gd(0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 7,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Der Fortschritt der Optimierung über $x$ kann wie folgt aufgezeichnet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 8,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def show_trace(res):\n",
    "    n = max(abs(min(res)), abs(max(res)))\n",
    "    f_line = np.arange(-n, n, 0.01)\n",
    "    d2l.set_figsize((3.5, 2.5))\n",
    "    d2l.plot(\n",
    "        [f_line, res],\n",
    "        [[f(x) for x in f_line], [f(x) for x in res]],\n",
    "        \"x\",\n",
    "        \"f(x)\",\n",
    "        fmts=[\"-\", \"-o\"],\n",
    "    )\n",
    "\n",
    "\n",
    "show_trace(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 9,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lernrate $\\eta$\n",
    "\n",
    "Die Lernrate $\\eta$ kann vom Entwickler des Algorithmus festgelegt werden. Wenn wir eine zu kleine Lernrate verwenden, wird $x$ sehr langsam aktualisiert, was mehr Iterationen erfordert, um eine bessere Lösung zu erhalten. Um zu zeigen, was in einem solchen Fall passiert, betrachten wir den Fortschritt bei demselben Optimierungsproblem für $\\eta = 0.05$. Wie wir sehen können, sind wir selbst nach 10 Schritten noch sehr weit von der optimalen Lösung entfernt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 10,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "show_trace(gd(0.05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 11,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Umgekehrt könnte $\\left|\\eta f'(x)\\right|$ zu gross für die Taylor-Erweiterungsformel erster Ordnung sein, wenn wir eine zu hohe Lernrate verwenden. \n",
    "- Das heisst, der Term $\\mathcal{O}(\\eta^2 f'^2(x))$ in Gleichung (2) könnte signifikant werden. \n",
    "- In diesem Fall können wir nicht garantieren, dass die Iteration von $x$ in der Lage ist, den Wert von $f(x)$ zu senken. \n",
    "\n",
    "Wenn wir z.B. die Lernrate auf $\\eta=1.1$ setzen, schwimmt $x$ über die optimale Lösung $x=0$ hinaus und divergiert allmählich.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 12,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "show_trace(gd(1.1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 13,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lokale Minima\n",
    "\n",
    "Um zu veranschaulichen, was bei nichtkonvexen Funktionen passiert, betrachten wir den Fall $f(x) = x \\cdot \\cos(cx)$ für eine Konstante $c$. Diese Funktion hat unendlich viele lokale Minima. Je nach Wahl der Lernrate und je nachdem, wie gut das Problem konditioniert ist, können wir am Ende eine von vielen Lösungen erhalten. Das folgende Beispiel veranschaulicht, wie eine (unrealistisch) hohe Lernrate zu einem schlechten lokalen Minimum führt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 14,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "c = 0.15 * math.pi\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    return x * math.cos(c * x)\n",
    "\n",
    "\n",
    "def gradf(x):\n",
    "    return math.cos(c * x) - c * x * math.sin(c * x)\n",
    "\n",
    "\n",
    "show_trace(gd(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 15,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multivariater Gradientenabstieg\n",
    "\n",
    "Nachdem wir nun ein besseres Verständnis für den univariaten Fall haben, wollen wir die Situation betrachten, in der $\\mathbf{x} = [x_1, x_2, \\ldots, x_d]^\\top$ ein Vektor ist. Das heisst, die Zielfunktion $f: \\mathbb{R}^d \\to \\mathbb{R}$ bildet Vektoren in Skalare ab. Dementsprechend ist auch ihr Gradient multivariat. Er ist ein Vektor, der aus $d$ partiellen Ableitungen besteht:\n",
    "\n",
    "$$\\nabla f(\\mathbf{x}) = \\bigg[\\frac{\\partial f(\\mathbf{x})}{\\partial x_1}, \\frac{\\partial f(\\mathbf{x})}{\\partial x_2}, \\ldots, \\frac{\\partial f(\\mathbf{x})}{\\partial x_d}\\bigg]^\\top.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Jedes partielle Ableitungselement $\\partial f(\\mathbf{x})/\\partial x_i$ im Gradienten gibt die Änderungsrate von $f$ bei $\\mathbf{x}$ in Bezug auf die Eingabe $x_i$ an. Wie zuvor im univariaten Fall können wir die entsprechende Taylor-Approximation für multivariate Funktionen verwenden, um eine Vorstellung davon zu bekommen, was wir tun sollten. Insbesondere haben wir, dass\n",
    "\n",
    "$$f(\\mathbf{x} + \\boldsymbol{\\epsilon}) = f(\\mathbf{x}) + \\mathbf{\\boldsymbol{\\epsilon}}^\\top \\nabla f(\\mathbf{x}) + \\mathcal{O}(\\|\\boldsymbol{\\epsilon}\\|^2).$$\n",
    ":eqlabel:`gd-multi-taylor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Mit anderen Worten, bis zu Termen zweiter Ordnung in $\\boldsymbol{\\epsilon}$ ist die Richtung des steilsten Abstiegs durch den negativen Gradienten $-\\nabla f(\\mathbf{x})$ gegeben. Wählt man eine geeignete Lernrate $\\eta > 0$, so erhält man den prototypischen Gradientenabstiegsalgorithmus:\n",
    "\n",
    "$$\\mathbf{x} \\leftarrow \\mathbf{x} - \\eta \\nabla f(\\mathbf{x}).$$\n",
    "\n",
    "Um zu sehen, wie sich der Algorithmus in der Praxis verhält, konstruieren wir eine Zielfunktion $f(\\mathbf{x})=x_1^2+2x_2^2$ mit einem zweidimensionalen Vektor $\\mathbf{x} = [x_1, x_2]^\\top$ als Eingabe und einem Skalar als Ausgabe. Der Gradient ist gegeben durch $\\nabla f(\\mathbf{x}) = [2x_1, 4x_2]^\\top$. Wir werden die Trajektorie von $\\mathbf{x}$ durch Gradientenabstieg von der Ausgangsposition $[-5, -2]$ aus betrachten. \n",
    "\n",
    "Zu Beginn benötigen wir zwei weitere Hilfsfunktionen. Die erste verwendet eine Aktualisierungsfunktion und wendet sie 20 Mal auf den Ausgangswert an. Die zweite Hilfsfunktion visualisiert die Trajektorie von $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 17,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Als nächstes betrachten wir den Verlauf der Optimierungsvariablen $\\mathbf{x}$ für die Lernrate $\\eta = 0.1$. Wir sehen, dass sich der Wert von $\\mathbf{x}$ nach 20 Schritten seinem Minimum bei $[0, 0]$ nähert. Der Fortschritt ist recht brav, wenn auch recht langsam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 16,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def f(x1, x2):\n",
    "    return x1**2 + 2 * x2**2  # objective\n",
    "\n",
    "\n",
    "def gradf(x1, x2):\n",
    "    return (2 * x1, 4 * x2)  # gradient\n",
    "\n",
    "\n",
    "def gd(x1, x2, s1, s2):\n",
    "    (g1, g2) = gradf(x1, x2)  # compute gradient\n",
    "    return (x1 - eta * g1, x2 - eta * g2, 0, 0)  # update variables\n",
    "\n",
    "\n",
    "eta = 0.1\n",
    "d2l.show_trace_2d(f, d2l.train_2d(gd))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 19,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adaptive Methoden\n",
    "\n",
    "Wie wir in sehen konnten, ist es schwierig, die Lernrate $\\eta$ \"genau richtig\" zu wählen. Wenn wir sie zu klein wählen, machen wir kaum Fortschritte. Wenn wir sie zu gross wählen, schwankt die Lösung und im schlimmsten Fall kann sie sogar divergieren. Was wäre, wenn wir $\\eta$ automatisch bestimmen oder überhaupt keine Lernrate mehr wählen müssten? \n",
    "Methoden zweiter Ordnung, die nicht nur den Wert und den Gradienten der Zielfunktion betrachten\n",
    "sondern auch auf ihre *Krümmung* schauen, können in diesem Fall helfen. Diese Methoden können zwar aufgrund des Rechenaufwands nicht direkt auf Deep Learning angewendet werden, sie liefern jedoch nützliche Anhaltspunkte für die Entwicklung fortgeschrittener Optimierungsalgorithmen, die viele der wünschenswerten Eigenschaften der unten beschriebenen Algorithmen nachahmen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Newtonsche Methode\n",
    "\n",
    "Bei der Überprüfung der Taylorentwicklung einer Funktion $f: \\mathbb{R}^d \\rightarrow \\mathbb{R}$ ist es nicht nötig, nach dem ersten Term aufzuhören. Tatsächlich können wir sie schreiben als\n",
    "\n",
    "$$f(\\mathbf{x} + \\boldsymbol{\\epsilon}) = f(\\mathbf{x}) + \\boldsymbol{\\epsilon}^\\top \\nabla f(\\mathbf{x}) + \\frac{1}{2} \\boldsymbol{\\epsilon}^\\top \\nabla^2 f(\\mathbf{x}) \\boldsymbol{\\epsilon} + \\mathcal{O}(\\|\\boldsymbol{\\epsilon}\\|^3). \\tag{4}$$\n",
    "\n",
    "- Um eine umständliche Notation zu vermeiden, definieren wir $\\mathbf{H} \\stackrel{\\mathrm{def}}{=} \\nabla^2 f(\\mathbf{x})$ als die Hessian von $f$, die eine $d \\times d$ Matrix ist. \n",
    "- Für kleine $d$ und einfache Probleme ist $\\mathbf{H}$ leicht zu berechnen. Für tiefe neuronale Netze hingegen kann $\\mathbf{H}$ aufgrund der Kosten für die Speicherung von $\\mathcal{O}(d^2)$-Einträgen unerschwinglich gross sein. \n",
    "- Ausserdem kann es zu teuer sein, sie mittels Backpropagation zu berechnen. Für den Moment ignorieren wir solche Überlegungen und sehen uns an, welchen Algorithmus wir erhalten würden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Schliesslich erfüllt das Minimum von $f$ die Bedingung $\\nabla f = 0$. \n",
    "Nach den Regeln des Kalküls durch Ableitung von (4) und Ignorieren von Termen höherer Ordnung erhalten wir\n",
    "\n",
    "$$\\nabla f(\\mathbf{x}) + \\mathbf{H} \\boldsymbol{\\epsilon} = 0$$\n",
    "und damit\n",
    "$$ \\boldsymbol{\\epsilon} = -\\mathbf{H}^{-1} \\nabla f(\\mathbf{x}).$$\n",
    "\n",
    "Das heisst, wir müssen die Hessematrix $\\mathbf{H}$ als Teil des Optimierungsproblems invertieren. Dies nennt man **Vorkonditionierung (preconditioning)**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Ein einfaches Beispiel: Für $f(x) = \\frac{1}{2} x^2$ haben wir $\\nabla f(x) = x$ und $\\mathbf{H} = 1$. \n",
    "- Daher erhalten wir für jedes $x$ $\\epsilon = -x$. Mit anderen Worten: ein *einziger* Schritt reicht aus, um perfekt zu konvergieren, ohne dass eine Anpassung erforderlich ist! \n",
    "- Leider hatten wir hier ein wenig Glück: Die Taylorentwicklung war exakt, da $f(x+\\epsilon)= \\frac{1}{2} x^2 + \\epsilon x + \\frac{1}{2} \\epsilon^2$. \n",
    "\n",
    "Schauen wir uns an, was bei anderen Problemen passiert.\n",
    "Bei einer konvexen hyperbolischen Kosinusfunktion $f(x) = \\cosh(cx)$ für eine Konstante $c$ ist zu erkennen, dass\n",
    "das globale Minimum bei $x=0$ nach ein paar Iterationen erreicht wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 20,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "c = 0.5\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    return math.cosh(c * x)  # objective\n",
    "\n",
    "\n",
    "def gradf(x):\n",
    "    return c * math.sinh(c * x)  # derivative\n",
    "\n",
    "\n",
    "def hessf(x):\n",
    "    return c**2 * math.cosh(c * x)  # hessian\n",
    "\n",
    "\n",
    "# hide learning rate for now\n",
    "def newton(eta=1):\n",
    "    x = 10\n",
    "    results = [x]\n",
    "    for i in range(10):\n",
    "        x -= eta * gradf(x) / hessf(x)\n",
    "        results.append(x)\n",
    "    print(\"epoch 10, x:\", x)\n",
    "    return results\n",
    "\n",
    "\n",
    "show_trace(newton())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 21
   },
   "source": [
    "Betrachten wir nun eine *nichtkonvexe* Funktion, wie $f(x) = x \\cdot \\cos(c x)$ für eine Konstante $c$. \n",
    "\n",
    "- Schliesslich ist zu beachten, dass wir bei der Newton-Methode durch die Hessematrix \"dividieren\" müssen. Das bedeutet, dass wir, wenn die zweite Ableitung *negativ* ist, in die Richtung gehen können, dass der Wert von $f$ *erhöht* wird.\n",
    "- Das ist ein fataler Fehler des Algorithmus. \n",
    "\n",
    "Schauen wir uns an, was in der Praxis passiert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 22,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "c = 0.15 * math.pi\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    return x * math.cos(c * x)\n",
    "\n",
    "\n",
    "def gradf(x):\n",
    "    return math.cos(c * x) - c * x * math.sin(c * x)\n",
    "\n",
    "\n",
    "def hessf(x):\n",
    "    return -2 * c * math.sin(c * x) - x * c**2 * math.cos(c * x)\n",
    "\n",
    "\n",
    "show_trace(newton())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "Das ging spektakulär schief. Wie können wir das beheben? \n",
    "- Eine Möglichkeit wäre, die Hessian zu \"reparieren\", indem man stattdessen ihren absoluten Wert nimmt. \n",
    "- Eine andere Strategie besteht darin, die Lernrate zu erhöhen. \n",
    "- Das scheint den Zweck zu vereiteln, aber nicht ganz. \n",
    "- Die Informationen zweiter Ordnung erlauben es uns, vorsichtig zu sein, wenn die Krümmung groß ist, und längere Schritte zu machen, wenn die Zielfunktion flacher ist. \n",
    "\n",
    "Sehen wir uns an, wie das mit einer etwas kleineren Lernrate, sagen wir $\\eta = 0.5$, funktioniert. Wie wir sehen können, haben wir einen recht effizienten Algorithmus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 24,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "show_trace(newton(0.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "* Lernraten sind wichtig. Ist sie zu gross, divergieren wir, ist sie zu klein, machen wir keine Fortschritte.\n",
    "* Gradientenabstieg kann in lokalen Minima stecken bleiben.\n",
    "* In hohen Dimensionen ist die Anpassung der Lernrate kompliziert.\n",
    "* Vorkonditionierung kann bei der Skalenanpassung helfen.\n",
    "* Die Newton-Methode ist viel schneller, wenn sie bei konvexen Problemen erst einmal richtig funktioniert.\n",
    "* Hüten Sie sich davor, die Newton-Methode ohne Anpassungen für nicht-konvexe Probleme zu verwenden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. Experimentieren Sie mit verschiedenen Lernraten und Zielfunktionen für den Gradientenabstieg.\n",
    "2. Implementieren Sie die **Liniensuche** zur Minimierung einer konvexen Funktion im Intervall $[a, b]$.\n",
    "    - A. Benötigen Sie Ableitungen für die binäre Suche, d.h. um zu entscheiden, ob $[a, (a+b)/2]$ oder $[(a+b)/2, b]$ gewählt werden soll.\n",
    "    - B. Wie schnell ist die Konvergenzrate des Algorithmus?\n",
    "    - C. Implementieren Sie den Algorithmus und wenden Sie ihn auf die Minimierung von $\\log (\\exp(x) + \\exp(-2x -3))$ an.\n",
    "3. Entwerfen Sie eine auf $\\mathbb{R}^2$ definierte Zielfunktion, bei der der Gradientenabstieg äußerst langsam ist. Tipp: Skalieren Sie verschiedene Koordinaten unterschiedlich.\n",
    "4. Implementieren Sie die leichtgewichtige Version der *Newtonschen Methode* unter Verwendung von **Vorkonditionierung**:\n",
    "    - A. Verwenden Sie die diagonale Hessematrix als Vorkonditionierer.\n",
    "    - B. Verwenden Sie die absoluten Werte anstelle der tatsächlichen (möglicherweise vorzeichenbehafteten) Werte.\n",
    "    - C. Wenden Sie dies auf das obige Problem an.\n",
    "5. Wenden Sie den obigen Algorithmus auf eine Reihe von Zielfunktionen (konvex oder nicht) an. Was passiert, wenn man die Koordinaten um $45$ Grad dreht?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
