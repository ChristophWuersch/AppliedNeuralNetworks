{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\"  align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN04/4.1-Optimierung.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "angelehnt an:\n",
    "- [Dive into Deep Learning, Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.](https://d2l.ai/index.html)\n",
    "- [Dive into Deep Learning](https://arxiv.org/abs/2106.11342)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimierung und Deep Learning\n",
    "\n",
    "In diesem Abschnitt werden wir die Beziehung zwischen Optimierung und Deep Learning sowie die Herausforderungen beim Einsatz von Optimierung beim Deep Learning diskutieren.\n",
    "- Für ein Deep-Learning-Problem wird in der Regel zunächst eine **Verlustfunktion** (loss $\\mathcal{L}$) definiert. \n",
    "- Sobald wir die Verlustfunktion kennen, können wir einen **Optimierungsalgorithmus** verwenden, um den Verlust zu minimieren.\n",
    "- In der Optimierung wird eine Verlustfunktion oft als **Zielfunktion** des Optimierungsproblems bezeichnet. Die meisten Optimierungsalgorithmen befassen sich traditionell mit der **Minimierung**. Wenn wir ein Ziel maximieren müssen, gibt es eine einfache Lösung: Drehen Sie einfach das Vorzeichen des Ziels um.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ziel der Optimierung\n",
    "\n",
    "Obwohl die Optimierung eine Möglichkeit bietet, die Verlustfunktion für Deep Learning zu minimieren, sind die Ziele der *mathematischen Optimierung* und für *Deep Learning* grundlegend verschieden.\n",
    "\n",
    "- Bei ersterem geht es in erster Linie um die *exakte Minimierung* einer Zielfunktion, während es beim Deep Learning darum geht, ein geeignetes Modell zu finden, das auf einer eine endlichen Menge an Testdaten gut generalisiert.\n",
    "- Die mathematische Optimierung minimiert eine **exakte Zielfunktion** $f(x)$, die überall innerhalb des Design-Raums ausgewertet werden kann, während die Optimierung das **empirische Risiko** (*empirical risk*) minimiert, welches anhand der Daten geschätzt werden muss.\n",
    "-  **Trainingsfehler** und **Generalisierungsfehler** sind im Allgemeinen unterschiedlich: Da die Zielfunktion des Optimierungsalgorithmus in der Regel eine Verlustfunktion ist, die auf dem Trainingsdatensatz basiert, besteht das Ziel der Optimierung darin, den Trainingsfehler zu reduzieren.\n",
    "- Das **Ziel des Deep Learning** (oder allgemeiner gesagt, der *statistischen Inferenz*) ist jedoch die den Generalisierungsfehler zu reduzieren.Um Letzteres zu erreichen, müssen wir beim Deep Learning nebst der Minimierung der Zielfunktion auf den Trainingsdaten auch auf die Reduktion der Überanpassung des Modells achten.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Risiko und empirisches Risiko\n",
    "\n",
    "Zur Veranschaulichung der oben genannten unterschiedlichen Ziele, lassen Sie uns das empirische Risiko und das Risiko definieren und visualisieren. \n",
    "\n",
    "- Das **empirische Risiko** $g(x)=\\bar{\\mathcal{L}}$ ist der durchschnittliche Verlust der Zielfunktion auf dem Trainingsdatensatz.\n",
    "- Das **Risiko** $f(x)=\\hat{\\mathcal{L}} = \\mathbb{E}_{x\\sim p(x)} [\\mathcal{L}(x)]$ ist der erwartete Verlust für die gesamte Datenpopulation, welche durch die Verteilungsfunktion $p(x)$ definiert ist.\n",
    "\n",
    "$$\\hat{\\mathcal{L}} = \\mathbb{E}_{x\\sim p(x)} [\\mathcal{L}(x)]$$\n",
    "\n",
    "Im Folgenden definieren wir zwei Funktionen:\n",
    "die Risikofunktion $f$ und die empirische Risikofunktion $g$.\n",
    "\n",
    "Nehmen wir an, dass wir nur eine endliche Menge an Trainingsdaten haben.\n",
    "Infolgedessen ist $g$ weniger glatt als $f$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 3,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install requests\n",
    "# !pip install autograd\n",
    "# !git clone https://github.com/dsgiitr/d2l-pytorch.git\n",
    "# Homepage\n",
    "# https://d2l.ai/\n",
    "\n",
    "# conda install -c conda-forge d2l\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from mpl_toolkits import mplot3d\n",
    "import torch\n",
    "import d2l\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 5,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x * np.cos(np.pi * x)\n",
    "\n",
    "\n",
    "def g(x):\n",
    "    return f(x) + 0.2 * np.cos(5 * np.pi * x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 6,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Das nachstehende Diagramm veranschaulicht, dass das Minimum des empirischen Risikos in einem Trainingsdatensatz an einer anderen Stelle liegen kann als das Minimum des Risikos (Generalisierungsfehler).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 7,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "d2l.set_figsize((4.5, 2.5))\n",
    "x = np.arange(0.5, 1.5, 0.01)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "(fig,) = d2l.plt.plot(x, f(x))\n",
    "(fig,) = d2l.plt.plot(x, g(x))\n",
    "fig.axes.annotate(\n",
    "    \"empirical risk\",\n",
    "    xy=(1.02, -1.21),\n",
    "    xytext=(0.5, -1.15),\n",
    "    arrowprops=dict(arrowstyle=\"->\"),\n",
    ")\n",
    "fig.axes.annotate(\n",
    "    \"expected risk\",\n",
    "    xy=(1.1, -1.05),\n",
    "    xytext=(0.95, -0.5),\n",
    "    arrowprops=dict(arrowstyle=\"->\"),\n",
    ")\n",
    "d2l.plt.xlabel(\"x\")\n",
    "d2l.plt.ylabel(\"risk\");\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Herausforderungen für die Optimierung beim Deep Learning\n",
    "\n",
    "In diesem Abschnitt werden wir uns speziell auf die Leistung von Optimierungsalgorithmen bei der Minimierung der Zielfunktion konzentrieren und nicht auf den Generalisierungsfehler des Modells. \n",
    "\n",
    "- Beim Deep Learning sind die meisten Zielfunktionen kompliziert und haben keine analytischen Lösungen. \n",
    "- Stattdessen müssen wir *numerische* Optimierungsalgorithmen verwenden. \n",
    "- Die Optimierungsalgorithmen die wir für Deep Learning verwenden fallen alle in diese Kategorie.\n",
    "\n",
    "Bei der Optimierung von Deep Learning gibt es viele Herausforderungen. \n",
    "Einige der lästigsten sind \n",
    "1. **lokale Minima** (local minima), \n",
    "2. **Sattelpunkte** (saddle points) und \n",
    "3. **verschwindende Gradienten** (vanishing gradients). \n",
    "\n",
    "Werfen wir einen Blick auf darauf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## 1. Lokale Extrema (Minima)\n",
    "\n",
    "Für jede beliebige Zielfunktion $f(x)$ gilt: Wenn der Wert von $f(x)$ an der Stelle $x^*$ kleiner ist als die Werte von $f(x)$ an allen anderen Punkten in der Umgebung $U$ von $x \\in U(x^*)$, dann könnte $x^*$ ein **lokales Minimum** sein.\n",
    "\n",
    "\n",
    "Wenn der Wert von $f(x)$ bei $x^*$ das Minimum der Zielfunktion über das gesamte Gebiet ist,\n",
    "dann ist $f^*=f(x^*)$ das **globale Minimum**.\n",
    "\n",
    "Ein Beispiel: Für die Funktion\n",
    "\n",
    "$$f(x) = x \\cdot \\text{cos}(\\pi x) \\text{ for } -1.0 \\leq x \\leq 2.0,$$\n",
    "\n",
    "können wir das lokale Minimum und das globale Minimum dieser Funktion approximieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 9,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "x = np.arange(-1.0, 2.0, 0.01)\n",
    "plt.figure(figsize=(6,4))\n",
    "(fig,) = d2l.plt.plot(x, f(x))\n",
    "fig.axes.annotate(\n",
    "    \"local minimum\",\n",
    "    xy=(-0.3, -0.25),\n",
    "    xytext=(-0.77, -1.0),\n",
    "    arrowprops=dict(arrowstyle=\"->\"),\n",
    ")\n",
    "fig.axes.annotate(\n",
    "    \"global minimum\",\n",
    "    xy=(1.1, -0.95),\n",
    "    xytext=(0.6, 0.8),\n",
    "    arrowprops=dict(arrowstyle=\"->\"),\n",
    ")\n",
    "d2l.plt.xlabel(\"x\")\n",
    "d2l.plt.ylabel(\"f(x)\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 10,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Die Zielfunktion von Deep-Learning-Modellen hat in der Regel **viele lokale Optima**. \n",
    "- Wenn sich die numerische Lösung eines Optimierungsproblems in der Nähe des lokalen Optimums befindet, minimiert die durch die letzte Iteration erhaltene numerische Lösung die Zielfunktion möglicherweise nur *lokal* und nicht *global*, da sich der Gradient der Lösungen der Zielfunktion dem Nullpunkt nähert oder diesen erreicht. \n",
    "- Nur ein gewisses Mass an Rauschen kann den Parameter aus dem lokalen Minimum herausbringen. Dies ist in der Tat eine der vorteilhaften Eigenschaften des *Minibatch stochastischen Gradientenabstiegs*, bei dem die natürliche Variation der Gradienten über Minibatches in der Lage ist, die Parameter aus den lokalen Minima zu verdrängen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Sattelpunkte\n",
    "\n",
    "Neben lokalen Minima sind Sattelpunkte ein weiterer Grund für das Verschwinden von Gradienten. Ein *Sattelpunkt* ist ein Ort, an dem alle Gradienten einer Funktion verschwinden, der aber weder ein globales noch ein lokales Minimum ist. \n",
    "Betrachten wir die Funktion $f(x) = x^3$. Ihre erste und zweite Ableitung verschwinden für $x=0$. Die Optimierung könnte an diesem Punkt zum Stillstand kommen, auch wenn es sich nicht um ein Minimum handelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 11,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "x = np.arange(-2.0, 2.0, 0.01)\n",
    "plt.figure(figsize=(6,4))\n",
    "(fig,) = d2l.plt.plot(x, x**3)\n",
    "fig.axes.annotate(\n",
    "    \"saddle point\", xy=(0, -0.2), xytext=(-0.52, -5.0), arrowprops=dict(arrowstyle=\"->\")\n",
    ")\n",
    "d2l.plt.xlabel(\"x\")\n",
    "d2l.plt.ylabel(\"f(x)\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 12,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sattelpunkte in höheren Dimensionen sind sogar noch heimtückischer, wie das folgende Beispiel zeigt. \n",
    "- Betrachten wir die Funktion \n",
    "$$\n",
    "f(x, y) = x^2 - y^2\n",
    "$$.\n",
    "- Sie hat ihren Sattelpunkt bei $(0, 0)$. Dies ist ein Maximum in Bezug auf $y$ und ein Minimum in Bezug auf $x$. Außerdem *sieht* er aus wie ein Sattel, daher hat diese mathematische Eigenschaft ihren Namen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 13,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "x, y = np.mgrid[-1:1:101j, -1:1:101j]\n",
    "z = x**2 - y**2\n",
    "\n",
    "ax = d2l.plt.figure(figsize=(8,5)).add_subplot(111, projection=\"3d\")\n",
    "ax.plot_wireframe(x, y, z, **{\"rstride\": 10, \"cstride\": 10})\n",
    "ax.plot([0], [0], [0], \"rx\")\n",
    "ticks = [-1, 0, 1]\n",
    "d2l.plt.xticks(ticks)\n",
    "d2l.plt.yticks(ticks)\n",
    "ax.set_zticks(ticks)\n",
    "d2l.plt.xlabel(\"x\")\n",
    "d2l.plt.ylabel(\"y\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 14,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wir nehmen an, dass die Eingabe einer Funktion ein $k$-dimensionaler Vektor ist und die\n",
    "Ausgabe der Funktion ein Skalar ist, so dass ihre hessische Matrix $k$ Eigenwerte hat.\n",
    "\n",
    "An einer Position, an der der Funktionsgradient verschwindet, könnte ein lokales Minimum, ein lokales Maximum oder ein Sattelpunkt sein!\n",
    "\n",
    "Die Eigenwerte der Hessematrix\n",
    "\n",
    "$$\\mathcal{H}_{ij}=\\frac{\\partial^2 f}{\\partial x_i \\partial x_i}$$\n",
    "\n",
    "entscheiden über die lokale Krümmung am Ort des stationären Punktes $x^*$.\n",
    "\n",
    "* Wenn die Eigenwerte der Hessematrix $\\mathcal{H}$ der Funktion an der Position des Nullgradienten alle positiv sind, liegt ein lokales Minimum der Funktion vor.\n",
    "* Wenn die Eigenwerte der Hessematrix $\\mathcal{H}$ der Funktion an der Position des Nullgradienten alle negativ sind, liegt ein lokales Maximum der Funktion vor.\n",
    "* Wenn die Eigenwerte der Hessematrix $\\mathcal{H}$ der Funktion an der Null-Gradienten-Position negativ und positiv sind, liegt ein Sattelpunkt für die Funktion vor.\n",
    "\n",
    "Bei hochdimensionalen Problemen ist die Wahrscheinlichkeit, dass zumindest *einige* der Eigenwerte negativ sind, recht hoch. Dies macht Sattelpunkte wahrscheinlicher als lokale Minima. Wir werden einige Ausnahmen von dieser Situation im nächsten Abschnitt diskutieren, wenn wir die Konvexität einführen. Kurz gesagt, konvexe Funktionen sind solche, bei denen die Eigenwerte der Hessian nie negativ sind. Leider fallen die meisten Deep-Learning-Probleme nicht in diese Kategorie. Nichtsdestotrotz ist es ein großartiges Werkzeug zur Untersuchung von Optimierungsalgorithmen.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Verschwindende Gradienten\n",
    "\n",
    "Das wahrscheinlich heimtückischste Problem ist der verschwindende Gradient.\n",
    "Erinnern Sie sich an unsere häufig verwendeten Aktivierungsfunktionen und ihre Ableitungen.\n",
    "\n",
    "- Nehmen wir zum Beispiel an, dass wir die Funktion $f(x) = \\tanh(x)$ minimieren wollen und wir bei $x = 4$ beginnen. \n",
    "- Wie wir sehen können, ist der Gradient von $f$ nahe Null.\n",
    "- Genauer gesagt ist $f'(x) = 1 - \\tanh^2(x)$ und damit $f'(4) = 0,0013$.\n",
    "- Folglich bleibt die Optimierung lange Zeit stecken, bevor wir Fortschritte machen. Dies ist einer der Gründe dafür, dass das Training von Deep-Learning-Modellen vor der Einführung der ReLU-Aktivierungsfunktion ziemlich schwierig war."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 15,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "x = np.arange(-2.0, 5.0, 0.01)\n",
    "plt.figure(figsize=(6,4))\n",
    "(fig,) = d2l.plt.plot(x, np.tanh(x))\n",
    "fig.axes.annotate(\n",
    "    \"vanishing gradient\", xy=(4, 1), xytext=(2, 0.0), arrowprops=dict(arrowstyle=\"->\")\n",
    ")\n",
    "d2l.plt.xlabel(\"x\")\n",
    "d2l.plt.ylabel(\"f(x)\");\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wie wir gesehen haben, ist die Optimierung für Deep Learning mit vielen Herausforderungen verbunden. Glücklicherweise gibt es eine robuste Reihe von Algorithmen, die gut funktionieren und auch für Anfänger einfach zu verwenden sind. Ausserdem ist es nicht unbedingt notwendig, *die* beste Lösung zu finden. Lokale Optima oder sogar Näherungslösungen sind immer noch sehr nützlich.\n",
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "* Die Minimierung des Trainingsfehlers ist *keine* Garantie dafür, dass wir den besten Parametersatz zur Minimierung des Generalisierungsfehlers finden.\n",
    "* Das Optimierungsproblem kann viele lokale Minima haben.\n",
    "* Das Problem kann noch mehr Sattelpunkte haben, da die Probleme im Allgemeinen nicht konvex sind.\n",
    "* Verschwindende Gradienten können die Optimierung zum Stillstand bringen. Oft hilft eine Neuparametrisierung des Problems.\n",
    "* Eine gute Initialisierung der Parameter kann ebenfalls von Vorteil sein.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übungen\n",
    "\n",
    "1. Betrachten Sie ein einfaches MLP mit einem einzigen `hidden layer` mit, sagen wir, $d$ Dimensionen in der versteckten Schicht und einem einzigen Ausgang. Zeigen Sie, dass es für jedes lokale Minimum mindestens $d!$ gleichwertige Lösungen gibt, die sich identisch verhalten.\n",
    "2. Welche anderen Herausforderungen bei der Optimierung von Deep Learning fallen Ihnen ein?\n",
    "3. Nehmen Sie an, Sie wollen einen (realen) Ball auf einem (realen) Sattel balancieren.\n",
    "    A. Warum ist das schwierig?\n",
    "    B. Kann man diesen Effekt auch für Optimierungsalgorithmen ausnutzen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
