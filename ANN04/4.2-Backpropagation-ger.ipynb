{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\"  align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN04/4.2-Backpropagation-ger.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Michael A. Nielsen, \"Neural Networks and Deep Learning\", Determination Press, 2015\n",
    "- Souce: http://neuralnetworksanddeeplearning.com/chap2.html\n",
    "- https://github.com/mnielsen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backpropagation - the mathematical way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Im letzten Kapitel haben wir gesehen, wie neuronale Netze ihre Gewichte und Verzerrungen mithilfe des Gradientenabstiegsalgorithmus lernen können. Es gab jedoch eine Lücke in unserer Erklärung: Wir haben nicht besprochen, **wie man den Gradienten der Kostenfunktion berechnet**. Das ist eine ziemliche Lücke! In diesem Kapitel werde ich einen schnellen Algorithmus zur Berechnung solcher Gradienten erklären, einen Algorithmus, der als Backpropagation bekannt ist.\n",
    "\n",
    "\n",
    "Was wir wollen, ist ein Algorithmus, mit dem wir Gewichte und Verzerrungen so finden können, dass die Ausgabe des Netzwerks $y(x)$ für alle Trainingseingaben $x$ angenähert wird. Um zu quantifizieren, wie gut wir dieses Ziel erreichen, definieren wir eine Kostenfunktion, **manchmal auch als Verlust- oder Zielfunktion** bezeichnet:\n",
    "$$\n",
    "\\begin{align}  C(w,b) \\equiv\n",
    "  \\frac{1}{2n} \\sum_x \\| y(x) - a\\|^2.\n",
    "\\tag{6}\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wie kann man den Gradientenabstieg zum Lernen in einem neuronalen Netz anwenden? Die Idee ist, den **Gradientenabstieg** zu verwenden, um die Gewichte $w_k$ und Offets $b_l$ zu finden, die die Kosten in Gleichung (6) minimieren. Um zu sehen, wie das funktioniert, werden wir die Aktualisierungsregel des Gradientenabstiegs neu formulieren, wobei die Gewichte und Offsets die Variablen $v_j$ ersetzen. Mit anderen Worten: Unsere \"Position\" hat jetzt die Komponenten $w_k$ und $b_l$, und der Gradientenvektor $\\nabla C$ hat die entsprechenden Komponenten $\\partial C / \\partial w_k$ und $\\partial C / \\partial b_l$. Wenn wir die Aktualisierungsregel des Gradientenabstiegs in Form dieser Komponenten ausschreiben, haben wir\n",
    "\n",
    "\\begin{align}\n",
    "  w_k & \\rightarrow & w_k' = w_k-\\eta \\frac{\\partial C}{\\partial w_k} \\tag{16}\\\\\n",
    "  b_l & \\rightarrow & b_l' = b_l-\\eta \\frac{\\partial C}{\\partial b_l}.\n",
    "\\tag{17}\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Geschichte:**\n",
    "- Der Backpropagation-Algorithmus wurde ursprünglich in den 1970er Jahren eingeführt, aber seine Bedeutung wurde erst in einem berühmten Papier [1986](http://www.nature.com/nature/journal/v323/n6088/pdf/323533a0.pdf) von [David Rumelhart](http://en.wikipedia.org/wiki/David_Rumelhart), [Geoffrey Hinton](http://www.cs.toronto.edu/~hinton/) und [Ronald Williams](http://en.wikipedia.org/wiki/Ronald_J._Williams) voll erkannt. \n",
    "- In dieser Abhandlung werden mehrere neuronale Netze beschrieben, bei denen Backpropagation viel schneller arbeitet als frühere Lernansätze, wodurch es möglich wurde, neuronale Netze zur Lösung von Problemen zu verwenden, die zuvor unlösbar waren. Heute ist der Backpropagation-Algorithmus das Arbeitspferd des Lernens in neuronalen Netzen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Partielle Ableitungen\n",
    "\n",
    "Das Herzstück der Backpropagation ist ein Ausdruck für die *partielle Ableitung* \n",
    "\n",
    "$$\\frac{\\partial C}{\\partial w}$$\n",
    "\n",
    "der Kosten- (oder Verlust-) Funktion $C$ in Bezug auf ein beliebiges Gewicht $w$ (oder einen Bias $b$) im Netzwerk. Der Ausdruck sagt uns, wie schnell sich die Kosten ändern, wenn wir die Gewichte und Verzerrungen ändern. Und obwohl der Ausdruck etwas komplex ist, hat er auch etwas Schönes an sich, da jedes Element eine natürliche, intuitive Interpretation hat. Und so ist Backpropagation nicht nur ein schneller Algorithmus zum Lernen. Er gibt uns tatsächlich detaillierte Einblicke in die Art und Weise, wie das Ändern der Gewichte und Bias-Terme das Gesamtverhalten des Netzwerks verändert. Das ist es wert, im Detail studiert zu werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aufwärmen: Ein schneller matrixbasierter Ansatz zur Berechnung der Ausgabe eines neuronalen Netzwerks\n",
    "\n",
    "Bevor wir die Backpropagation besprechen, wollen wir uns mit einem schnellen matrixbasierten Algorithmus zur Berechnung der Ausgabe eines neuronalen Netzes aufwärmen. Beginnen wir mit einer Notation, die es uns ermöglicht, auf die Gewichte im Netzwerk eindeutig zu verweisen. Wir verwenden $w_{jk}^l$, um das Gewicht für die Verbindung vom $k^{th}$ Neuron in der $(l-1)^{th}$ Schicht zum $j^{th}$ Neuron in der $l^{th}$ Schicht zu bezeichnen.\n",
    "\n",
    "**Anmerkung: $w_{jk}^{l}$ bedeutet vom Neuron $k$ in der Schicht $(l-1)$ zum Neuron $j$ in der Schicht $l$**\n",
    "\n",
    "Das folgende Diagramm zeigt also z. B. das Gewicht einer Verbindung vom vierten Neuron in der zweiten Schicht zum zweiten Neuron in der dritten Schicht eines Netzes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN04/Bilder/backprop_WeightDefinition.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Eine Eigenart der Notation ist die Anordnung der Indizes $j$ und $k$. Man könnte meinen, dass es sinnvoller ist, $j$ für das Eingangsneuron und $k$ für das Ausgangsneuron zu verwenden und nicht umgekehrt, wie es tatsächlich gemacht wird. \n",
    "\n",
    "Wir verwenden eine ähnliche Notation für die Biases und Aktivierungen des Netzwerks. Explizit verwenden wir $b_j^l$ für die Vorspannung des $j^{th}$ Neurons in der $l^{th}$ Schicht. Und wir verwenden $a^l_j$ für die Aktivierung des $j^{th}$-Neurons in der $l^{th}$-Schicht. Das folgende Diagramm zeigt Beispiele für die Verwendung dieser Notationen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN04/Bilder/backprop_activation.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Mit diesen Notationen ist die Aktivierung $a^l_j$ des $j^{th}$ Neurons in der $l^{th}$ Schicht mit den Aktivierungen in der $(l-1)^{th}$ Schicht durch die Gleichung verbunden\n",
    "\n",
    "$$\n",
    "\\begin{align} \n",
    "  a^{l}_j = \\sigma\\left( \\sum_k w^{l}_{jk} a^{l-1}_k + b^l_j \\right),\n",
    "\\tag{23}\\end{align}\n",
    "$$\n",
    "wobei die Aktivierungsfunktion durch die Sigmoidfunktion gegeben ist\n",
    "\n",
    "$$\n",
    "\\begin{align} \n",
    "  \\sigma(z) \\equiv \\frac{1}{1+e^{-z}}.\n",
    "\\tag{3}\\end{align}\n",
    "$$\n",
    "\n",
    "und wobei die Summe über alle Neuronen $k$ in der $(l-1)^{th}$ Schicht ist. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Vektorisierung**\n",
    "- Um diesen Ausdruck in eine Matrixform umzuschreiben, definieren wir eine **Gewichtsmatrix** $w^l$ für jede Schicht $l$. \n",
    "- Die Einträge der Gewichtsmatrix $w^l$ sind einfach die Gewichte, die mit der $l^{th}$ Schicht der Neuronen verbunden sind, d.h. der Eintrag in der **$j^{th}$ Zeile und $k^{th}$ Spalte ist $w^{l}_{jk}$**. \n",
    "- Auf ähnliche Weise definieren wir für jede Schicht l einen Bias-Vektor, $b^l$. Sie können sich wahrscheinlich denken, wie das funktioniert - die Komponenten des Bias-Vektors sind einfach die Werte blj, eine Komponente für jedes Neuron in der l-ten Schicht. Und schließlich definieren wir einen Aktivierungsvektor al, dessen Komponenten die Aktivierungen $a^l_j$ sind.\n",
    "- Die letzte Zutat, die wir brauchen, um (23) in eine Matrixform umzuschreiben, ist die Idee der Vektorisierung einer Funktion wie $\\sigma$. Wir haben die Vektorisierung im letzten Kapitel kurz kennengelernt, aber zur Wiederholung: Die Idee ist, dass wir eine Funktion wie $\\sigma$ auf jedes Element in einem Vektor $v$ anwenden wollen. Wir verwenden die offensichtliche Notation $\\sigma(v)$, um diese Art der elementweisen Anwendung einer Funktion zu bezeichnen.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Das heißt, die Komponenten von $\\sigma(v)$ sind einfach $\\sigma(v_j)=\\sigma(v)_j$. Wenn wir zum Beispiel die Funktion $f(x)=x^2$ haben, dann hat die vektorisierte Form von $f$ den Effekt\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  f\\left(\\left[ \\begin{array}{c} 2 \\\\\\ 3 \\end{array} \\right] \\right)\n",
    "  = \\left[ \\begin{array}{c} f(2) \\\\\\ f(3) \\end{array} \\right]\n",
    "  = \\left[ \\begin{array}{c} 4 \\\\\\ 9 \\end{array} \\right],\n",
    "\\tag{24}\\end{align}\n",
    "$$\n",
    "\n",
    "Das heisst, das vektorisierte $f$ quadriert einfach jedes Element des Vektors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Mit diesen Notationen im Hinterkopf kann Gleichung (23) in die schöne und kompakte vektorisierte Form umgeschrieben werden\n",
    "\n",
    "$$\n",
    "\\begin{align} \n",
    "  a^{l} = \\sigma(w^l a^{l-1}+b^l).\n",
    "\\tag{25}\\end{align}\n",
    "$$\n",
    "\n",
    "Mit diesem Ausdruck können wir viel globaler darüber nachdenken, wie die Aktivierungen in einer Schicht mit den Aktivierungen in der vorherigen Schicht zusammenhängen: \n",
    "- Wir wenden einfach die Gewichtsmatrix auf die Aktivierungen an, fügen dann den Bias-Vektor hinzu und wenden schließlich die Funktion $\\sigma$ an\n",
    "\n",
    "*Dieser Ausdruck ist übrigens der Grund für die bereits erwähnte Eigenart der wljk-Notation. Wenn wir j zur Indizierung des Eingangsneurons und k zur Indizierung des Ausgangsneurons verwenden würden, dann müssten wir die Gewichtsmatrix in Gleichung (25) durch die Transponierung der Gewichtsmatrix ersetzen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Mit diesen Notationen im Hinterkopf kann Gleichung (23) in die schöne und kompakte vektorisierte Form umgeschrieben werden\n",
    "\n",
    "$$\n",
    "\\begin{align} \n",
    "  a^{l} = \\sigma(w^l a^{l-1}+b^l).\n",
    "\\tag{25}\\end{align}\n",
    "$$\n",
    "\n",
    "Mit diesem Ausdruck können wir viel globaler darüber nachdenken, wie die Aktivierungen in einer Schicht mit den Aktivierungen in der vorherigen Schicht zusammenhängen: \n",
    "- Wir wenden einfach die Gewichtsmatrix auf die Aktivierungen an, fügen dann den Bias-Vektor hinzu und wenden schließlich die Funktion $\\sigma$ an\n",
    "\n",
    "*Dieser Ausdruck ist übrigens der Grund für die bereits erwähnte Eigenart der $w^l_{jk}$-Notation. Wenn wir $j$ zur Indizierung des Eingangsneurons und $k$ zur Indizierung des Ausgangsneurons verwenden würden, dann müssten wir die Gewichtsmatrix in Gleichung (25) durch die Transponierung der Gewichtsmatrix ersetzen.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Die beiden Annahmen, die wir über die Kostenfunktion benötigen\n",
    "\n",
    "Das Ziel der Backpropagation ist es, die partiellen Ableitungen $\\partial C / \\partial w$ und ∂$\\partial C / \\partial b$ der Kostenfunktion $C$ in Bezug auf ein beliebiges Gewicht $w$ oder einen Bias $b$ im Netzwerk zu berechnen. Damit Backpropagation funktioniert, müssen wir zwei Hauptannahmen über die Form der Kostenfunktion machen. Bevor wir diese Annahmen aufstellen, ist es jedoch nützlich, ein Beispiel für eine Kostenfunktion im Kopf zu haben. Wir werden die quadratische Kostenfunktion aus dem letzten Kapitel verwenden (vgl. Gleichung (6)). In der Notation des letzten Abschnitts haben die quadratischen Kosten die Form\n",
    "\n",
    "\\begin{align}\n",
    "  C = \\frac{1}{2n} \\sum_x \\|y(x)-a^L(x)\\|^2,\n",
    "\\tag{26}\\end{align}\n",
    "\n",
    "wobei: \n",
    "- $n$ die Gesamtzahl der Trainingsbeispiele ist; \n",
    "- die Summe ist über die einzelnen Trainingsbeispiele $x$; \n",
    "- $y=y(x)$ die entsprechende gewünschte Ausgabe ist; \n",
    "- $L$ bezeichnet die Anzahl der Schichten im Netz; und \n",
    "- $a^L=a^L(x)$ ist der Vektor der Aktivierungen, die vom Netz ausgegeben werden, wenn $x$ eingegeben wird.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Die **erste Annahme**, die wir brauchen, ist, dass die Kostenfunktion als Durchschnitt geschrieben werden kann\n",
    "\n",
    "$$\n",
    "C = \\frac{1}{n} \\sum_x C_x\n",
    "$$\n",
    "\n",
    "über Kostenfunktionen $C_x$ für einzelne Trainingsbeispiele $x$ geschrieben werden kann. Dies ist der Fall für die quadratische Kostenfunktion, bei der die Kosten für ein einzelnes Trainingsbeispiel $C_x = \\frac{1}{2} \\|y-a^L \\|^2$ . \n",
    "\n",
    "Der Grund, warum wir diese Annahme brauchen, ist, dass wir mit Backpropagation die partiellen Ableitungen $\\partial C_x / \\partial w$ und $\\partial C_x / \\partial b$ für ein einzelnes Trainingsbeispiel berechnen können. Wir gewinnen dann $\\partial C / \\partial w$ und $\\partial C / \\partial b$ durch Mittelung über die Trainingsbeispiele zurück. Mit dieser Annahme im Hinterkopf nehmen wir an, dass das Trainingsbeispiel $x$ fixiert wurde, und lassen den tiefgestellten Index $x$ weg und schreiben die Kosten $C_x$ als $C$. Irgendwann werden wir das $x$ wieder einfügen, aber für den Moment ist es ein notatorisches Ärgernis, das man besser implizit lässt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Die **zweite Annahme**, die wir über die Kosten machen, ist, dass sie als Funktion der Ausgaben des neuronalen Netzes geschrieben werden können:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN04/Bilder/backprop_loss.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Zum Beispiel erfüllt die quadratische Kostenfunktion diese Anforderung, da die quadratischen Kosten für ein einzelnes Trainingsbeispiel $x$ geschrieben werden können als\n",
    "\n",
    "\\begin{align}\n",
    "  C = \\frac{1}{2} \\|y-a^L\\|^2 = \\frac{1}{2} \\sum_j (y_j-a^L_j)^2,\n",
    "\\tag{27}\\end{align}\n",
    "\n",
    "und ist somit eine Funktion der Ausgangsaktivierungen. \n",
    "- Natürlich hängt diese Kostenfunktion auch von der gewünschten Ausgabe $y$ ab, und Sie fragen sich vielleicht, warum wir die Kosten nicht auch als Funktion von $y$ betrachten. \n",
    "- Erinnern Sie sich aber daran, dass das Eingabe-Trainingsbeispiel $x$ fest ist, und somit ist auch die Ausgabe $y$ ein fester Parameter. \n",
    "- Insbesondere ist es nicht etwas, das wir durch Ändern der Gewichte und Verzerrungen in irgendeiner Weise modifizieren können, d. h. es ist nicht etwas, was das neuronale Netzwerk lernt. \n",
    "- Und so macht es Sinn, $C$ als eine Funktion der Ausgangsaktivierungen $a^L$ allein zu betrachten, wobei $y$ lediglich ein Parameter ist, der hilft, diese Funktion zu definieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Das Hadamard-Produkt, $s\\odot t$\n",
    "Der Backpropagation-Algorithmus basiert auf gängigen linearen algebraischen Operationen - Dinge wie Vektoraddition, Multiplikation eines Vektors mit einer Matrix und so weiter. Aber eine der Operationen ist etwas weniger gebräuchlich. Nehmen wir insbesondere an, dass $s$ und $t$ zwei Vektoren der gleichen Dimension sind. Dann verwenden wir $s\\odot t$, um das **elementweise Produkt** der beiden Vektoren zu bezeichnen. Die Komponenten von $s\\odot t$ sind also einfach $(s\\odot t)_j=s_jt_j$. Als Beispiel,\n",
    "\n",
    "\\begin{align}\n",
    "\\left[\\begin{array}{c} 1 \\\\\\ 2 \\end{array}\\right] \n",
    "  \\odot \\left[\\begin{array}{c} 3 \\\\\\ 4 \\end{array} \\right]\n",
    "= \\left[ \\begin{array}{c} 1 \\cdot 3 \\\\\\ 2 \\cdot 4 \\end{array} \\right]\n",
    "= \\left[ \\begin{array}{c} 3 \\\\\\ 8 \\end{array} \\right].\n",
    "\\tag{28}\\end{align}\n",
    "\n",
    "Diese Art der elementweisen Multiplikation wird manchmal als **Hadamard-Produkt oder Schur-Produkt** bezeichnet. Wir werden sie als Hadamard-Produkt bezeichnen. Gute Matrixbibliotheken bieten in der Regel schnelle Implementierungen des Hadamard-Produkts, was bei der Implementierung von Backpropagation sehr nützlich ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Die vier grundlegenden Gleichungen hinter Backpropagation\n",
    "\n",
    "- Bei der Backpropagation geht es darum, zu verstehen, wie die Änderung der Gewichte und Verzerrungen in einem Netzwerk die Kostenfunktion verändert.\n",
    "- Letztendlich bedeutet dies, die partiellen Ableitungen zu berechnen\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C}{\\partial w^l_{jk}} \\quad \\text{und} \\quad \\frac{\\partial C}{ \\partial b^l_j}\n",
    "$$.\n",
    "\n",
    "- Um diese zu berechnen, führen wir zunächst eine Zwischengröße ein, $\\delta^l_j$, die wir den Fehler im $j^{th}$-Neuron in der $l$-ten Schicht nennen. \n",
    "- Durch Backpropagation erhalten wir eine Prozedur zur Berechnung des Fehlers $\\delta^l_j$ und setzen dann $\\delta^l_j$ in Beziehung zu $\\frac{\\partial C}{\\partial w^l_{jk}}$ und $\\frac{\\partial C}{ \\partial b^l_j}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Um zu verstehen, wie der Fehler definiert ist, stellen Sie sich vor, es gäbe einen Dämon in unserem neuronalen Netz:\n",
    "\n",
    "- Der Dämon sitzt auf dem $j^{th}$ Neuron in Schicht $l$.\n",
    "- Wenn die Eingabe für das Neuron eintrifft, bringt der Dämon die Operation des Neurons durcheinander. \n",
    "- Er fügt eine kleine Änderung $\\Delta z^l_j$ zu der gewichteten Eingabe des Neurons hinzu, so dass das Neuron statt $\\sigma(z^l_j)$ stattdessen $\\sigma(z^l_j+\\Delta z^l_j)$ ausgibt. \n",
    "- Diese Änderung pflanzt sich durch spätere Schichten im Netz fort und bewirkt schließlich, dass sich die Gesamtkosten um einen Betrag $\\frac{\\partial C}{\\partial z^l_j} \\Delta z^l_j$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN04/Bilder/backprop_demon.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nun ist dieser Dämon ein guter Dämon und versucht, Ihnen zu helfen, die Kosten zu verbessern, d.h. er versucht, ein $\\Delta z^l_j$ zu finden, das die Kosten kleiner macht. \n",
    "- Angenommen, $\\frac{\\partial C}{\\partial z^l_j}$ hat einen großen Wert (positiv oder negativ). Dann kann der Dämon die Kosten ziemlich stark senken, indem er $\\Delta z^l_j$ so wählt, dass es das entgegengesetzte Vorzeichen zu $\\frac{\\partial C}{\\partial z^l_j}$ hat. \n",
    "- Wenn dagegen $\\frac{\\partial C}{\\partial z^l_j}$ nahe bei Null liegt, dann kann der Dämon die Kosten durch eine Störung der gewichteten Eingabe $\\Delta z^l_j$ nicht wesentlich verbessern. Soweit der Dämon das beurteilen kann, ist das Neuron schon ziemlich nahe am Optimum.\n",
    "\n",
    "*Das gilt natürlich nur für kleine Änderungen $\\Delta z^l_j$. Wir nehmen an, dass der Dämon gezwungen ist, solche kleinen Änderungen vorzunehmen.* \n",
    "\n",
    "Und so gibt es einen heuristischen Sinn, in dem $\\frac{\\partial C}{\\partial z^l_j}$ **ein Maß für den Fehler im Neuron** ist. Motiviert durch diese Geschichte, definieren wir den Fehler $\\delta^l_j$ des Neurons $j$ in der Schicht $l$ durch\n",
    "\n",
    "\\begin{align} \n",
    "  \\delta^l_j \\equiv \\frac{\\partial C}{\\partial z^l_j}.\n",
    "\\tag{29}\\end{align}\n",
    "\n",
    "Gemäß unseren üblichen Konventionen verwenden wir $\\delta^l$, um den Vektor der Fehler zu bezeichnen, der zur Schicht $l$ gehört. Die Backpropagation gibt uns eine Möglichkeit, $\\delta^l$ für jede Schicht zu berechnen und diese Fehler dann mit den Größen von realem Interesse, $\\partial C / \\partial w^l_{jk}$ und $\\partial C / \\partial b^l_{j}$, in Beziehung zu setzen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sie fragen sich vielleicht, warum der Dämon die gewichtete Eingabe $z^l_j$ ändert. \n",
    "- Sicherlich wäre es natürlicher, sich vorzustellen, dass der Dämon die Ausgangsaktivierung $a^l_j$ ändert, mit dem Ergebnis, dass wir $\\frac{\\partial C}{\\partial a^l_j}$ als unser Fehlermaß verwenden würden. \n",
    "- In der Tat, wenn Sie dies tun, funktionieren die Dinge ganz ähnlich wie in der Diskussion unten. Aber es stellt sich heraus, dass es die Darstellung der Backpropagation algebraisch ein wenig komplizierter macht. \n",
    "- Wir bleiben also bei $\\delta^l_j \\equiv \\frac{\\partial C}{\\partial z^l_j}$ als Fehlermaß.\n",
    "\n",
    "*NB: Bei Klassifikationsproblemen wie MNIST wird der Begriff \"Fehler\" manchmal verwendet, um die Fehlerrate bei der Klassifikation zu bezeichnen. Wenn z. B. das neuronale Netz 96,0 Prozent der Ziffern richtig klassifiziert, dann beträgt der Fehler 4,0 Prozent. Offensichtlich hat dies eine ganz andere Bedeutung als unsere $\\delta$-Vektoren. In der Praxis sollten Sie keine Probleme haben zu erkennen, welche Bedeutung bei einer bestimmten Verwendung gemeint ist.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Angriffsplan: \n",
    "\n",
    "Die Backpropagation basiert auf **vier fundamentalen Gleichungen**. Zusammen geben uns diese Gleichungen eine Möglichkeit, sowohl den Fehler $\\delta^l$ als auch den **Gradienten der Kostenfunktion** zu berechnen. \n",
    "\n",
    "- Wir werden einen **kurzen Beweis** der Gleichungen geben, der hilft zu erklären, warum sie wahr sind; \n",
    "- Wir werden die Gleichungen in algorithmischer Form als \"Pseudocode\" wiedergeben und sehen, wie der Pseudocode als echter, laufender Python-Code implementiert werden kann; \n",
    "- und im letzten Abschnitt des Kapitels werden wir ein **intuitives Bild** davon entwickeln, was die Backpropagation-Gleichungen bedeuten und wie jemand sie von Grund auf entdecken könnte. Auf dem Weg dorthin werden wir immer wieder zu den vier grundlegenden Gleichungen zurückkehren, und wenn Sie Ihr Verständnis vertiefen, werden Ihnen diese Gleichungen vertraut und vielleicht sogar schön und natürlich erscheinen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### BP1: Eine Gleichung für den Fehler in der Ausgabeschicht $L$, $\\delta^L$: \n",
    "\n",
    "Die Komponenten von $\\delta^L$ sind gegeben durch\n",
    "\\begin{align} \n",
    "  \\delta^L_j = \\frac{\\partial C}{\\partial a^L_j} \\sigma'(z^L_j).\n",
    "\\tag{BP1}\\end{align}\n",
    "\n",
    "Dies ist ein sehr natürlicher Ausdruck. Der erste Term auf der rechten Seite, $\\partial C / \\partial a^L_j$, misst einfach, wie schnell sich die Kosten in Abhängigkeit von der $j^{th}$ Ausgangsaktivierung ändern. Wenn zum Beispiel $C$ nicht viel von einem bestimmten Ausgangsneuron $j$ abhängt, dann wird $\\delta^L_j$ klein sein, was wir erwarten würden. Der zweite Term auf der rechten Seite, $\\sigma'(z^L_j)$, misst, wie schnell sich die Aktivierungsfunktion $\\sigma$ bei $z^L_j$ ändert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Beachten Sie, dass alles in (BP1) **einfach zu berechnen ist**. Insbesondere berechnen wir $z^L_j$ während der Berechnung des Verhaltens des Netzwerks (Vorwärtspass), und es ist nur ein kleiner zusätzlicher Overhead, $\\sigma'(z^L_j)$ zu berechnen. Die genaue Form von $\\sigma'(z^L_j)$ hängt natürlich von der Form der Kostenfunktion ab. Vorausgesetzt, die Kostenfunktion ist bekannt, sollte es jedoch wenig Probleme bei der Berechnung von $\\sigma'(z^L_j)$ geben. Wenn wir zum Beispiel die quadratische Kostenfunktion verwenden, dann\n",
    "\n",
    "$$C = \\frac{1}{2} \\sum_j(y_j-a^L_j)^2$$\n",
    ", und damit \n",
    "\n",
    "$$\\frac{\\partial C }{ \\partial a^L_j} = (a_j^L-y_j)$$ \n",
    "was offensichtlich leicht berechenbar ist. Die Ableitung der Sigmoidfunktion kann geschrieben werden als:\n",
    "\n",
    "$$\\sigma'(z^L_j)= \\sigma(z^L_j)\\cdot \\left( 1 - \\sigma(z^L_j) \\right)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gleichung (BP1) ist ein komponentenweiser Ausdruck für $\\delta^L$. Es ist ein absolut guter Ausdruck, aber nicht die matrixbasierte Form, die wir für die Backpropagation benötigen. Es ist jedoch einfach, die Gleichung in einer matrixbasierten Form umzuschreiben, als\n",
    "\n",
    "\\begin{align} \n",
    "  \\delta^L = \\nabla_a C \\odot \\sigma'(z^L).\n",
    "\\tag{BP1a}\\end{align}\n",
    "\n",
    "Hier ist $\\nabla_a C$ als ein Vektor definiert, dessen Komponenten die partiellen Ableitungen $\\partial C / \\partial a^L_j$ sind. Man kann sich $\\nabla_a C$ als Ausdruck der Änderungsrate von $C$ in Bezug auf die Ausgangsaktivierungen vorstellen. Es ist leicht zu sehen, dass die Gleichungen (BP1a) und (BP1) äquivalent sind, und aus diesem Grund werden wir von nun an (BP1) austauschbar verwenden, um auf beide Gleichungen zu verweisen. Als Beispiel haben wir im Fall der quadratischen Kosten $\\nabla_a C = (a^L-y)$, und so wird die vollständig matrixbasierte Form von (BP1)\n",
    "\n",
    "\\begin{align} \n",
    "  \\delta^L = (a^L-y) \\odot \\sigma'(z^L) = (a^L-y) \\odot \\sigma(z^L) \\odot \\left[ 1-\\sigma'(z^L)\\right].\n",
    "\\tag{30}\\end{align}\n",
    "\n",
    "Wie Sie sehen können, hat alles in diesem Ausdruck eine schöne Vektorform und lässt sich mit einer Bibliothek wie Numpy leicht berechnen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Beweis der Gleichung (BP1)**, die einen Ausdruck für den Ausgangsfehler, $\\delta^L$, liefert. Um diese Gleichung zu beweisen, sei daran erinnert, dass per Definition\n",
    "\n",
    "\\begin{align}\n",
    "  \\delta^L_j = \\frac{\\partial C}{\\partial z^L_j}.\n",
    "\\tag{36}\\end{align}\n",
    "\n",
    "Unter Anwendung der **Kettenregel** können wir die obige partielle Ableitung in Form von partiellen Ableitungen in Bezug auf die Ausgangsaktivierungen neu ausdrücken,\n",
    "\\begin{align}\n",
    "  \\delta^L_j = \\sum_k \\frac{\\partial C}{\\partial a^L_k} \\frac{\\partial a^L_k}{\\partial z^L_j},\n",
    "\\tag{37}\\end{align}\n",
    "\n",
    "wobei die Summe über alle Neuronen $k$ in der Ausgabeschicht gilt. Natürlich hängt die Ausgangsaktivierung $a^L_k$ des $k^{th}$ Neurons nur von der gewichteten Eingabe $z^L_j$ für das $j^{th}$ Neuron ab, wenn $k=j$. Und so verschwindet $\\partial a^L_k / \\partial z^L_j$, wenn $k\\ne j$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Als Ergebnis können wir die vorherige Gleichung vereinfachen zu\n",
    "\n",
    "\\begin{align}\n",
    "  \\delta^L_j = \\frac{\\partial C}{\\partial a^L_j} \\frac{\\partial a^L_j}{\\partial z^L_j}.\n",
    "\\tag{38}\\end{align}\n",
    "\n",
    "Wenn wir uns daran erinnern, dass $a^L_j = \\sigma(z^L_j)$ ist, kann der zweite Term auf der rechten Seite als $\\sigma'(z^L_j)$ geschrieben werden, und die Gleichung wird\n",
    "\n",
    "\\begin{align}\n",
    "  \\delta^L_j = \\frac{\\partial C}{\\partial a^L_j} \\sigma'(z^L_j),\n",
    "\\tag{39}\\end{align}\n",
    "\n",
    "was einfach (BP1) ist, in Komponentenform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### BP2: Eine Gleichung für den Fehler $\\delta^l$ in Bezug auf den Fehler in der nächsten Schicht, $\\delta^{l+1}$\n",
    "\n",
    "Im Einzelnen\n",
    "\n",
    "\\begin{align} \n",
    "  \\delta^l = ((w^{l+1})^T \\delta^{l+1}) \\odot \\sigma'(z^l),\n",
    "\\tag{BP2}\\end{align}\n",
    "\n",
    "wobei $(w^{l+1})^T$ die **Transponierte der Gewichtsmatrix** $w^{l+1}$ für die $(l+1)^{th}$ Schicht ist. \n",
    "\n",
    "Diese Gleichung erscheint kompliziert, aber jedes Element hat eine schöne Interpretation. \n",
    "- Nehmen wir an, wir kennen den Fehler $\\delta^{l+1}$ auf der $(l+1)^{th}$-Schicht. \n",
    "- Wenn wir die transponierte Gewichtsmatrix, $(w^{l+1})^T$, anwenden, können wir uns dies intuitiv als **Verschiebung des Fehlers rückwärts durch das Netzwerk** vorstellen, was uns eine Art Maß für den Fehler am Ausgang der l-ten Schicht liefert. \n",
    "- Wir nehmen dann das Hadamard-Produkt $\\odot \\sigma'(z^l)$. \n",
    "- Dies verschiebt den Fehler rückwärts durch die Aktivierungsfunktion in der Schicht $l$ und gibt uns den Fehler $\\delta^l$ in der gewichteten Eingabe der Schicht $l$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Beweis** der Gleichung BP2, die eine Gleichung für den Fehler $\\delta^l$ in Bezug auf den Fehler in der nächsten Schicht, $δ^{l+1}, liefert.\n",
    "\n",
    "Dazu wollen wir $\\delta^l_j = \\partial C / \\partial z^l_j$ in Begriffe von $\\delta^{l+1}_k = \\partial C / \\partial z^{l+1}_k$ umschreiben. Wir können dies mit Hilfe der Kettenregel tun,\n",
    "\n",
    "\\begin{align}\n",
    "  \\delta^l_j & = & \\frac{\\partial C}{\\partial z^l_j} \\tag{40}\\\\\n",
    "  & = & \\sum_k \\frac{\\partial C}{\\partial z^{l+1}_k} \\frac{\\partial z^{l+1}_k}{\\partial z^l_j} \\tag{41}\\\\ \n",
    "  & = & \\sum_k \\frac{\\partial z^{l+1}_k}{\\partial z^l_j} \\delta^{l+1}_k,\n",
    "\\tag{42}\\end{align}\n",
    "\n",
    "wobei wir in der letzten Zeile die beiden Terme auf der rechten Seite vertauscht und die Definition von $\\delta^{l+1}_k$ ersetzt haben. Um den ersten Term in der letzten Zeile auszuwerten, beachten Sie, dass\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\\begin{align}\n",
    "  z^{l+1}_k = \\sum_j w^{l+1}_{kj} a^l_j +b^{l+1}_k = \\sum_j w^{l+1}_{kj} \\sigma(z^l_j) +b^{l+1}_k.\n",
    "\\tag{43}\\end{align}\n",
    "\n",
    "Differenziert man, erhält man\n",
    "\\begin{align}\n",
    "  \\delta^l_j = \\sum_k w^{l+1}_{kj}  \\delta^{l+1}_k \\sigma'(z^l_j).\n",
    "\\tag{45}\\end{align}\n",
    "\n",
    "Zurücksubstituiert in (42) erhalten wir\n",
    "\n",
    "\\begin{align}\n",
    "  \\delta^l_j = \\sum_k w^{l+1}_{kj}  \\delta^{l+1}_k \\sigma'(z^l_j).\n",
    "\\tag{45}\\end{align}\n",
    "\n",
    "Dies ist einfach (BP2) geschrieben in Komponentenform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Propagieren des Fehlers rückwärts\n",
    "\n",
    "Durch Kombination von (BP2) mit (BP1) können wir den Fehler $\\delta^l$ für eine beliebige Schicht im Netzwerk berechnen. Wir beginnen mit (BP1), um $\\delta^L$ zu berechnen, wenden dann Gleichung (BP2) an, um $\\delta^{L-1}$ zu berechnen, dann wieder Gleichung (BP2), um $\\delta^{L-2}$ zu berechnen, und so weiter, den ganzen Weg zurück durch das Netzwerk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### BP3: Eine Gleichung für die Änderungsrate der Kosten in Bezug auf jede Verzerrung im Netzwerk: \n",
    "\n",
    "Im Besonderen:\n",
    "\n",
    "\\begin{align}  \\frac{\\partial C}{\\partial b^l_j} =\n",
    "  \\delta^l_j.\n",
    "\\tag{BP3}\\end{align}\n",
    "\n",
    "Das heißt, der Fehler $\\delta^l_j$ ist *exakt gleich* der Änderungsrate $\\partial C / \\partial b^l_j$. Das ist eine gute Nachricht, denn (BP1) und (BP2) haben uns bereits gesagt, wie wir $\\delta^l_j$ berechnen können. Wir können (BP3) in Kurzschrift umschreiben als\n",
    "\n",
    "\\begin{align}\n",
    "  \\frac{\\partial C}{\\partial b} = \\delta,\n",
    "\\tag{31}\\end{align}\n",
    "\n",
    "wobei davon auszugehen ist, dass $\\delta$ an demselben Neuron ausgewertet wird wie der Bias $b$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### BP4: Eine Gleichung für die Änderungsrate der Kosten in Bezug auf ein beliebiges Gewicht im Netzwerk: \n",
    "\n",
    "Im Besonderen:\n",
    "\n",
    "\\begin{align}\n",
    " \\frac{\\partial C}{\\partial w^l_{jk}} = a^{l-1}_k \\delta^l_j.\n",
    "\\tag{BP4}\\end{align}\n",
    "\n",
    "Dies sagt uns, wie wir die partiellen Ableitungen $\\partial C/ \\partial w^l_{jk}$ in Bezug auf die Größen $\\delta^l$ und $a^{l-1}$ berechnen können, von denen wir bereits wissen, wie sie zu berechnen sind. Die Gleichung kann in einer weniger indexlastigen Notation umgeschrieben werden als\n",
    "\\begin{align}  \\frac{\\partial\n",
    "    C}{\\partial w} = a_{\\rm in} \\delta_{\\rm out},\n",
    "\\tag{32}\\end{align}\n",
    "\n",
    "\n",
    "wobei es sich versteht, dass ain die Aktivierung des Neurons ist, das in das Gewicht $w$ eingegeben wird, und δout der Fehler des Neurons ist, das vom Gewicht $w$ ausgegeben wird:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Eine nette Konsequenz von Gleichung (32) ist, dass, wenn die Aktivierung $a_{\\mathrm{in}}$ klein ist, $a_{\\mathrm{in}}\\approx 0$, der Gradiententerm $\\partial C / \\partial w$ ebenfalls dazu tendiert, klein zu sein. In diesem Fall sagen wir, dass das Gewicht langsam lernt, was bedeutet, dass es sich während des Gradientenabstiegs nicht viel ändert. Mit anderen Worten, eine Folge von (BP4) ist, dass Gewichte, die von Neuronen mit niedriger Aktivierung ausgegeben werden, langsam lernen.\n",
    "\n",
    "Es gibt noch weitere Einsichten in diese Richtung, die aus (BP1)-(BP4) gewonnen werden können. Beginnen wir mit der Betrachtung der Ausgabeschicht. - Betrachten Sie den Term $\\sigma'(z^L_j)$ in (BP1). \n",
    "- Erinnern Sie sich an den Graphen der Sigmoidfunktion im letzten Kapitel, dass die $\\sigma$-Funktion sehr flach wird, wenn $\\sigma(z^L_j)$ ungefähr 0 oder 1 ist. \n",
    "- Wenn dies der Fall ist, haben wir $\\sigma'(z^L_j)\\approx 0$. \n",
    "- Die Lektion ist also, dass ein Gewicht in der letzten Schicht langsam lernt, wenn das Ausgangsneuron entweder eine niedrige Aktivierung $(\\approx 0)$ oder eine hohe Aktivierung $(\\approx 1)$ hat. \n",
    "- In diesem Fall ist es üblich zu sagen, dass das Ausgangsneuron gesättigt ist und das *Gewicht folglich aufgehört hat zu lernen* (oder langsam lernt). Ähnliche Bemerkungen gelten auch für die Biases des Ausgangsneurons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wir können ähnliche Erkenntnisse für frühere Schichten gewinnen. Beachten Sie insbesondere den Term $\\sigma'(z^l)$ in (BP2). Das bedeutet, dass $\\delta^l_j$ wahrscheinlich klein wird, wenn das Neuron nahe der Sättigung ist. Und das wiederum bedeutet, dass alle Gewichte, die in ein gesättigtes Neuron eingegeben werden, langsam lernen. Diese Argumentation gilt nicht, wenn ${w^{l+1}}^T \\delta^{l+1}$ genügend große Einträge hat, um die Kleinheit von $\\sigma'(z^l_j)$ zu kompensieren. Aber ich spreche hier von der allgemeinen Tendenz.\n",
    "\n",
    "Zusammenfassend haben wir gelernt, dass ein Gewicht langsam lernt, wenn entweder das Eingangsneuron niedrig aktiviert ist, oder wenn das Ausgangsneuron gesättigt ist, d.h. entweder hoch oder niedrig aktiviert ist.\n",
    "\n",
    "Keine dieser Beobachtungen ist allzu sehr überraschend. Dennoch helfen sie, unser mentales Modell dessen zu verbessern, was beim Lernen eines neuronalen Netzwerks vor sich geht. Außerdem können wir diese Art der Argumentation umkehren. Es stellt sich heraus, dass die vier fundamentalen Gleichungen für jede Aktivierungsfunktion gelten, nicht nur für die Standard-Sigmoidfunktion (das liegt daran, dass, wie wir gleich sehen werden, die Beweise keine speziellen Eigenschaften von σ verwenden). Und so können wir diese Gleichungen verwenden, um Aktivierungsfunktionen zu entwerfen, die bestimmte gewünschte Lerneigenschaften haben. Als Beispiel, um Ihnen die Idee zu geben, nehmen wir an, wir würden eine (nicht-sigmoide) Aktivierungsfunktion σ so wählen, dass σ′ immer positiv ist und nie gegen Null geht. Das würde die Verlangsamung des Lernens verhindern, die auftritt, wenn gewöhnliche sigmoide Neuronen in die Sättigung gehen. Später im Buch werden wir Beispiele sehen, bei denen diese Art von Modifikation an der Aktivierungsfunktion vorgenommen wird. Wenn man sich die vier Gleichungen (BP1)-(BP4) vor Augen hält, kann man erklären, warum solche Modifikationen versucht werden und welche Auswirkungen sie haben können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Übung\n",
    "1. Beweisen Sie die Gleichungen (BP3) und (BP4).\n",
    "\n",
    "Damit ist der Beweis der vier Grundgleichungen der Backpropagation abgeschlossen. Der Beweis mag kompliziert erscheinen. Aber er ist eigentlich nur das Ergebnis einer sorgfältigen Anwendung der Kettenregel. Etwas weniger prägnant kann man sich die Backpropagation als einen Weg vorstellen, den Gradienten der Kostenfunktion zu berechnen, indem man systematisch die Kettenregel aus der Multivariablenrechnung anwendet. Das ist alles, was die Backpropagation wirklich ausmacht - der Rest sind Details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Der Backpropagation-Algorithmus\n",
    "\n",
    "Die Backpropagation-Gleichungen bieten uns eine Möglichkeit, den Gradienten der Kostenfunktion zu berechnen. Lassen Sie uns dies explizit in Form eines Algorithmus ausschreiben:\n",
    "\n",
    "1. **Eingabe** $x$: Setzen Sie die entsprechende Aktivierung a1 für die Eingabeschicht.\n",
    "2. **Feedforward**: Für jedes $l = 2, 3, \\ldots, L$ berechnen Sie \n",
    "$$\n",
    "z^{l} = w^l a^{l-1}+b^l\n",
    "$$ \n",
    "und \n",
    "$$\n",
    "a^{l} = \\sigma(z^{l})\n",
    "$$.\n",
    "3. **Ausgangsfehler** $\\delta^L$: Berechnen Sie den Vektor\n",
    "\n",
    "$$\\delta^{L}= \\nabla_a C \\odot \\sigma'(z^L)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4. **Backpropagieren Sie den Fehler**: Berechnen Sie für jedes $l = L-1, L-2, \\dots, 2\n",
    "\n",
    "$$\n",
    "\\delta^{l} = ((w^{l+1})^T \\delta^{l+1}) \\odot \\sigma'(z^{l})\n",
    "$$.\n",
    "\n",
    "5. **Ausgabe**: Der Gradient der Kostenfunktion ist gegeben durch\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C}{\\partial w^l_{jk}} = a^{l-1}_k \\delta^l_j\n",
    "$$\n",
    "und \n",
    "$$\n",
    "\\frac{\\partial C}{\\partial b^l_j} = \\delta^l_j\n",
    "$$\n",
    "\n",
    "Wenn Sie den Algorithmus betrachten, sehen Sie, warum er Backpropagation genannt wird. Wir berechnen die Fehlervektoren δl rückwärts, ausgehend von der letzten Schicht. Es mag sonderbar erscheinen, dass wir das Netzwerk rückwärts durchlaufen. Aber wenn Sie über den Beweis der Backpropagation nachdenken, ist die Rückwärtsbewegung eine Folge der Tatsache, dass die Kosten eine Funktion der Ausgaben des Netzwerks sind. Um zu verstehen, wie die Kosten mit früheren Gewichten und Verzerrungen variieren, müssen wir wiederholt die Kettenregel anwenden und uns rückwärts durch die Schichten arbeiten, um brauchbare Ausdrücke zu erhalten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Übungen\n",
    "1. **Backpropagation mit einem einzelnen modifizierten Neuron:** Angenommen, wir modifizieren ein einzelnes Neuron in einem Feedforward-Netzwerk so, dass die Ausgabe des Neurons durch $f(\\sum_j w_j x_j + b)$ gegeben ist, wobei $f$ eine andere Funktion als das Sigmoid ist. Wie sollte man den Backpropagation-Algorithmus in diesem Fall modifizieren?\n",
    "2. **Backpropagation mit linearen Neuronen:** Angenommen, wir ersetzen die übliche nicht-lineare $\\sigma$-Funktion im gesamten Netzwerk durch $\\sigma(z)=z$. Schreiben Sie den Backpropagation-Algorithmus für diesen Fall neu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#### Miscellaneous functions\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Network(object):\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.\"\"\"\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "        if test_data:\n",
    "            n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k : k + mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)\n",
    "            ]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                print(\n",
    "                    \"Epoch {0}: {1} / {2}\".format(j, self.evaluate(test_data), n_test)\n",
    "                )\n",
    "            else:\n",
    "                print(\"Epoch {0} complete\".format(j))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "        is the learning rate.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [\n",
    "            w - (eta / len(mini_batch)) * nw for w, nw in zip(self.weights, nabla_w)\n",
    "        ]\n",
    "        self.biases = [\n",
    "            b - (eta / len(mini_batch)) * nb for b, nb in zip(self.biases, nabla_b)\n",
    "        ]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x]  # list to store all the activations, layer by layer\n",
    "        zs = []  # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book.  Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on.  It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l + 1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l - 1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return output_activations - y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "file = gzip.open(\"./data/mnist.pkl.gz\", \"rb\")\n",
    "u = pickle._Unpickler(file)\n",
    "u.encoding = \"latin1\"\n",
    "tr_d, va_d, te_d = u.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def vectorized_result(j):\n",
    "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n",
    "    position and zeroes elsewhere.  This is used to convert a digit\n",
    "    (0...9) into a corresponding desired output from the neural\n",
    "    network.\"\"\"\n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n",
    "training_results = [vectorized_result(y) for y in tr_d[1]]\n",
    "training_data = list(zip(training_inputs, training_results))\n",
    "validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]\n",
    "validation_data = list(zip(validation_inputs, va_d[1]))\n",
    "test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]\n",
    "test_data = list(zip(test_inputs, te_d[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "net = Network([784, 30, 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "net.SGD(training_data, 30, 10, 3.0, test_data=test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backpropagation: das grosse Bild\n",
    "\n",
    "Wir haben ein Bild des Fehlers entwickelt, der von der Ausgabe zurückpropagiert wird. Aber können wir noch tiefer gehen und mehr Intuition darüber entwickeln, was vor sich geht, wenn wir all diese Matrix- und Vektor-Multiplikationen durchführen? \n",
    "\n",
    "Es ist eine Sache, den Schritten in einem Algorithmus zu folgen, oder sogar dem Beweis zu folgen, dass der Algorithmus funktioniert. Aber das bedeutet nicht, dass Sie das Problem so gut verstehen, dass Sie den Algorithmus überhaupt erst hätten entdecken können. Gibt es eine plausible Argumentationskette, die Sie zur Entdeckung des Backpropagation-Algorithmus geführt haben könnte? In diesem Abschnitt werde ich diese beiden Rätsel angehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Um uns ein besseres Bild davon zu machen, was der Algorithmus macht, stellen wir uns vor, dass wir eine kleine Änderung $\\Delta w^l_{jk}$ an einem Gewicht im Netzwerk, $w^l_{jk}$, vorgenommen haben:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN04/Bilder/big_picture1.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Diese Änderung der Gewichtung bewirkt eine Änderung der Ausgangsaktivierung des entsprechenden Neurons:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN04/Bilder/big_picture2.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Das wiederum bewirkt eine Änderung in **allen** Aktivierungen in der nächsten Schicht:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN04/Bilder/big_picture3.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Diese Änderungen bewirken wiederum Änderungen in der nächsten Schicht, und dann in der nächsten, und so weiter bis hin zu einer Änderung in der letzten Schicht, und dann in der Kostenfunktion:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN04/Bilder/big_picture4.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Die Änderung $\\Delta C$ der Kosten ist mit der Änderung $\\Delta w^l_{jk}$ des Gewichts durch die Gleichung verbunden\n",
    "\n",
    "\\begin{align} \n",
    "  \\Delta C \\approx \\frac{\\partial C}{\\partial w^l_{jk}} \\Delta w^l_{jk}.\n",
    "\\tag{47}\\end{align}\n",
    "\n",
    "Dies legt nahe, dass ein möglicher Ansatz zur Berechnung von $\\frac{\\partial C}{\\partial w^l_{jk}}$ darin besteht, sorgfältig zu verfolgen, wie sich eine kleine Änderung in $w^l_{jk}$ ausbreitet, um eine kleine Änderung in $C$ zu verursachen. Wenn wir das können und dabei darauf achten, alles in leicht berechenbaren Größen auszudrücken, dann sollten wir in der Lage sein, $\\frac{\\partial C}{\\partial w^l_{jk}}$ zu berechnen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Versuchen wir, dies auszuführen. Die Änderung $\\Delta w^l_{jk}$ bewirkt eine kleine Änderung $\\Delta a^l_j$ in der Aktivierung des $j^{th}$ Neurons in der l-ten Schicht. Diese Änderung ist gegeben durch:\n",
    "\n",
    "\\begin{align} \n",
    "  \\Delta a^l_j \\approx \\frac{\\partial a^l_j}{\\partial w^l_{jk}} \\Delta w^l_{jk}.\n",
    "\\tag{48}\\end{align}\n",
    "\n",
    "Die Änderung der Aktivierung $\\Delta a^l_j$ bewirkt eine Änderung aller Aktivierungen in der nächsten Schicht, d.h. der $(l+1)^{th}$ Schicht.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wir konzentrieren uns auf die Art und Weise, wie nur eine einzige dieser Aktivierungen beeinflusst wird, sagen wir $a^{l+1}_q$,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN04/Bilder/big_picture5.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tatsächlich wird es die folgende Änderung verursachen:\n",
    "\n",
    "\\begin{align}\n",
    "  \\Delta a^{l+1}_q \\approx \\frac{\\partial a^{l+1}_q}{\\partial a^l_j} \\Delta a^l_j.\n",
    "\\tag{49}\\end{align}\n",
    "\n",
    "Setzt man den Ausdruck aus Gleichung (48) ein, erhält man:\n",
    "\n",
    "\\begin{align}\n",
    "  \\Delta a^{l+1}_q \\approx \\frac{\\partial a^{l+1}_q}{\\partial a^l_j} \\frac{\\partial a^l_j}{\\partial w^l_{jk}} \\Delta w^l_{jk}.\n",
    "\\tag{50}\\end{align}\n",
    "\n",
    "Natürlich wird die Änderung $\\Delta a^{l+1}_q$ wiederum Änderungen in den Aktivierungen in der nächsten Schicht verursachen. In der Tat können wir uns einen Pfad durch das gesamte Netzwerk von $w^l_{jk}$ bis $C$ vorstellen, wobei jede Änderung der Aktivierung eine Änderung der nächsten Aktivierung und schließlich eine Änderung der Kosten am Ausgang bewirkt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wenn der Pfad durch die Aktivierungen $a^l_j, a^{l+1}_q, \\ldots, a^{L-1}_n, a^L_m$ geht, dann ist der resultierende Ausdruck:\n",
    "\n",
    "\\begin{align}\n",
    "  \\Delta C \\approx \\frac{\\partial C}{\\partial a^L_m} \n",
    "  \\frac{\\partial a^L_m}{\\partial a^{L-1}_n}\n",
    "  \\frac{\\partial a^{L-1}_n}{\\partial a^{L-2}_p} \\ldots\n",
    "  \\frac{\\partial a^{l+1}_q}{\\partial a^l_j}\n",
    "  \\frac{\\partial a^l_j}{\\partial w^l_{jk}} \\Delta w^l_{jk},\n",
    "\\tag{51}\\end{align}\n",
    "\n",
    "das heißt, wir haben einen Term vom Typ $\\partial a / \\partial a$ für jedes zusätzliche Neuron aufgenommen, das wir durchlaufen haben, sowie den Term $\\partial C/\\partial a^L_m$ am Ende. Dieser repräsentiert die Änderung in $C$ aufgrund von Änderungen in den Aktivierungen entlang dieses speziellen Pfades durch das Netzwerk. Natürlich gibt es viele Pfade, über die sich eine Änderung von $w^l_{jk}$ ausbreiten kann, um die Kosten zu beeinflussen, und wir haben nur einen einzigen Pfad betrachtet.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Um die Gesamtänderung von $C$ zu berechnen, ist es plausibel, dass wir über alle möglichen Pfade zwischen dem Gewicht und den Endkosten summieren, d. h.,\n",
    "\n",
    "\\begin{align} \n",
    "  \\Delta C \\approx \\sum_{mnp\\ldots q} \\frac{\\partial C}{\\partial a^L_m} \n",
    "  \\frac{\\partial a^L_m}{\\partial a^{L-1}_n}\n",
    "  \\frac{\\partial a^{L-1}_n}{\\partial a^{L-2}_p} \\ldots\n",
    "  \\frac{\\partial a^{l+1}_q}{\\partial a^l_j} \n",
    "  \\frac{\\partial a^l_j}{\\partial w^l_{jk}} \\Delta w^l_{jk},\n",
    "\\tag{52}\\end{align}\n",
    "\n",
    "wobei wir über alle möglichen Auswahlen für die Zwischenneuronen entlang des Pfades summiert haben. Im Vergleich mit (47) sehen wir, dass\n",
    "\n",
    "\\begin{align} \n",
    "  \\frac{\\partial C}{\\partial w^l_{jk}} = \\sum_{mnp\\ldots q} \\frac{\\partial C}{\\partial a^L_m} \n",
    "  \\frac{\\partial a^L_m}{\\partial a^{L-1}_n}\n",
    "  \\frac{\\partial a^{L-1}_n}{\\partial a^{L-2}_p} \\ldots\n",
    "  \\frac{\\partial a^{l+1}_q}{\\partial a^l_j} \n",
    "  \\frac{\\partial a^l_j}{\\partial w^l_{jk}}.\n",
    "\\tag{53}\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nun sieht Gleichung (53) kompliziert aus. Sie hat jedoch eine schöne intuitive Interpretation. \n",
    "- Wir berechnen die Änderungsrate von $C$ in Bezug auf ein Gewicht im Netzwerk. \n",
    "- Was uns die Gleichung sagt, ist, dass jede Kante zwischen zwei Neuronen im Netzwerk mit einem Ratenfaktor verbunden ist, der einfach die **partielle Ableitung der Aktivierung eines Neurons in Bezug auf die Aktivierung des anderen Neurons** ist.\n",
    "- Die Kante vom ersten Gewicht zum ersten Neuron hat einen Ratenfaktor $\\partial a^{l}_j / \\partial w^l_{jk}$. \n",
    "- Der Ratenfaktor für einen Pfad ist einfach das Produkt der Ratenfaktoren entlang des Pfades. \n",
    "- Und die Gesamtänderungsrate $\\partial C / \\partial w^l_{jk}$ ist einfach die **Summe der Ratenfaktoren aller Pfade** vom Anfangsgewicht bis zu den Endkosten. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Dieses Verfahren wird hier für einen einzelnen Pfad dargestellt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN04/Bilder/big_picture6.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Was ich bis jetzt geliefert habe, ist ein heuristisches Argument, eine Art, darüber nachzudenken, was passiert, wenn man ein Gewicht in einem Netzwerk stört. \n",
    "- Zunächst könnten Sie explizite Ausdrücke für alle einzelnen partiellen Ableitungen in Gleichung (53) herleiten. Das ist mit ein wenig Kalkül leicht zu bewerkstelligen. \n",
    "- Danach könnte man versuchen, herauszufinden, wie man alle Summen über Indizes als Matrixmultiplikationen schreiben kann. Das erweist sich als mühsam und erfordert etwas Ausdauer, aber keine außergewöhnliche Einsicht. \n",
    "- Nachdem Sie all dies getan und dann so weit wie möglich vereinfacht haben, stellen Sie fest, dass Sie am Ende genau den Backpropagation-Algorithmus haben! \n",
    "\n",
    "**Und so können Sie sich den Backpropagation-Algorithmus als eine Möglichkeit vorstellen, die Summe über den Ratenfaktor für alle diese Pfade zu berechnen. Oder, um es etwas anders auszudrücken, der Backpropagation-Algorithmus ist eine clevere Methode, um kleine Störungen der Gewichte (und Verzerrungen) zu verfolgen, während sie sich durch das Netzwerk ausbreiten, den Ausgang erreichen und dann die Kosten beeinflussen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Es gibt buchstäblich Hunderte (wenn nicht Tausende) von Tutorials über Backpropagation, die\n",
    "heute. Einige meiner Favoriten sind:\n",
    "\n",
    "1. Andrew Ng’s discussion on backpropagation inside the Machine Learning course by Coursera.\n",
    "2. Das stark mathematisch motivierte [Kapitel 2](http://neuralnetworksanddeeplearning.com/chap2.html) - Wie der Backpropagation-Algorithmus funktioniert aus \"Neural Networks and Deep Learning\" von [Michael Nielsen](https://github.com/mnielsen/neural-networks-and-deep-learning).\n",
    "3. [Stanford’s cs231n](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture4.pdf) Ausführungen zur und Analyse der Backpropagation.\n",
    "4. [Matt Mazur's](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/) ausgezeichnetes konkretes Beispiel (mit tatsächlich gearbeiteten Zahlen), das zeigt, wie Backpropagation funktioniert.\n",
    "5. https://medium.freecodecamp.org/build-a-flexible-neural-network-with-backpropagation-in-python-acffeb7846d0\n",
    "6. https://ayearofai.com/rohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d or \n",
    "7. einige Artikel, die die Intuition des Gradientenabstiegs erklären, wie https://medium.com/datathings/neural-networks-and-backpropagation-explained-in-a-simple-way-f540a3611f5e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "ger",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "ger",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
