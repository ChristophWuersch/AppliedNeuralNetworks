{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\"  align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch, François Chollet </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik-neu/systemtechnik/ice-institut-fuer-computational-engineering\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN09/9.3-RNN_verstehen_pl.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# für Ausführung auf Google Colab auskommentieren und installieren\n",
    "!pip install -q -r https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/main/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This notebook contains the first code sample found in Chapter 6, Section 2 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 9.3 Rekurrente neuronale Netze verstehen\n",
    "\n",
    "- Alle bislang vorgestellten Arten von NNs, wie z.B. Fully-connected CNNs, besitzen **kein »Gedächtnis«**. \n",
    "- Die Eingaben werden unabhängig voneinander verarbeitet – der durch Eingaben verursachte Zustand wird nicht gespeichert. \n",
    "- Um eine Sequenz oder eine Zeitreihe von Daten mit so einem NN verarbeiten zu können, muss die gesamte Sequenz auf einmal übergeben werden: Sie müssen sie also in einen einzigen Datenpunkt umwandeln. \n",
    "\n",
    "So sind wir beim IMDb-Beispiel vorgegangen: Eine komplette Filmbewertung wurde in einen einzelnen grossen Vektor umgewandelt\n",
    "und »in einem Rutsch« verarbeitet. Man bezeichnet das als **Feedforward-Netz**.\n",
    "\n",
    "- Im Gegensatz dazu verarbeiten Sie beim Lesen dieses Satzes die Wörter **der Reihe nach (sequentiell)** einzeln, nämlich bei jeder Augenbewegung, mit der Sie ein Wort erfassen. Dabei merken Sie sich die vorangegangenen Wörter und erhalten eine flüssige Repräsentation der Bedeutung des Satzes. \n",
    "- Biologische Intelligenz verarbeitet Informationen schrittweise und erzeugt dabei ein internes Modell dessen, was verarbeitet wird, das auf den erhaltenen Informationen aufbaut und kontinuierlich durch neue Informationen ergänzt wird.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Bilder/RNN_Schleife.PNG\" width=\"500\"  align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ein **rekurrentes neuronales Netz (RNN)** funktioniert nach dem gleichen Prinzip, wenngleich in einer extrem vereinfachten Version: Es verarbeitet Sequenzen, indem es die Elemente durchläuft und einen Zustand erfasst, der Informationen relativ zu\n",
    "den vorangegangenen Elementen beinhaltet. \n",
    "- Faktisch ist ein RNN ein Netz, das eine **interne Schleife** besitzt. \n",
    "- Der Zustand des RNNs wird zwischen der Verarbeitung zweier unterschiedlicher, voneinander unabhängiger Sequenzen (etwa zwei verschiedene Filmbewertungen) zurückgesetzt, sodass Sie jede Sequenz nach wie vor als einzelnen Datenpunkt betrachten können, also als einzelne Eingabe für das RNN. \n",
    "- Der Unterschied besteht darin, dass dieser Datenpunkt nicht mehr in einem einzigen Schritt verarbeitet wird, sondern dass das RNN intern die Elemente der Sequenz in einer Schleife durchläuft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Test RNN\n",
    "\n",
    "- Zur Verdeutlichung der Funktionsweise von Schleife und Zustand implementieren wir die Weitergabe des Zustands in einem *Test-RNN mit Numpy*.\n",
    "- Dieses RNN nimmt eine Vektorsequenz als Eingabe entgegen, die als 2-D-Tensor der Grösse `(timesteps, input_features)` codiert ist. \n",
    "- Beim Durchlaufen der einzelnen Zeitschritte berücksichtigt es den aktuellen Zustand und die Eingabe mit der Shape `(input_features,)` zum Zeitpunkt `t` und berechnet daraus die Ausgabe für diesen Zeitpunkt `t`. \n",
    "- Anschliessend wird die Ausgabe dem Zustand für die nächste Iteration zugewiesen. Beim ersten Zeitschritt ist die vorangegangene Ausgabe undefiniert, und es gibt noch keinen aktuellen Zustand. \n",
    "- Er wird deshalb mit einem Nullvektor initialisiert, der als der Anfangszustand des RNNs bezeichnet wird."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "state_t = 0\n",
    "for input_t in input_sequence:\n",
    "    output_t = f(input_t, state_t)\n",
    "    state_t = output_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Wir können die Funktion `f()` sogar schon konkretisieren: Die Abbildung der Eingabe\n",
    "und des Zustands auf eine Ausgabe wird durch die beiden Matrizen `W` und `U`\n",
    "sowie einen *Bias-Vektor* parametrisiert. Sie ähnelt der Abbildung, die ein Fullyconnected\n",
    "Layer in einem Feedforward-Netz durchführt."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "state_t = 0\n",
    "\n",
    "for input_t in input_sequence:\n",
    "    output_t = activation(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
    "    state_t = output_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Zwecks Vermeidung von Mehrdeutigkeiten programmieren wir eine naive\n",
    "Numpy-Implementierung für die Weitergabe des Zustands des einfachen RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Anzahl der Zeitschritte in der Eingabesequenz\n",
    "timesteps = 100\n",
    "# Dimensionalität des Eingabemerkmalsraums\n",
    "input_features = 32\n",
    "# Dimensionalität des Ausgabemerkmalsraums\n",
    "output_features = 64\n",
    "# Eingabedaten, im Beispiel das zufällige Rauschen\n",
    "inputs = np.random.random((timesteps, input_features))\n",
    "# Anfangszustand, ein Nullvektor\n",
    "state_t = np.zeros((output_features,))\n",
    "# Erzeugt zufällige Gewichtungsmatrizen\n",
    "W = np.random.random((output_features, input_features))\n",
    "U = np.random.random((output_features, output_features))\n",
    "b = np.random.random((output_features,))\n",
    "\n",
    "successive_outputs = []\n",
    "# input_t ist ein Vektor mit der Shape (input_features,).\n",
    "\n",
    "for input_t in inputs:\n",
    "    # Errechnet aus der Eingabe und dem aktuellen Zustand die Ausgabe\n",
    "    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
    "    # Speichert die Ausgabe in einer Liste\n",
    "    successive_outputs.append(output_t)\n",
    "    # Aktualisiert den Zustand des Netzes für den nächsten Zeitschritt\n",
    "    state_t = output_t\n",
    "    final_output_sequence = np.concatenate(successive_outputs, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Zusammengefasst, ist ein RNN eine `for`-Schleife, die die beim vorangegangenen\n",
    "Durchlauf der Schleife berechneten Grössen wiederverwendet, nicht mehr und nicht weniger.**\n",
    "\n",
    "Natürlich gibt es viele verschiedene RNNs, auf die diese Definition\n",
    "zutrifft – dieses Beispiel ist eine der einfachsten Möglichkeiten, ein RNN zu\n",
    "beschreiben. RNNs sind durch die Funktion gekennzeichnet, die zum nächsten\n",
    "Schritt führt. In diesem Fall sieht sie so aus:\n",
    "<img src=\"Bilder/RNN.png\" width=\"640\"  align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In diesem Beispiel ist die endgültige Ausgabe ein Tensor mit der Shape `(timesteps, output_features)`.\n",
    "- Jeder Zeitschritt enthält die Ausgabe der Schleife zum Zeitpunkt `t`. \n",
    "- Der Zeitschritt `t` im Ausgabetensor enthält Informationen über die Zeitschritte `0` bis `t` in der Eingabesequenz – also über den gesamten zeitlichen Verlauf. \n",
    "- Aus diesem Grund ist in vielen Fällen die vollständige Ausgabesequenz gar nicht erforderlich. \n",
    "- Die letzte Ausgabe (`output_t` am Ende der Schleife) reicht aus, denn sie enthält Informationen über die gesamte Sequenz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ein rekurrenter Layer in PyTorch\n",
    "\n",
    "Ein einfacher rekurrenter Layer in PyTorch kann mit ``torch.nn.RNN`` umgesetzt werden. Dieser verarbeitet standardmäßig ganze Batches von Sequenzen.\n",
    "\n",
    "- Die Eingabe muss die Form (seq_len, batch_size, input_size) haben. Alternativ kann man im Konstruktor batch_first=True setzen, dann wird die Form (batch_size, seq_len, input_size) erwartet.\n",
    "\n",
    "- nn.RNN kann so verwendet werden, dass entweder:\n",
    "\n",
    "    - die vollständige Ausgabesequenz für alle Zeitschritte zurückgegeben wird → Tensor der Form (batch_size, seq_len, hidden_size) (bei batch_first=True)\n",
    "\n",
    "    - oder nur der letzte Hidden State verwendet wird → Tensor der Form (batch_size, hidden_size)\n",
    "\n",
    "- Welche Variante man nimmt, hängt davon ab, ob man das komplette output-Tensor weiterverwendet oder nur das hidden-Tensor (hn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "class SimpleRNN_LastOnly(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(10000, 32)\n",
    "        self.rnn = nn.RNN(input_size=32, hidden_size=32, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, h = self.rnn(x)\n",
    "        return h.squeeze(0)  # nur letzter Zustand\n",
    "\n",
    "\n",
    "model1 = SimpleRNN_LastOnly().to(\"cpu\")\n",
    "\n",
    "summary(\n",
    "    model1,\n",
    "    input_size=(1, 100),  # (batch_size, sequence_length)\n",
    "    dtypes=[torch.long],  # dtypes MUSS Liste sein!\n",
    "    device=\"cpu\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Das folgende Beispiel gibt die vollständige Sequenz der Zustände zurück:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleRNN_WithSequences(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(10000, 32)\n",
    "        self.rnn = nn.RNN(input_size=32, hidden_size=32, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (batch, seq_len, embedding_dim)\n",
    "        output, _ = self.rnn(x)  # return_sequences=True → full output\n",
    "        return output  # (batch, seq_len, hidden_size)\n",
    "\n",
    "\n",
    "# Modellinstanz\n",
    "model2 = SimpleRNN_WithSequences().to(\"cpu\")\n",
    "\n",
    "# torchinfo summary-Aufruf\n",
    "summary(\n",
    "    model2,\n",
    "    input_size=(1, 100),  # (batch_size, sequence_length)\n",
    "    dtypes=[torch.long],  # für nn.Embedding wichtig\n",
    "    device=\"cpu\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gelegentlich ist es sinnvoll, mehrere rekurrente Layer hintereinanderzuschalten,\n",
    "um die Repräsentationsfähigkeit des NNs zu erhöhen. In diesem Fall müssen die\n",
    "zwischenliegenden Layer die vollständigen Sequenzen ausgeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "class StackedSimpleRNN(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(10000, 32)\n",
    "        self.rnn1 = nn.RNN(32, 32, batch_first=True)\n",
    "        self.rnn2 = nn.RNN(32, 32, batch_first=True)\n",
    "        self.rnn3 = nn.RNN(32, 32, batch_first=True)\n",
    "        self.rnn4 = nn.RNN(32, 32, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (batch, seq_len, embedding_dim)\n",
    "        x, _ = self.rnn1(x)  # return_sequences=True → volle Sequenz\n",
    "        x, _ = self.rnn2(x)  # \"\n",
    "        x, _ = self.rnn3(x)  # \"\n",
    "        _, h = self.rnn4(x)  # return_sequences=False → letzter Zustand\n",
    "        return h.squeeze(0)  # (batch, hidden_size)\n",
    "\n",
    "\n",
    "# Modell instanziieren\n",
    "model = StackedSimpleRNN().to(\"cpu\")\n",
    "\n",
    "# torchinfo summary\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(1, 100),  # batch_size=1, sequence_length=100\n",
    "    dtypes=[torch.long],  # nötig für Embedding\n",
    "    device=\"cpu\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchview import draw_graph\n",
    "\n",
    "# Modell vorbereiten\n",
    "model = StackedSimpleRNN().to(\"cpu\")\n",
    "\n",
    "# Visualisierung erstellen\n",
    "viz = draw_graph(\n",
    "    model,\n",
    "    input_size=(1, 100),\n",
    "    dtypes=[torch.long],\n",
    "    device=\"cpu\",\n",
    "    expand_nested=True,\n",
    "    graph_name=\"StackedSimpleRNN\",\n",
    "    save_graph=True,\n",
    "    filename=\"model_plot\",  # erzeugt model_plot.png\n",
    "    directory=\"./\",  # oder ein anderer Pfad\n",
    "    show_shapes=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nun verwenden wir ein solches Modell für die Aufgabe, IMDb-Filmbewertungen\n",
    "zu klassifizieren. Zunächst erfolgt die Vorverarbeitung der Daten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Hyperparameter\n",
    "max_features = 10000  # Wortindex-Limit\n",
    "maxlen = 500  # maximale Sequenzlänge\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Textvorverarbeitung: einfache Tokenisierung\n",
    "def simple_tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<br\\s*/?>\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "# 1. IMDb laden\n",
    "print(\"Lade IMDb-Daten...\")\n",
    "dataset = load_dataset(\"imdb\")\n",
    "train_texts = dataset[\"train\"][\"text\"]\n",
    "train_labels = dataset[\"train\"][\"label\"]\n",
    "test_texts = dataset[\"test\"][\"text\"]\n",
    "test_labels = dataset[\"test\"][\"label\"]\n",
    "\n",
    "# 2. Tokenisierung & Vokabular-Erstellung\n",
    "print(\"Tokenisiere Texte & baue Vokabular...\")\n",
    "tokenized_train = [simple_tokenize(text) for text in train_texts]\n",
    "all_tokens = [token for text in tokenized_train for token in text]\n",
    "most_common = Counter(all_tokens).most_common(max_features - 2)\n",
    "\n",
    "# Spezial-Tokens\n",
    "word_to_idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for idx, (word, _) in enumerate(most_common, start=2):\n",
    "    word_to_idx[word] = idx\n",
    "\n",
    "\n",
    "# Hilfsfunktion: Text zu Sequenz von Indizes\n",
    "def encode(text_tokens):\n",
    "    return [word_to_idx.get(token, word_to_idx[\"<UNK>\"]) for token in text_tokens]\n",
    "\n",
    "\n",
    "# 3. Kodieren und Padding\n",
    "def encode_and_pad(text_list, maxlen):\n",
    "    encoded = [encode(simple_tokenize(text)) for text in text_list]\n",
    "    padded = []\n",
    "    for seq in encoded:\n",
    "        if len(seq) > maxlen:\n",
    "            padded.append(seq[-maxlen:])  # abschneiden hinten\n",
    "        else:\n",
    "            padded.append([0] * (maxlen - len(seq)) + seq)  # vorne auffüllen mit PAD\n",
    "    return torch.tensor(padded, dtype=torch.long)\n",
    "\n",
    "\n",
    "print(\"Kodieren & Padding...\")\n",
    "X_train = encode_and_pad(train_texts, maxlen)\n",
    "X_test = encode_and_pad(test_texts, maxlen)\n",
    "y_train = torch.tensor(train_labels, dtype=torch.float32)\n",
    "y_test = torch.tensor(test_labels, dtype=torch.float32)\n",
    "\n",
    "# 4. Dataset & Dataloader\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f\"Train Shape: {X_train.shape}\")\n",
    "print(f\"Test Shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Und jetzt trainieren wir ein einfaches rekurrentes NN unter Verwendung eines\n",
    "`Embedding`- und eines `SimpleRNN`-Layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "class SimpleRNNClassifier(pl.LightningModule):\n",
    "    def __init__(self, vocab_size=10000, embedding_dim=32, hidden_size=32):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (batch, seq_len, embedding_dim)\n",
    "        _, h = self.rnn(x)  # h: (1, batch, hidden_size)\n",
    "        out = self.fc(h.squeeze(0))  # (batch, 1)\n",
    "        return torch.sigmoid(out)  # (batch, 1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze(1)  # (batch,)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = ((y_hat > 0.5) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze(1)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = ((y_hat > 0.5) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.RMSprop(self.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "np.Inf = np.inf\n",
    "# TensorDataset + Validation-Split wie in validation_split=0.2\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "val_size = int(0.2 * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "# Lightning-Modell instanziieren\n",
    "model = SimpleRNNClassifier(vocab_size=10000)\n",
    "\n",
    "\n",
    "csv_logger = CSVLogger(\"logs\", name=\"simple_rnn\")\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"auto\", logger=csv_logger)\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Zum Abschluss stellen wir die Verlustfunktion und die Korrektklassifizierungsrate\n",
    "beim Training und bei der Validierung dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the metrics.csv file\n",
    "metrics_file = \"logs/simple_rnn/version_0/metrics.csv\"  # Pfad anpassen!!\n",
    "metrics = pd.read_csv(metrics_file)\n",
    "data = metrics[[\"epoch\", \"train_acc_epoch\", \"train_loss_epoch\", \"val_acc\", \"val_loss\"]]\n",
    "# Nach Epoche gruppieren, fehlende Werte nach unten füllen\n",
    "data_cleaned = data.groupby(\"epoch\").first().reset_index()\n",
    "data_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(\n",
    "    data_cleaned[\"epoch\"],\n",
    "    data_cleaned[\"train_acc_epoch\"],\n",
    "    label=\"Train Accuracy\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.plot(\n",
    "    data_cleaned[\"epoch\"],\n",
    "    data_cleaned[\"val_acc\"],\n",
    "    label=\"Validation Accuracy\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Train vs Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(\n",
    "    data_cleaned[\"epoch\"],\n",
    "    data_cleaned[\"train_loss_epoch\"],\n",
    "    label=\"Train Loss\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.plot(\n",
    "    data_cleaned[\"epoch\"],\n",
    "    data_cleaned[\"val_loss\"],\n",
    "    label=\"Validation Loss\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Zur Erinnerung: Der erste naive Ansatz zur Verarbeitung dieser Datenmenge in Kapitel 3 erreichte bei den Testdaten eine Korrektklassifizierungsrate von 88%. \n",
    "- Im Vergleich dazu funktioniert das kleine RNN leider nicht besonders gut (nur 85%).\n",
    "- Das liegt zum einen daran, dass nur die ersten 500 Wörter berücksichtigt werden, nicht die vollständige Sequenz. Das RNN kann also nur auf weniger Informationen zugreifen als das Modell aus Kapitel 3. \n",
    "- Zum anderen ist `SimpleRNN` nicht besonders gut für die Verarbeitung langer Sequenzen (wie Text) geeignet.\n",
    "- Andere Arten von RNNs sind hier deutlich leistungsfähiger.\n",
    "\n",
    "Sehen wir uns also einige ausgeklügeltere Layer an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vanishing Gradients Problem: LSTM- und GRU-Layer\n",
    "\n",
    "- Es gibt zwei weitere: `LSTM` und `GRU`. \n",
    "- In der Praxis werden Sie eigentlich immer einen dieser beiden verwenden, denn `SimpleRNN` ist im Allgemeinen zu schlicht, um wirklich von Nutzen zu sein. \n",
    "- Darüber hinaus gibt es ein ernsthaftes Problem: Theoretisch sollte `SimpleRNN` eigentlich in der Lage sein, zum Zeitpunkt `t` auf Informationen über vor vielen Zeitschritten erfolgte Eingaben zuzugreifen, aber in der Praxis ist es unmöglich, so langfristige Abhängigkeiten zu erlernen. Dafür ist das Problem des **verschwindenden Gradienten (vanishing gradients)**  verantwortlich, ein Effekt, der an das erinnert, was bei nicht rekurrenten NNs (Feedforward-Netze) beobachtbar ist, die viele Layer tief sind:\n",
    "- Wenn einem NN immer mehr Layer hinzugefügt werden, wird es irgendwann untrainierbar. Die theoretischen Gründe hierfür wurden Anfang der 1990er-Jahre von *Sepp Hochreiter, Jürgen Schmidhuber* [1] und *Yoshua Bengio* [2] untersucht.\n",
    "\n",
    "**LSTM- und GRU-Layer wurden entwickelt, um dieses Problem zu lösen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[1] [Sepp Hochreiter und Jürgen Schmidhuber, *Long Short-Term Memory*, Neural Computation 9,\n",
    "Nr. 8 (1997)](https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory)\n",
    "\n",
    "[2] [Yoshua Bengio, Patrice Simard und Paolo Frasconi, *Learning Long-Term Dependencies with Gradient Descent Is Difficult*, IEEE Transactions on Neural Networks 5, Nr. 2 (1994)](https://ieeexplore.ieee.org/document/279181)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LSTM-Layer\n",
    "\n",
    "Betrachten wir zunächst die LSTM-Layer. \n",
    "- Der zugrunde liegende Algorithmus namens [Long Short-Term Memory](https://en.wikipedia.org/wiki/Long_short-term_memory) (LSTM, zu Deutsch etwa »langes Kurzzeitgedächtnis «) wurde 1997 von Hochreiter und Schmidhuber entwickelt und war die Krönung ihrer Forschungsarbeiten über das Problem des verschwindenden Gradienten [2].\n",
    "- Bei diesem Layer handelt es sich um eine Variante des Ihnen schon bekannten `SimpleRNN`-Layers. \n",
    "- *Er fügt eine Möglichkeit hinzu, Informationen über viele Zeitschritte hinweg zu erhalten*. \n",
    "- Stellen Sie sich ein Förderband vor, das parallel zu der verarbeitenden Sequenz verläuft. Die in der Sequenz enthaltenen Informationen können bei Bedarf zu jedem beliebigen Zeitpunkt auf das Förderband wechseln, sich zu einem späteren Zeitschritt befördern lassen und dort wieder unbeschadet zurückwechseln. \n",
    "\n",
    "**Das ist im Wesentlichen das, was der LSTM-Layer leistet: Informationen für den späteren Gebrauch speichern und so verhindern, dass ältere Signale während der Verarbeitung allmählich verschwinden.**\n",
    "- Hier ist ein [exzellenter Blog von Christopher Olah](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) zu LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Um das im Detail zu verstehen, betrachten wir eine `SimpleRNN`-Zelle. Da es viele verschiedene Gewichtungsmatrizen gibt, erhalten die Matrizen `W` und `U` als Index den Buchstaben `o` wie output (`Wo` und `Uo`).\n",
    "\n",
    "<img src=\"Bilder/SimpleRNN_LSTM.png\" width=\"640\"  align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Diesem Diagramm *fügen wir nun eine weitere Spur hinzu, auf der Informationen über die Zeitschritte hinweg fliessen können*. \n",
    "- Die Werte der verschiedenen Zeitschritte bezeichnen wir als `Ct`, wobei das `c` für carry (befördern) steht.\n",
    "- Die hier beförderte Information bewirkt in der Zelle Folgendes: \n",
    "- Sie wird mit der Eingabe und der rekurrenten Verbindung kombiniert (durch ein Tensorprodukt mit einer\n",
    "Gewichtungsmatrix, der Addition eines Bias-Vektors und der Anwendung einer Aktivierungsfunktion) und beeinflusst so den Zustand, der an den nächsten Zeitschritt übergeben wird (per Aktivierungsfunktion und Multiplikation). \n",
    "- Konzeptuell ist dieser Datenfluss eine Modulierung der nächsten Ausgabe und des nächsten Zustands.\n",
    "\n",
    "So weit, so gut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Bilder/simple_LSTM.png\" width=\"640\" align=\"center\"/>\n",
    "Aus einem `SimpleRNN` wird durch Hinzufügen einer Carry-Spur ein `LSTM`-Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aber bei der Berechnung des nächsten Carry-Werts wird es raffiniert: Sie erfordert\n",
    "**drei verschiedene Transformationen in Form einer SimpleRNN-Zelle**:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "y = activation(dot(state_t, U) + dot(input_t, W) + b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Allerdings besitzen diese Abbildungen jeweils eigene Gewichtungsmatrizen, die\n",
    "durch die Indizes `i`, `f` und `k` gekennzeichnet werden. Das mag etwas willkürlich erscheinen, aber warten Sie einen Moment. Damit ergibt sich Folgendes:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "output_t = activation(dot(state_t, Uo) + dot(input_t, Wo) + dot(c_t, Vo) + bo)\n",
    "i_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi)\n",
    "f_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bf)\n",
    "k_t = activation(dot(state_t, Uk) + dot(input_t, Wk) + bk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Durch Kombination von `i_t`, `f_t` und `k_t` ergibt sich der nachfolgende Carry- Zustand (der nächste Wert von `c_t`)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "c_t+1 = i_t * k_t + c_t * f_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Dies fügen wir dem Diagramm hinzu, und das war’s.\n",
    "Eigentlich gar nicht so kompliziert, nur ziemlich komplex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"Bilder/full_LSTM.png\" width=\"640\"  align=\"center\"/>\n",
    "Aus einem `SimpleRNN` wird durch Hinzufügen einer Carry-Spur ein `LSTM`-Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wenn Sie die Funktionsweise analysieren möchten, können Sie versuchen zu interpretieren, was\n",
    "diese Operationen bewirken. \n",
    "- Man könnte beispielsweise sagen, dass die Multiplikation von `c_t` und `f_t` eine Möglichkeit darstellt, irrelevante Informationen im Carry Datenfluss zu unterdrücken. \n",
    "- `i_t` und `k_t` hingegen liefern Informationen über den jetzigen Zustand und aktualisieren die Carry-Spur.\n",
    "\n",
    "Letztendlich sind solche **Interpretationen mehr oder weniger bedeutungslos**, denn was diese Operationen tatsächlich\n",
    "bewirken, hängt von den Gewichtungen ab, durch die sie parametrisiert werden. Und die Gewichtungen werden bei jedem Training anhand aller Zeitschritte neu erlernt, was es unmöglich macht, der einen oder anderen Operation einen bestimmten\n",
    "Zweck zuzuschreiben. \n",
    "\n",
    "Die Spezifizierung einer RNN-Zelle (wie gerade beschrieben) begrenzt den Hypothesenraum – den Raum, in dem Sie beim Trainieren nach einer guten Modellkonfiguration suchen –, sie legt jedoch nicht fest, was eine Zelle eigentlich bewirkt, denn das ist die Aufgabe der Gewichtungen. Ein und dieselbe Zelle kann sehr verschiedene Dinge bewirken, wenn sie unterschiedliche Gewichtungen\n",
    "besitzt. Die Kombination der Operationen, aus der eine RNN-Zelle besteht, sollte eher als eine Reihe von Beschränkungen Ihrer Suche aufgefasst werden, nicht als ein Design im architektonischen Sinn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Die Spezifizierung einer RNN-Zelle (wie gerade beschrieben) begrenzt den Hypothesenraum** – den Raum, in dem Sie beim Trainieren nach einer guten Modellkonfiguration suchen (inductive Bias).\n",
    "- Sie legt jedoch nicht fest, was eine Zelle eigentlich bewirkt, denn das ist die Aufgabe der Gewichtungen. Ein und dieselbe Zelle kann sehr verschiedene Dinge bewirken, wenn sie unterschiedliche Gewichtungen besitzt. \n",
    "- Die Kombination der Operationen, aus der eine RNN-Zelle besteht, sollte eher als eine Reihe von Beschränkungen Ihrer Suche aufgefasst werden, nicht als ein Design im architektonischen Sinn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Als Forscher gewinnt man den Eindruck, dass man die Auswahl dieser Beschränkungen, also wie die RNN-Zelle implementiert wird, besser den Optimierungsalgorithmen (wie etwa genetischen Algorithmen oder verstärkenden Lernvorgängen) überlässt, nicht menschlichen Entwicklern. \n",
    "\n",
    "- Zukünftig werden wir NNs auf diese Weise entwickeln. \n",
    "- **Zusammengefasst**: Sie brauchen die Architektur einer bestimmten LSTM-Zelle nicht zu verstehen; das sollte nicht zu den Aufgaben eines Menschen gehören. Denken Sie einfach nur daran, was eine LSTM-Zelle leisten soll: Sie soll es ermöglichen, ältere Informationen zu einem späteren Zeitpunkt wieder aufzunehmen und so dem Problem des verschwindenden Gradienten entgegenwirken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "## Ein konkretes LSTM-Beispiel in Pytorch\n",
    "\n",
    "\n",
    "Wenden wir uns wieder praktischen Aufgaben zu und erstellen wir ein Modell mit einem LSTM-Layer, das wir mit den IMDb-Daten trainieren. \n",
    "- Das NN ähnelt dem gerade vorgestellten SimpleRNN-Layer.\n",
    "- Wir geben lediglich die Dimensionalität des LSTM-Layers an; \n",
    "- bei allen anderen Argumenten (von denen es eine ganze Menge gibt) belassen wir es bei den Vorgaben.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lightning.ai/lightning-ai/studios/train-a-recurrent-neural-network-with-pytorch-lightning?section=featured "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "class LSTMClassifier(pl.LightningModule):\n",
    "    def __init__(self, vocab_size=10000, embedding_dim=32, hidden_size=32):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim, hidden_size=hidden_size, batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (batch, seq_len, emb_dim)\n",
    "        _, (h_n, _) = self.lstm(x)  # h_n: (1, batch, hidden)\n",
    "        out = self.fc(h_n.squeeze(0))  # (batch, 1)\n",
    "        return torch.sigmoid(out)  # (batch, 1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze(1)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = ((y_hat > 0.5) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze(1)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = ((y_hat > 0.5) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.RMSprop(self.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "# Werte aus deinem vorherigen Code:\n",
    "# input_train (→ torch.tensor), y_train (→ torch.tensor)\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "\n",
    "# 50% Validation-Split\n",
    "val_size = len(dataset) // 2\n",
    "train_size = len(dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "# Modell instanziieren\n",
    "model = LSTMClassifier(vocab_size=10000)\n",
    "\n",
    "# CSV-Logger für spätere Plot-Auswertung\n",
    "csv_logger = CSVLogger(\"logs\", name=\"lstm_model\")\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"auto\", logger=csv_logger)\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Dieses Mal erreichen wir bei der Validierung eine Korrektklassifizierungsrate von\n",
    "bis zu 89%. Gar nicht schlecht und erheblich besser als das SimpleRNN-Modell.\n",
    "Das liegt vor allem daran, dass **LSTM weniger unter dem Problem des verschwindenden\n",
    "Gradienten zu leiden hat**. \n",
    "- Das Ergebnis ist sogar geringfügig besser als das des vollständig verbundenen Ansatzes in Kapitel 3, obwohl hier weniger Daten verwendet werden, denn die Sequenzen werden nach 500 Zeitschritten abgeschnitten, während in Kapitel 3 vollständige Sequenzen genutzt wurden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zusammenfassung\n",
    "Sie haben Folgendes gelernt:\n",
    "- Was RNNs eigentlich sind und wie sie funktionieren\n",
    "- Was LSTM ist und warum es besser für lange Sequenzen geeignet ist als ein naives RNN\n",
    "- Wie RNN-Layer zur Verarbeitung sequenzieller Daten verwendet werden\n",
    "\n",
    "Als Nächstes werden wir einige der erweiterten Features von RNNs betrachten, die Ihnen dabei helfen können, die Deep-Learning-Modelle für sequenzielle Daten richtig auszureizen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
