{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"Bilder\\ost_logo.png\" width=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik/systemtechnik/ice-institut-fuer-computational-engineering/\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN01/1.1-Einführung_NN-EDA.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# für Ausführung auf Google Colab auskommentieren und installieren\n",
    "%pip install -q -r https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from IPython.display import Image, display\n",
    "from matplotlib.colors import ListedColormap\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learnining und Deep Learning\n",
    "\n",
    "Quellen: \n",
    "- **Aurélien Géron:** *Praxiseinstieg Machine Learning mit Scikit-Learn und Tensorflow*: Konzepte, Tools und Techniken für intelligenze Systeme, Authorized German translation of the English edition of Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, ISBN 978-1-491-96229-9\n",
    "- **Francois Chollet**: *Deep Learning mit Python und Keras*, Das Praxis-HandbuchISBN 978-3-95845-839-0, 1. Auflage 2018, www.mitp.de, © 2018 mitp Verlags GmbH & Co. KG, Frechen, Übersetzung der amerikanischen Originalausgabe François Chollet: Deep Learning with Python, ISBN 978-1617294433\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Machine Learning entstand aufgrund folgender Frage: Könnte ein Computer über das, »von dem wir wissen, wie wir es befehlen können«, hinausgehen und selbst erlernen, wie eine bestimmte Aufgabe erledigt wird? Könnte ein Computer uns überraschen? Könnte ein Computer automatisch Regeln erlernen, indem er Daten betrachtet, ohne dass Programmierer diese Datenverarbeitungsregeln von Hand erstellen müssen?\n",
    "- Diese Fragen öffneten einem neuen Programmierparadigma Tür und Tor. Bei der klassischen Programmierung, der symbolischen KI, geben Menschen Regeln (ein Programm) und die gemäss diesen Regeln zu verarbeitenden Daten vor, was zu Antworten führt. Beim Machine Learning geben Menschen sowohl die Daten als auch die dazugehörigen Antworten vor, und heraus kommen die Regeln. Diese Regeln sind dann auf neue Daten anwendbar und liefern eigenständige Antworten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN01/Bilder/ML_Paradigma.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Artificial Neural Networks (ANNs)\n",
    "\n",
    "Künstliche Neuronale Netze (ANNs=artificial neural netwoks) sind die Kernkomponente des Deep Learning. Sie sind flexibel, mächtig und skalierbar, was sie ideal für große und hochgradig komplexe Machine-Learning-Aufgaben einsetzbar macht, wie beispielsweise die Klassifizierung von Milliarden Bildern (Google Images), Spracherkennung (Apples Siri), Videoempfehlungen für\n",
    "Hunderte Millionen Nutzer pro Tag (YouTube) oder den Weltmeister im Brettspiel Go durch die Analyse von Millionen Partien und anschließendes Spielen gegen sich selbst zu schlagen, z.B. [AlphaGo von DeepMind](https://www.youtube.com/watch?v=HT-UZkiOLv8).\n",
    "\n",
    "In diesem Kapitel werden wir künstliche neuronale Netze kennenlernen. Wir beginnen mit einem kurzen Überblick der ersten Architekturen von ANNs. Dann werden wir mehrschichtige Perzeptrons (MLPs) vorstellen und eines mithilfe von TensorFlow implementieren, um die Klassifikation der MNIST-Ziffern anzugehen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Was ist Deep Learning ?\n",
    "\n",
    "Deep Learning ist ein Teilgebiet des Machine Learnings: ein neuer Ansatz, die Repräsentationen anhand von Daten zu erkennen, der den Schwerpunkt auf das Erlernen aufeinanderfolgender Layer (Schichten) mit zunehmend sinnvolleren Repräsentationen legt. Das Deep in Deep Learning bezieht sich also nicht auf irgendein tiefer gehendes durch diesen Ansatz erzielbares Verständnis, sondern steht für das Konzept aufeinanderfolgender Repräsentations-Layer. \n",
    "\n",
    "Die Anzahl der zu einem Datenmodell beitragenden Layer wird als die Tiefe des Modells bezeichnet.\n",
    "Man hätte Deep Learning auch als Lernen durch schichtweise Repräsentationen oder Lernen durch hierarchische Repräsentationen bezeichnen können. Deep Learning umfasst heutzutage oft Dutzende oder sogar Hunderte aufeinanderfolgender Repräsentations-Layer – die alle durch die Bereitstellung der Trainingsdaten automatisch erlernt werden. Andere Ansätze des Machine Learnings konzentrieren sich tendenziell auf nur einen oder zwei Repräsentations-Layer und werden deshalb mitunter als Shallow Learning (»flaches« Lernen) bezeichnet.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was Deep Learning heute leistet:\n",
    "\n",
    "- *Bildklassifizierung* auf nahezu menschlichem Niveau\n",
    "- *Spracherkennung* auf nahezu menschlichem Niveau\n",
    "- *Handschriftenerkennung* auf nahezu menschlichem Niveau\n",
    "- Verbesserung der *Übersetzung von Fremdsprachen*\n",
    "- Verbesserung der *Sprachsynthese*\n",
    "- *Digitale Assistenten* wie Google Now oder Amazon Alexa\n",
    "- *Selbstfahrende Autos* auf nahezu menschlichem Niveau\n",
    "- Verbesserung *gezielter Werbung*, wie sie Google, Baidu und Bing einsetzen\n",
    "- Verbesserung der *Suchergebnisse im Web*\n",
    "- Beantwortung von in natürlicher Sprache gestellten Fragen\n",
    "- Ein Programm schlägt den besten menschlichen Go-Spieler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Von biologischen und künstlichen Neuronen \n",
    "\n",
    "NNs sind aus buchstäblich übereinandergestapelten Layern aufgebaut. \n",
    "- Der Begriff entstammt zwar der Neurobiologie, aber obwohl einige der grundlegenden Konzepte des Deep Learnings zum Teil durch unser Verständnis vom Gehirn inspiriert wurden, sind **Deep-Learning-Modelle keine Nachbildungen des Gehirns.**\n",
    "- Es gibt keinerlei Hinweise darauf, dass das Gehirn irgendwelche Verfahren einsetzt, die den in modernen Deep-Learning-Modellen eingesetzten Lernmechanismen ähneln. \n",
    "- In populärwissenschaftlichen Artikeln wird gelegentlich behauptet, Deep Learning funktioniere wie das Gehirn oder sei dem Gehirn nachgebildet worden, **aber das stimmt nicht. Deep Learning hat nichts mit Neurobiologie zu tun.** \n",
    "- **Vergessen Sie die Mythen und Rätsel, die um die Vorstellung »genau wie unser Gehirn« gesponnen wurden, und am besten auch alles, was Sie über hypothetische Zusammenhänge zwischen Deep Learning und Biologie gelesen haben.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Entmystifizierung des kurzfristigen Hypes\n",
    "\n",
    "Deep Learning hat zwar in den letzten Jahren bemerkenswerte Fortschritte erzielt, allerdings sind die Erwartungen in Bezug darauf, was auf diesem Gebiet im kommenden Jahrzehnt erreicht werden kann, viel zu hoch gesteckt. \n",
    "- Auch wenn weltbewegende Anwendungen wie selbstfahrende Autos schon in greifbarer Nähe sind, werden viele andere wahrscheinlich noch lange unerreichbar bleiben, wie etwa glaubwürdige Sprachdialogsysteme, Übersetzungen zwischen beliebigen Sprachen oder das Verständnis natürlicher Sprache auf menschlichem Niveau. \n",
    "- Vor allem die Berichte über allgemeine Intelligenz auf menschlichem Niveau sollten nicht allzu ernst genommen werden. Hohe Erwartungen, die kurzfristig nicht erfüllt werden, weil die Technologie noch nicht so weit ist, bringen das Risiko mit sich, dass weniger in die Forschung investiert wird und sich der Fortschritt auf diese Weise nachhaltig verlangsamt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Das Besondere an Deep Learning: Merkmalserstellung\n",
    "\n",
    "- Der Hauptgrund dafür, dass sich Deep Learning so schnell durchgesetzt hat, ist die verbesserte Leistung, die es bei vielen Aufgabenstellungen bietet. Das ist jedoch nicht der einzige Grund. Deep Learning vereinfacht das Lösen von Aufgaben so sehr, weil es einen der entscheidenden Schritte des Machine-Learning-Workflows automatisiert: die **Merkmalserstellung**.\n",
    "\n",
    "- Beim Deep Learning ist entscheidend, dass es dem Modell ermöglicht wird, alle Repräsentations-Layer zusammen und gleichzeitig zu erlernen (man bezeichnet das als **greedy**, also gierig) anstatt der Reihe nach. Durch dieses gleichzeitige Erlernen der Merkmale werden bei der Anpassung des Modells an eins der internen Merkmale alle anderen davon abhängigen Merkmale ebenfalls automatisch angepasst, ohne dass ein menschliches Eingreifen nötig wäre. \n",
    "- Alles wird durch **ein einziges Feedback-Signal** gesteuert: Alle Änderungen am Modell tragen zum eigentlichen Ziel bei. Dieses Verfahren ist sehr viel leistungsfähiger als ein massenhaftes Aufreihen von Shallow-Learning-Modellen, weil es ermöglicht, **komplexe, abstrakte Repräsentationen** zu erlernen, indem sie in eine lange Reihe dazwischenliegender Räume (Layer) unterteilt werden: Jeder dieser Räume unterscheidet sich von dem vorhergehenden nur durch eine einfache Transformation.\n",
    "- Die Machine-Learning-Wettbewerbe bei [Kaggle](https://www.kaggle.com/) näher zu betrachten, stellt eine hervorragende Möglichkeit dar, sich ein Bild vom aktuellen Stand der Machine-Learning-Algorithmen und der verfügbaren Tools zu machen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Es gibt drei allgemeine Faktoren, die den Fortschritt beim Machine Learning\n",
    "beeinflussen:\n",
    "1. **Hardware:** Faktisch subventionierte der *Spielemarkt* das Supercomputing der nächsten Generation von KI-Anwendungen. Manchmal wird aus einem Spiel tatsächlich eine bedeutende Entwicklung. Eine NVIDIA TITAN X, eine Grafikkarte für Spiele, die\n",
    "Ende 2015 1.000 Dollar kostete, kann bis zu 6,6 TFLOPS liefern (einfache Genauigkeit): 6,6 Billionen float32-Operationen pro Sekunde. Das ist etwa das 350-Fache dessen, was ein moderner Laptop leistet.\n",
    "2. **Datenmengen und Benchmarks:** Wenn man eine Datenmenge nennen sollte, die als Katalysator für den Erfolg des Deep Learnings gedient hat, dann die *ImageNet-Datenbank*, die mehr als 1,4 Millionen Bilder enthält, die von Hand einer von 1.000 Kategorien zugewiesen worden sind (eine Kategorie pro Bild). Das Besondere an der ImageNet-Datenbank ist jedoch nicht nur ihre Größe, sondern auch der dazugehörige alljährlich stattfindende Wettbewerb.\n",
    "3. **Verbesserte Algorithmen:** Erst nachdem folgende Verbesserungen umgesetzt wurden, war es möglich, Modelle mit zehn oder mehr Layern zu trainieren und die Vorteile des Deep Learnings zu nutzen:\n",
    "    - verbesserte *Aktivierungsfunktionen* für die Layer\n",
    "    - verbesserte Verfahren zur *Initialisierung der Gewichtungen* (He, Xavier), zunächst durch schichtweises Vortrainieren, was aber bald wieder aufgegeben wurde \n",
    "    - verbesserte *Optimierungsverfahren*, wie etwa RMSProp und Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Historische Entwicklung\n",
    "## McCulloch-Pitts-Zelle\n",
    "\n",
    "Überraschenderweise gibt es ANNs schon eine ganze Weile: Das erste Mal wurden Sie 1943 vom Neurophysiologen **Warren McCulloch** und vom Mathematiker **Walter Pitts** erwähnt. In ihrem wegweisenden Artikel (https://goo.gl/Ul4mxW) »*A Logical Calculus of Ideas Immanent in Nervous Activity*« stellen McCulloch und Pitts ein vereinfachtes rechnerisches Modell vor, nach dem biologische Neuronen im Gehirn von Tieren zusammenarbeiten könnten, um komplexe Berechnungen mithilfe von Aussagenlogik durchzuführen. Dies war die erste Architektur eines künstlichen neuronalen Netzwerks. Seitdem wurden viele weitere Architekturen erfunden, wie wir noch sehen werden.\n",
    "\n",
    "Die frühen Erfolge von ANNs bis zu den 1960ern führten zur verbreiteten Annahme, dass wir uns schon bald mit wirklich intelligenten Maschinen unterhalten würden. Als klar wurde, dass dieses Versprechen nicht eingelöst werden würde (zumindest\n",
    "für eine lange Zeit), flossen Forschungsgelder in andere Richtungen, und für ANNs brach ein langes, dunkles Zeitalter an.\n",
    "\n",
    "- [Wang: On the Origin of Deep Learning](https://arxiv.org/pdf/1702.07800.pdf)\n",
    "- [Tappert: Who ist the father of Deep Learning?](https://ieeexplore.ieee.org/abstract/document/9070967)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Das Perzeptron\n",
    "\n",
    "Das 1957 von [**Frank Rosenblatt**](https://ieeexplore.ieee.org/abstract/document/9070967) erfundene [Perzeptron](https://de.wikipedia.org/wiki/Perzeptron) gehört zu den einfachsten Architekturen neuronaler Netze. Es baut auf einem leicht unterschiedlichen künstlichen Neuron auf, der **Linear Threshold Unit (LTU)**:\n",
    "Die Ein- und Ausgaben sind nun Zahlen (anstatt binäre Ein-/Aus-Werte), und zu jeder Eingabeleitung gehört ein Gewicht. Die LTU berechnet eine gewichtete Summe ihrer Eingaben\n",
    "\n",
    "$$ z = w_1 x_1 + w_2 x_2 + \\dots + w_n x_n = \\mathbf{w}^T  \\mathbf{x}$$\n",
    "\n",
    "und wendet dann eine *Aktivierungsfunktion* $\\sigma(z)$ auf diese Summe an und gibt das Ergebnis aus: \n",
    "\n",
    "$$ h_w(x) = \\sigma(\\mathbf{w}^T  \\mathbf{x})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN01/Bilder/perceptron.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Die im Perzeptron am häufigsten verwendete Aktivierungsfunktion ist die Heaviside-Funktion $\\theta(z)$. Manchmal wird stattdessen die Vorzeichenfunktion $\\operatorname{sgn}(z)$ verwendet.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\theta(z) =\n",
    "\\begin{cases}\n",
    "0 & \\text{if }z < 0\\\\\n",
    "1 & \\text{if }z \\ge 0\n",
    "\\end{cases} & \\quad\\quad\n",
    "\\operatorname{sgn}(z) =\n",
    "\\begin{cases}\n",
    "-1 & \\text{if }z < 0\\\\\n",
    "0 & \\text{if }z = 0\\\\\n",
    "+1 & \\text{if }z > 0\n",
    "\\end{cases}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "\n",
    "Eine einzelne LTU lässt sich für einfache lineare binäre Klassifikationsaufgaben einsetzen. Sie berechnet eine Linearkombination der Eingabewerte und gibt die positive Kategorie aus, falls das Ergebnis einen Schwellenwert überschreitet, und andernfalls die negative Kategorie (wie bei der logistischen Regression oder einer linearen SVM). Die Entscheidungsgrenze stellt eine lineare Hyperebene dar, welche durch die Gewichte $\\mathbf{w}$ definiert ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Ein Perzeptron besteht einfach aus einer einzelnen Schicht LTUs, wobei jedes Neuron mit allen Eingabewerten verbunden ist.\n",
    "- Diese Verbindungen werden oft als *spezielle Neuronen* zum Durchreichen der Information der *Eingabeneuronen* repräsentiert.\n",
    "- Diese geben einfach nur die erhaltenen Eingabedaten aus. \n",
    "- Ausserdem wird üblicherweise ein zusätzliches *Bias-Merkmal* hinzugefügt ($x_0 = 1$). Dieses Bias-Merkmal wird durch ein weiteres spezielles Neuron repräsentiert, dem Bias-Neuron, das stets 1 ausgibt.\n",
    "\n",
    "In der folgenden Abbildung ist ein Perzeptron mit zwei Eingaben und drei Ausgaben dargestellt. Dieses Perzeptron kann Datenpunkte gleichzeitig drei unterschiedlichen binären Kategorien zuordnen, wodurch es zu einem Klassifikator mit mehreren\n",
    "Ausgaben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN01/Bilder/perceptron2.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wie lässt sich ein Perzeptron trainieren? \n",
    "\n",
    "Der von Frank Rosenblatt vorgeschlagene Algorithmus zum Trainieren von Perzeptrons ist in weiten Teilen von der\n",
    "**Hebbschen Lernregel** inspiriert. In seinem 1949 veröffentlichten Buch \"*The Organization\n",
    "of Behavior*\" stellte Donald Hebb eine These vor, nach der die Verbindung zweier biologischer Neuronen stärker werde, wenn eines das andere häufig aktiviert.\n",
    "\n",
    "Siegrid Löwel hat diesen Gedanken später als knackigen Satz formuliert: **»Cells that fire together, wire together.«** Dieser Grundsatz wurde später als Hebbsche Lernregel (oder Hebbsches Lernen) bekannt; dabei wird die Verbindung zweier\n",
    "Neuronen immer dann verstärkt, wenn beide die gleiche Ausgabe haben. Perzeptrons lassen sich mit einer Variante dieser Regel trainieren, die die vom Netz begangenen Fehler berücksichtigt; Verbindungen, die zu einer falschen Ausgabe führen,\n",
    "werden nicht verstärkt. Beim Trainieren wird dem Perzeptron ein einzelner Trainingsdatenpunkt vorgestellt und eine Vorhersage getroffen. Bei jedem Ausgabeneuron das eine falsche Vorhersage trifft, werden die Gewichte der Verbindungen verstärkt, die zu einer korrekten Vorhersage beigetragen hätten. \n",
    "\n",
    "$$ {w_{i,j}}^{(\\text{next step})} = w_{i,j} + \\eta \\cdot (y_j - \\hat{y}_j) x_i $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Die Entscheidungsgrenze jedes Ausgabeneurons ist linear. Damit sind Perzeptrons nicht in der Lage, komplexe Muster zu erlernen (wie auf logistischer Regression aufbauende Klassifikatoren). Wenn sich die Trainingsdatenpunkte aber linear separieren\n",
    "lassen, konvergiert dieser Algorithmus laut Rosenblatt zu einer Lösung. Dies nennt man das *Perzeptron-Konvergenztheorem*.\n",
    "\n",
    "Scikit-Learn enthält die Klasse Perceptron, die ein einzelnes LTU-Netz implementiert.\n",
    "Diese funktioniert wie erwartet – beispielsweise auf dem Iris-Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Explorative Datenanalyse (EDA)\n",
    "\n",
    "- Bevor wir mit dem Trainieren starten, ist es *Pflicht*, die Daten statistisch zu untersuchen und zu visualisieren.\n",
    "- Wir gehen dabei unvoreingenommen vor, wie ein Forscher oder Detektiv, der in den Daten spannende Zusammenhänge, Korrelationen, Kausaliäten oder Unstimmigkeiten zu *entdecken* sucht.\n",
    "\n",
    "Um Daten zu sichten und visualisieren eignen sich die Pakete `seaborn`und `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Der Lilienblüten-Datensatz oder Fisher's Iris-Datensatz ist ein multivariater Datensatz, der von dem britischen Statistiker und Biologen Ronald Fisher in seinem 1936 erschienenen Aufsatz The use of multiple measurements in taxonomic problems (Die Verwendung von Mehrfachmessungen bei taxonomischen Problemen) als Beispiel für eine lineare Diskriminanzanalyse verwendet und berühmt gemacht wurde. \n",
    "- Der Datensatz besteht aus 50 Proben von jeder der drei Irisarten (Iris setosa, Iris virginica und Iris versicolor). \n",
    "- Bei jeder Probe wurden vier Merkmale gemessen: die Länge und die Breite der Kelch- und Blütenblätter in Zentimetern.\n",
    "- Auf der Grundlage der Kombination dieser vier Merkmale entwickelte Fisher ein *lineares Diskriminanzmodell* zur Unterscheidung der Arten voneinander. \n",
    "\n",
    "- Iris Setosa\n",
    "- Iris Versicolor\n",
    "- Iris Virginica\n",
    "\n",
    "\n",
    "Es handelt sich hier um eine Aufgabe des **überwachten Lernens** (supervised): **Klassifizierung**\n",
    "- Die *Features* $X_i \\, (i=1, \\dots 4)$ sind die Längen der Blüten und Kelchblätter in cm.\n",
    "- Das *Label* $y$ ist die Art der Lilie (setosa, ,virginica, versicolor), hier als Integer (diskret) repräsentiert.\n",
    "- Wäre das Label als Zeichenkette codiert (d.h. mit Namen), müssten wir erst durch einen `LabelEncoder` diese Klassen erzeugen.\n",
    "\n",
    "Wir erzeugen als erstes einen `pandas`-Dataframe (tidy data) dieses Datensatzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN01/Bilder/iris_setosa.jpg\"\n",
    "display(Image(url=url))\n",
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN01/Bilder/iris_versicolor.jpg\"\n",
    "display(Image(url=url))\n",
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN01/Bilder/iris_virginica.jpg\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "iris.feature_names\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df[\"class\"] = y\n",
    "df.tail(10)\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit `describe`lässt sich die 5-Werte-Statistik berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spannend sind immer die Korrelationen zwichen den Features und den Features und der Response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(8, 7))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    vmax=0.3,\n",
    "    center=0,\n",
    "    annot=True,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.5},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am besten visualisiert man diese durch einen `pairplot` (Scatterplot, Streudiagramm):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df)\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binäre Klassifizierung\n",
    "\n",
    "- Nun verwenden wir nur zwei Merkmale (Featrures) als Input (petal length, petal width) und entscheiden nur, ob es sich um eine Iris Setosa handelt oder nicht.\n",
    "- Wir verwenden das Perceptron-Modell von scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(int)\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[4.5, 0.8]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "    np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "    np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    ")\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y == 0, 0], X[y == 0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y == 1, 0], X[y == 1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "\n",
    "\n",
    "custom_cmap = ListedColormap([\"#9898ff\", \"#fafab0\"])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "plt.savefig(\"Bilder/perceptron_iris_plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In einer Monografie aus dem Jahr 1969 mit dem Titel *Perceptrons* hoben **Marvin Minsky** und **Seymour Papert** eine Reihe ernster Nachteile von Perzeptrons hervor, insbesondere ihr Versagen bei einer Reihe trivialer Probleme (z.B. das exklusive OR\n",
    "(XOR) als Klassifikationsaufgabe; dargestellt auf der linken Seite der folgenden Abbildung. Natürlich gilt dies auch für jedes andere lineare Klassifikationsmodell (wie die logistische Regression). In der Folge wandten sich viele Wissenschaftler vom *Konnektionismus* insgesamt ab (d.h. dem Studium neuronaler Netze), um sich übergeordneten Aufgabenstellungen wie\n",
    "Logik, Problemlösung und Suche zuzuwenden. Dies läutete den **ersten AI-Winter** ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN01/Bilder/perceptron3.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Es stellt sich aber heraus, dass sich einige dieser Beschränkungen aufheben lassen, indem man mehrere Perzeptrons in Reihe schaltet. Das dabei entstehende ANN bezeichnet man als mehrschichtiges Perzeptron (MLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mehrschichtiges Perzeptron (MLP) und Backpropagation\n",
    "\n",
    "Ein MLP setzt sich aus einer Eingabeschicht (zum Durchreichen) und einer oder mehreren Schichten von LTUs zusammen, den verborgenen Schichten, und einer letzten Schicht LTUs, der Ausgabeschicht. Bis auf die Ausgabeschicht\n",
    "enthält jede Schicht ein Bias-Neuron und ist mit der nächsten Schicht vollständig verbunden. Wenn ein ANN aus zwei oder mehr verborgenen Schichten besteht, bezeichnet man es auch als Deep-Learning-Netz (DNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN01/Bilder/MLP.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Viele Jahre lang haben Forscher vergeblich nach einer Möglichkeit zum Trainieren von MLPs gesucht. Im Jahr 1986 aber publizierten D. E. Rumelhart et al. einen wegweisenden Artikel (https://goo.gl/Wl7Xyc), der den Backpropagation-Algorithmus\n",
    "bekannt machte. Heute würden wir ihn als **Gradientenverfahren mit Autodiff im Reverse-Modus** beschreiben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Vorwärtspfad**: Der Algorithmus speist jeden Trainingsdatenpunkt in das Netz ein und berechnet die Ausgabe jedes Neurons in jeder aufeinanderfolgenden Schicht (dies ist ein vorwärts gerichteter Durchlauf wie beim Treffen von Vorhersagen). \n",
    "- **Error-Berechnung**: Anschliessend wird der Fehler der Ausgabe des Netzes gemessen (d.h. die Differenz zwischen der gewünschten und der tatsächlichen Ausgabe). Für jedes Neuron in der letzten verborgenen Schicht wird dann bestimmt, wie stark es zum Fehler der Ausgabe beitrug.\n",
    "- **Rückwärtspfad**:Anschliessend wird berechnet, welcher Teil dieser Fehlerbeiträge auf jedes Neuron in der vorigen verborgenen Schicht entfiel – und so weiter, bis der Algorithmus die Eingabeschicht erreicht. In diesem rückwärtigen Durchlauf wird der Fehlergradient über sämtliche Gewichte im Netz zurückverfolgt (daher der Name Backpropagation). \n",
    "\n",
    "Der letzte Schritt des Backpropagation-Algorithmus ist ein Schritt im Gradientenverfahren auf allen Gewichten im Netz unter Verwendung des zuvor bestimmten Gradienten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aktivierungsfunktionen\n",
    "\n",
    "Damit dieser Algorithmus gut funktioniert, nahmen die Autoren eine wichtige Änderung an der Architektur des MLP vor: Sie ersetzten die Stufenfunktion mit der logistischen Funktion \n",
    "\n",
    "$$ \n",
    "\\sigma(z) = \\frac{1}{1 + e^{–z}}\n",
    "$$. \n",
    "\n",
    "Dies erwies sich als entscheidend, weil die Stufenfunktion nur flache Abschnitte enthält und es daher keinen Gradienten\n",
    "gibt (die Gradientenmethode kann sich auf einer flachen Oberfläche nicht bewegen), wohingegen die Ableitung der logistischen Funktion überall ungleich null ist. Damit kann die Gradientenmethode an jeder Stelle ein wenig voranschreiten.\n",
    "Der Backpropagation-Algorithmus lässt sich auch mit anderen Aktivierungsfunktionen als der logistischen Funktion einsetzen. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Zwei weitere **beliebte Aktivierungsfunktionen** sind:\n",
    "\n",
    "\n",
    "- **Der Tangens hyperbolicus** $\\tanh(z)$: Wie die logistische Funktion ist der Tangens S-förmig, stetig und differenzierbar, aber die Ausgabewerte liegen im Bereich zwischen –1 und 1 (anstatt von 0 bis 1 bei der logistischen Funktion). Damit wird die Ausgabe jeder Schicht zu Beginn des Trainings tendenziell normalisiert (d.h. auf 0 zentriert). Dies beschleunigt bisweilen die Konvergenz.\n",
    "- Die **ReLU-Funktion** $\\operatorname{ReLU}(z) = \\max (0, z)$: Diese Funktion ist stetig, aber bei $z = 0$ leider nicht differenzierbar. In der Praxis funktioniert diese Funktion aber sehr gut und ist ausserdem schnell berechenbar. Wichtiger ist, dass sie keinen maximalen Ausgabewert besitzt, was einige Probleme des Gradientenverfahrens umgeht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps)) / (2 * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z, np.sign(z), \"r-\", linewidth=2, label=\"Step\")\n",
    "plt.plot(z, logit(z), \"g--\", linewidth=2, label=\"Logit\")\n",
    "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Aktivierungsfunktionen\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=2, label=\"Step\")\n",
    "plt.plot(0, 0, \"ro\", markersize=5)\n",
    "plt.plot(0, 0, \"rx\", markersize=10)\n",
    "plt.plot(z, derivative(logit, z), \"g--\", linewidth=2, label=\"Logit\")\n",
    "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "# plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Ableitung\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "plt.savefig(\"activation_functions_plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Klassifizieren mit einem softmax-Layer\n",
    "\n",
    "Ein MLP wird häufig zur Klassifikation eingesetzt, wobei jede Ausgabe einer anderen binären Kategorie entspricht (z.B. Spam/Ham, dringend/nicht dringend und so weiter). Falls die Kategorien sich gegenseitig ausschliessen (z.B. Kategorien von 0\n",
    "bis 9 bei der Klassifikation der Bilder von Ziffern), werden in der Ausgabeschicht normalerweise die einzelnen Aktivierungsfunktionen durch eine gemeinsame Softmax-Funktion ersetzt. Die **Softmax-Funktion** ist definiert durch:\n",
    "\n",
    "$$\n",
    "\\hat{p}_k = \\sigma\\left[\\mathbf{s}(\\mathbf{x})\\right]_k = \\dfrac{\\exp\\left(s_k(\\mathbf{x})\\right)}{\\sum\\limits_{j=1}^{K}{\\exp\\left(s_j(\\mathbf{x})\\right)}}\n",
    "$$\n",
    "\n",
    "Die Ausgabe jedes Neurons entspricht dann der geschätzten Wahrscheinlichkeit der entsprechenden Kategorie. Beachten Sie, dass das Signal nur in eine Richtung fliesst (von der Ein- zur Ausgabe). Daher ist diese Architektur ein Beispiel für ein **Feed-Forward-Netz** (engl. Feedforward Neural Networks, FNN).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/master/ANN01/Bilder/softmax.png\"\n",
    "display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bemerkung: *Biologische Neuronen scheinen eine in etwa sigmoide (S-förmige) Aktivierungsfunktion zu implementieren, daher hatte sich die Wissenschaft sehr lange auf Sigmoidalfunktionen eingeschossen. In ANNs funktioniert ReLU als Aktivierungsfunktion jedoch meist besser. In diesem Fall war die biologische Analogie irreführend.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python 3.8.6/tensorflow==2.5.0/keras==2.4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Die MNIST-Datensammlung ist Bestandteil von `torchvision` und steht in Form von vier\n",
    "Numpy-Arrays zur Verfügung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation for the MNIST dataset\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# Extract the data and labels\n",
    "train_images = train_dataset.data\n",
    "train_labels = train_dataset.targets\n",
    "test_images = test_dataset.data\n",
    "test_labels = test_dataset.targets\n",
    "\n",
    "# Check the shape of the training images\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Wenn Sie sich eingehender mit Machine Learning befassen, wird Ihnen die MNIST-Datensammlung immer wieder begegnen, in wissenschaftlichen Arbeiten, Blogbeiträgen usw. Der folgende Code-Snippet zeigt einige Beispiele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_digit(train_images[1549])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size, size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap=matplotlib.cm.binary, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 9))\n",
    "example_images = train_images[:40000:600]\n",
    "plot_digits(example_images, images_per_row=10)\n",
    "plt.show()\n",
    "# fig.savefig('more_digits_plot.png',format='png',dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`train_images` und `train_labels` bilden den \"Trainingssatz\", die Daten, aus denen das Modell lernt. Das Modell wird dann auf der\n",
    "\"test set\", `test_images` und `test_labels`. Unsere Bilder sind als Numpy-Arrays codiert und die Labels sind einfach ein Array von Ziffern, die von 0 bis 9 reichen. Es besteht eine Eins-zu-Eins-Entsprechung zwischen den Bildern und den Etiketten.\n",
    "\n",
    "Schauen wir uns die Trainingsdaten an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Schauen wir uns die Testdaten an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Unser Arbeitsablauf sieht wie folgt aus: Zuerst präsentieren wir unser neuronales Netz mit den Trainingsdaten `train_images` und `train_labels`. Das\n",
    "Netzwerk lernt dann, Bilder und Labels zuzuordnen. Schließlich werden wir das Netzwerk bitten, Vorhersagen für `test_images` zu erstellen, und wir überprüfen, ob diese Vorhersagen mit den Labels von `test_labels` übereinstimmen.\n",
    "\n",
    "Lassen Sie uns unser Netzwerk aufbauen – denken Sie noch einmal daran, dass Sie noch nicht alles über dieses Beispiel verstehen sollen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Der folgende Code implementiert ein einfaches neuronales Netz zur Klassifikation von MNIST-Daten in PyTorch Lightning. Hier ist eine ausführliche Erklärung der einzelnen Schritte:\n",
    "\n",
    "\n",
    "#### **1. Bibliotheken importieren**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "```\n",
    "\n",
    "- **`torch`**: Hauptbibliothek für maschinelles Lernen mit PyTorch.\n",
    "- **`nn`**: Enthält Module, um neuronale Netzwerke aufzubauen (z. B. `Linear`, `ReLU`).\n",
    "- **`pytorch_lightning`**: Eine High-Level-Bibliothek, die das Training und die Verwaltung von Modellen in PyTorch vereinfacht.\n",
    "\n",
    "\n",
    "\n",
    "#### **2. Definition des Modells**\n",
    "\n",
    "```python\n",
    "class MNISTModel(pl.LightningModule):\n",
    "    def __init__(self, input_size=28*28, hidden_size=512, num_classes=10, learning_rate=0.001):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Define the model architecture\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.hparams.input_size, self.hparams.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hparams.hidden_size, self.hparams.num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Define the loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "```\n",
    "\n",
    "##### **Erklärung:**\n",
    "- **`__init__`**: Initialisiert das Modell.\n",
    "    - `input_size`: Größe des Eingabevektors (28 × 28 für MNIST-Bilder).\n",
    "    - `hidden_size`: Anzahl der Neuronen in der versteckten Schicht.\n",
    "    - `num_classes`: Anzahl der Klassen (10 Ziffern: 0–9).\n",
    "    - `learning_rate`: Lernrate für den Optimierungsalgorithmus.\n",
    "- **`save_hyperparameters()`**: Speichert alle Hyperparameter, damit sie für Logging und Checkpoints verfügbar sind.\n",
    "- **Modellarchitektur (`nn.Sequential`)**:\n",
    "    - `nn.Linear`: Vollverbundene Schichten (Input → Hidden → Output).\n",
    "    - `nn.ReLU`: Aktivierungsfunktion, um Nichtlinearitäten einzuführen.\n",
    "    - `nn.Softmax`: Normalisiert die Ausgaben der letzten Schicht zu Wahrscheinlichkeiten.\n",
    "- **Verlustfunktion (`CrossEntropyLoss`)**:\n",
    "    - Misst den Unterschied zwischen vorhergesagten Wahrscheinlichkeiten und den Zielwerten.\n",
    "\n",
    "\n",
    "\n",
    "#### **3. Vorwärtspropagation**\n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "    return self.model(x)\n",
    "```\n",
    "\n",
    "- **`forward`**: Definiert, wie die Eingabedaten durch das Modell verarbeitet werden.\n",
    "- Nimmt den Eingabevektor `x` und leitet ihn durch die Modellarchitektur (`self.model`).\n",
    "\n",
    "\n",
    "\n",
    "#### **4. Trainingsschritt**\n",
    "\n",
    "```python\n",
    "def training_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    x = x.view(x.size(0), -1)  # Flatten the input\n",
    "    preds = self(x)\n",
    "    loss = self.loss_fn(preds, y)\n",
    "    self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "```\n",
    "\n",
    "##### **Erklärung:**\n",
    "- **`training_step`**: Führt einen einzelnen Trainingsschritt aus.\n",
    "    - `batch`: Ein Batch von Eingabedaten (Bilder und Labels).\n",
    "    - `batch_idx`: Index des Batches.\n",
    "- **Input-Transformation**:\n",
    "    - `x.view(x.size(0), -1)`: Flacht die Bilder (28 × 28) zu einem Vektor (784) ab.\n",
    "- **Vorhersage**:\n",
    "    - `preds = self(x)`: Berechnet die Ausgabe des Modells.\n",
    "- **Verlustberechnung**:\n",
    "    - `self.loss_fn(preds, y)`: Vergleicht die Vorhersagen mit den Labels und berechnet den Cross-Entropy-Verlust.\n",
    "- **Logging**:\n",
    "    - `self.log`: Loggt den Trainingsverlust für jeden Schritt und jede Epoche (für Monitoring).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lightning\n",
    "\n",
    "\n",
    "class MNISTModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, input_size=28 * 28, hidden_size=512, num_classes=10, learning_rate=0.001\n",
    "    ):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Define the model architecture\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.hparams.input_size, self.hparams.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hparams.hidden_size, self.hparams.num_classes),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        # Define the loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.train_accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        preds = self(x)\n",
    "        loss = self.loss_fn(preds, y)\n",
    "\n",
    "        # Log loss and accuracy\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"train_accuracy\",\n",
    "            self.train_accuracy(preds, y),\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        preds = self(x)\n",
    "        loss = self.loss_fn(preds, y)\n",
    "\n",
    "        # Log validation loss and accuracy\n",
    "        self.log(\n",
    "            \"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"val_accuracy\",\n",
    "            self.val_accuracy(preds, y),\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device: CUDA if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to selected device\n",
    "model = MNISTModel().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(1, 28 * 28))  # 1 is the batch size (arbitrary here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Der wichtigste Baustein eines NNs ist layers, ein **Datenverarbeitungsmodul**, das Sie sich wie einen Datenfilter vorstellen können. Es nimmt Daten entgegen und gibt sie in einer nützlicheren Form wieder aus. Das Modul extrahiert aus den eingegebenen Daten Repräsentationen, die für eine gegebene Aufgabe hoffentlich sinnvoller sind als die Rohdaten. \n",
    "\n",
    "Ein Grossteil des Deep Learnings besteht aus dem Verketten einfacher Layer, die eine Art von schrittweiser Datendestillation implementieren. Ein Deep-Learning-Modell ähnelt einem *Sieb für die Datenverarbeitung*, das aus einer Abfolge von immer ausgeklügelteren Datenfiltern besteht – den Layern.\n",
    "\n",
    "In diesem Fall besteht das NN aus zwei vollständig miteinander verbundenen Layern des Typs Dense. Beim zweiten (und letzten) Layer handelt es sich um einen 10-fachen Softmax-Layer. Das bedeutet, dass er ein Array ausgibt, das 10 Wahrscheinlichkeitswerte enthält (die sich zu 1 summieren). Diese Werte geben die Wahrscheinlichkeit an, dass die aktuelle Ziffer zu einer der 10 Ziffernklassen gehört.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ModelSummary(model, max_depth=-1))  # max_depth=-1 prints all layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Um das NN für das Training vorzubereiten, müssen wir bei der Kompilierung drei weitere Dinge festlegen:\n",
    "1. Eine **Verlustfunktion (loss)** – Sie beschreibt, wie das NN seine Leistung für die Trainingsdaten beurteilen kann, und damit auch, wie es Korrekturen in der richtigen Richtung vornehmen kann.\n",
    "2. Einen **Optimierer (optimizer)** – Der Mechanismus, durch den sich das NN anhand der bekannten Daten und der dazugehörigen Werte der Verlustfunktion selbst aktualisiert.\n",
    "3. Beim Trainieren und Testen **zu überwachende Kennzahlen (metric)** – In diesem Fall sind wir lediglich an der Korrektklassifizierungsrate interessiert (dem Anteil der richtig klassifizierten Bilder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **5. Optimierer konfigurieren**\n",
    "\n",
    "```python\n",
    "def configure_optimizers(self):\n",
    "    return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "```\n",
    "\n",
    "- **`configure_optimizers`**: Definiert den Optimierungsalgorithmus.\n",
    "    - **`Adam`**: Ein Optimierer, der den Gradientenabstieg verbessert.\n",
    "    - Verwendet die gespeicherte Lernrate `self.hparams.learning_rate`.\n",
    "\n",
    "\n",
    "\n",
    "#### **6. Training des Modells**\n",
    "\n",
    "```python\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load the dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Instantiate the model\n",
    "model = MNISTModel()\n",
    "\n",
    "# Train the model\n",
    "trainer = pl.Trainer(max_epochs=5, log_every_n_steps=10)\n",
    "trainer.fit(model, train_loader)\n",
    "```\n",
    "\n",
    "##### **Erklärung:**\n",
    "1. **Datenvorbereitung**:\n",
    "    - **`transforms.ToTensor()`**: Konvertiert Bilder in PyTorch-Tensoren.\n",
    "    - **`transforms.Normalize`**: Normalisiert die Pixelwerte auf den Bereich [-1, 1].\n",
    "2. **Datenladefunktion (`DataLoader`)**:\n",
    "    - Erzeugt Batches der Eingabedaten (Batchgröße: 64).\n",
    "    - `shuffle=True`: Mischt die Daten für jeden Durchgang (Epoche).\n",
    "3. **Modellinstanziierung**:\n",
    "    - `model = MNISTModel()`: Erstellt eine Instanz des definierten Modells.\n",
    "4. **Trainer**:\n",
    "    - `pl.Trainer`: Verwaltet das Training.\n",
    "    - `max_epochs=5`: Trainiert das Modell für 5 Epochen.\n",
    "    - `log_every_n_steps=10`: Loggt alle 10 Schritte den Fortschritt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "de",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vor dem Training werden wir unsere Daten vorverarbeiten, indem wir sie in die vom Netzwerk erwartete Form umformen und sie so skalieren, dass alle Werte im Intervall `[0, 1]` leigen. Die Trainingsbilder sind beispielsweise in einem Array der\n",
    "Form `[60000, 28, 28]` und des Typs `uint8` mit Werten im Intervall `[0, 255]` gespeichert. Wir wandeln es in ein `float32`-Array der Form `[60000, 28 * 28]` mit Werten zwischen `0` und `1` um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=True, num_workers=15, persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "val_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=64, shuffle=False, num_workers=15, persistent_workers=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Jetzt können wir das NN trainieren. Zu diesem Zweck wird in Keras die `fit()`- Methode aufgerufen, die das Modell an die Trainingsdaten anpasst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Logger initialisieren\n",
    "logger = CSVLogger(save_dir=\"logs\", name=\"mnist\")\n",
    "\n",
    "# Trainer initialisieren\n",
    "trainer = pl.Trainer(max_epochs=10, log_every_n_steps=5, logger=logger)\n",
    "\n",
    "# Training starten\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Während des Trainings werden zwei Werte angezeigt: \n",
    "- der **Wert der Verlustfunktion (loss)** und \n",
    "- die **Korrektklassifizierungsrate (acc)** für die Trainingsdaten.\n",
    "\n",
    "Wir erzielen für die Trainingsdaten schon bald eine Korrektklassifizierungsrate von 0.989 (98.9 %). Nun überprüfen wir, ob das Modell mit den Testdaten genauso gut zurechtkommt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# results = trainer.validate(model, dataloaders=val_loader)\n",
    "# print(results)  # This will output the logged validation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Die Korrektklassifizierungsrate für die Testdatenmenge beträgt 97,8% – deutlich weniger als bei den Trainingsdaten. Diese Differenz zwischen den Korrektklassifizierungsraten von Trainings- und Testdatenmenge ist ein typisches Beispiel für\n",
    "eine Überanpassung: Die Leistung von Machine-Learning-Modellen ist bei neuen Daten tendenziell schlechter als bei den Trainingsdaten. Die **Überanpassung (overfitting)** ist das Hauptthema einer der folgenden Lektionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV-Logdatei laden\n",
    "log_data = pd.read_csv(\"./logs/mnist/version_0/metrics.csv\")\n",
    "\n",
    "\n",
    "log_data.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainings- und Validierungsdaten extrahieren\n",
    "train_loss = log_data[\"train_loss_epoch\"].dropna()\n",
    "val_loss = log_data[\"val_loss_epoch\"].dropna()\n",
    "train_acc = log_data[\"train_accuracy\"].dropna()\n",
    "val_acc = log_data[\"val_accuracy\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\", marker=\"o\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot: Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_acc, label=\"Train Accuracy\", marker=\"o\")\n",
    "plt.plot(val_acc, label=\"Validation Accuracy\", marker=\"o\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "de",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "de",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
