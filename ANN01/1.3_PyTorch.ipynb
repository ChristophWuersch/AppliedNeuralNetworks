{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> \n",
    "\n",
    "[View Source Code](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb) | [View Slides](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/slides/00_pytorch_and_deep_learning_fundamentals.pdf) | [Watch Video Walkthrough](https://youtu.be/Z_ikDlimN6A?t=76) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSNK7duj5SeU"
   },
   "source": [
    "# 1.3 PyTorch Grundlagen\n",
    "\n",
    "- [PyTorch] (https://pytorch.org/) ist ein Open-Source-Framework für maschinelles Lernen und Deep Learning.\n",
    "- Quelle: [Daniel Bourke](https://github.com/mrdbourke)\n",
    "\n",
    "## Was ist PyTorch?\n",
    "PyTorch ist ein Open-Source-Framework für maschinelles Lernen und Deep Learning. Mit PyTorch können Sie Daten manipulieren und verarbeiten und Algorithmen für maschinelles Lernen mit Python-Code schreiben. Viele der weltweit größten Technologieunternehmen wie [Meta (Facebook)](https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/), Tesla und Microsoft sowie Forschungsunternehmen für künstliche Intelligenz wie [OpenAI verwenden PyTorch](https://openai.com/blog/openai-pytorch/), um ihre Forschung voranzutreiben und maschinelles Lernen in ihre Produkte zu integrieren.\n",
    "\n",
    "![pytorch wird in Industrie und Forschung eingesetzt](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-being-used-across-research-and-industry.png)\n",
    "\n",
    "Andrej Karpathy (Leiter der Abteilung für künstliche Intelligenz bei Tesla) hat beispielsweise in mehreren Vorträgen ([PyTorch DevCon 2019](https://youtu.be/oBklltKXtDE), [Tesla AI Day 2021](https://youtu.be/j0z4FweCy4M?t=2904)) darüber gesprochen, wie Tesla PyTorch nutzt, um seine selbstfahrenden Computer-Vision-Modelle zu betreiben.\n",
    "\n",
    "PyTorch wird auch in anderen Branchen eingesetzt, z. B. in der Landwirtschaft, um [Computer Vision auf Traktoren zu betreiben](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1).\n",
    "\n",
    "\n",
    "## Warum PyTorch verwenden?\n",
    "Forscher im Bereich des maschinellen Lernens verwenden PyTorch sehr gerne. Und im Februar 2022 ist PyTorch das [meistgenutzte Deep-Learning-Framework auf Papers With Code] (https://paperswithcode.com/trends), einer Website zur Verfolgung von Forschungsarbeiten zum maschinellen Lernen und den dazugehörigen Code-Repositories. PyTorch kümmert sich auch um viele Dinge wie GPU-Beschleunigung (damit Ihr Code schneller läuft) im Hintergrund. Sie können sich also auf die Bearbeitung von Daten und das Schreiben von Algorithmen konzentrieren, und PyTorch sorgt dafür, dass diese schnell ausgeführt werden. Und wenn Unternehmen wie Tesla und Meta (Facebook) es nutzen, um Modelle zu erstellen, mit denen sie Hunderte von Anwendungen betreiben, Tausende von Autos antreiben und Inhalte für Milliarden von Menschen bereitstellen, ist es eindeutig auch an der Entwicklungsfront fähig.\n",
    "\n",
    "## Was wir in diesem Modul behandeln werden\n",
    "\n",
    "| **Thema** | **Inhalt** |\n",
    "| ----- | ----- |\n",
    "| **Einführung in Tensoren** | Tensoren sind der Grundbaustein für maschinelles Lernen und Deep Learning. |\n",
    "| **Erstellen von Tensoren** | Tensoren können fast jede Art von Daten darstellen (Bilder, Wörter, Zahlentabellen). |\n",
    "| **Informationen aus Tensoren gewinnen** | Wenn man Informationen in einen Tensor eingeben kann, will man sie auch wieder herausbekommen. |\n",
    "| **Manipulation von Tensoren** | Algorithmen für maschinelles Lernen (wie neuronale Netze) beinhalten die Manipulation von Tensoren auf viele verschiedene Arten, wie z. B. Addition, Multiplikation, Kombination. |\n",
    "| Eines der häufigsten Probleme beim maschinellen Lernen ist der Umgang mit Formfehlern (der Versuch, falsch geformte Tensoren mit anderen Tensoren zu mischen). |\n",
    "| **Indizierung auf Tensoren** | Wenn Sie schon einmal auf einer Python-Liste oder einem NumPy-Array indiziert haben, ist es bei Tensoren sehr ähnlich, außer dass sie viel mehr Dimensionen haben können. |\n",
    "| PyTorch spielt mit Tensoren ([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)), NumPy mag Arrays ([`np.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)). Manchmal werden Sie diese mischen und anpassen wollen. |\n",
    "| **Reproduzierbarkeit** | Maschinelles Lernen ist sehr experimentell und da es eine Menge *Zufälligkeit* verwendet, um zu funktionieren, wollen Sie manchmal, dass diese *Zufälligkeit* nicht so zufällig ist. |\n",
    "| **Ausführen von Tensoren auf GPU** | GPUs (Graphics Processing Units) machen Ihren Code schneller, PyTorch macht es einfach, Ihren Code auf GPUs auszuführen. |\n",
    "\n",
    "Alle Materialien für diesen Kurs [live auf GitHub] (https://github.com/mrdbourke/pytorch-deep-learning).\n",
    "Und wenn Sie auf Probleme stoßen, können Sie dort auch eine Frage auf der [Diskussionsseite](https://github.com/mrdbourke/pytorch-deep-learning/discussions) stellen. Es gibt auch die [PyTorch-Entwicklerforen](https://discuss.pytorch.org/), ein sehr hilfreicher Ort für alles, was mit PyTorch zu tun hat.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5v3iRCRUTGeu"
   },
   "source": [
    "## Importieren von PyTorch\n",
    "\n",
    "> **Hinweis:** Bevor Sie den Code in diesem Notizbuch ausführen, sollten Sie die [PyTorch-Einrichtungsschritte] (https://pytorch.org/get-started/locally/) durchlaufen haben.\n",
    "> **Wenn Sie jedoch mit Google Colab** arbeiten, sollte alles funktionieren (Google Colab wird mit PyTorch und anderen Bibliotheken installiert).\n",
    "\n",
    "Beginnen wir damit, PyTorch zu importieren und die verwendete Version zu überprüfen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1VxEOik46Y4i",
    "outputId": "f3141076-29bc-4600-c1c3-1586b1fe2292"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0+cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SqvI4S9TGew"
   },
   "source": [
    "Dies bedeutet, wenn Sie durch diese Materialien gehen, werden Sie sehen, die meisten Kompatibilität mit PyTorch 2.0.0 +, aber wenn Ihre Versionsnummer ist weit höher als das, könnten Sie einige Unstimmigkeiten bemerken.\n",
    "\n",
    "Und wenn Sie irgendwelche Probleme haben, posten Sie bitte im Kurs [GitHub Discussions page] (https://github.com/mrdbourke/pytorch-deep-learning/discussions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-33BKR16iWc"
   },
   "source": [
    "## Einführung in Tensoren\n",
    "\n",
    "Nachdem wir nun PyTorch importiert haben, ist es an der Zeit, etwas über Tensoren zu lernen. Tensoren sind der grundlegende Baustein des maschinellen Lernens. Ihre Aufgabe ist es, Daten auf numerische Weise darzustellen.\n",
    "\n",
    "Zum Beispiel könnte man ein Bild als Tensor mit der Form `[3, 224, 224]` darstellen, was `[Farbkanäle, Höhe, Breite]` bedeuten würde, denn das Bild hat `3` Farbkanäle (rot, grün, blau), eine Höhe von `224` Pixeln und eine Breite von `224` Pixeln.\n",
    "\n",
    "![Beispiel für die Umwandlung eines Eingabebildes in eine Tensordarstellung des Bildes, das Bild wird in 3 Farbkanäle sowie in Zahlen zur Darstellung der Höhe und Breite zerlegt](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)\n",
    "\n",
    "In der Tensor-Sprache (der Sprache, die zur Beschreibung von Tensoren verwendet wird) hätte der Tensor drei Dimensionen, eine für \"Farbkanäle\", \"Höhe\" und \"Breite\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFF0N2TU7S7Q"
   },
   "source": [
    "### Tensoren erstellen\n",
    "\n",
    "PyTorch liebt Tensoren. So sehr, dass es eine ganze Dokumentationsseite gibt, die der Klasse [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) gewidmet ist. Ihre erste Hausaufgabe ist es, 10 Minuten lang [die Dokumentation zu `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) durchzulesen. Aber dazu können Sie später kommen. \n",
    "\n",
    "- Das erste, was wir erstellen werden, ist ein **Skalar**. \n",
    "- Ein Skalar ist eine einzelne Zahl, und in der Tensor-Sprache ist es ein Tensor mit null Dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUDgG2zk7Us5",
    "outputId": "0ac22bd2-16bc-4307-f312-31ae89d6c375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqSuhW7rTGey"
   },
   "source": [
    "- Sehen Sie, wie oben `Tensor(7)` ausgedruckt wird? \n",
    "- Das bedeutet, obwohl `Skalar` eine einzelne Zahl ist, ist sie vom Typ `Torch.Tensor`.\n",
    "- Wir können die Dimensionen eines Tensors mit dem Attribut `ndim` überprüfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV98Yz868bav",
    "outputId": "502a625e-ff3c-4fc4-b523-f7634ea82128"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO2YW_QGTGez"
   },
   "source": [
    "Was wäre, wenn wir die Zahl aus dem Tensor abrufen wollten?\n",
    "\n",
    "- Zum Beispiel, indem wir sie von `torch.Tensor` in eine Python-Ganzzahl umwandeln?\n",
    "- Dazu können wir die Methode `item()` verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-k4cyKumPfbE",
    "outputId": "1f6a7916-0c7c-403f-8ebd-875454a94470"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Python number within a tensor (only works with one-element tensors)\n",
    "scalar.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYs7ulrATGe0"
   },
   "source": [
    "Okay, sehen wir uns jetzt einen **Vektor** an.\n",
    "\n",
    "- Ein Vektor ist ein eindimensionaler Tensor, kann aber viele Zahlen enthalten.\n",
    "- Du könntest z.B. einen Vektor `[3, 2]` haben, um `[Schlafzimmer, Bäder]` in deinem Haus zu beschreiben. Oder du könntest `[3, 2, 2]` haben, um `[Schlafzimmer, Badezimmer, Parkplätze]` in deinem Haus zu beschreiben.\n",
    "- Die wichtige Eigenschaft hier ist, dass ein Vektor flexibel ist in dem, was er darstellen kann (dasselbe gilt für Tensoren).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IZF6ASs8QH9",
    "outputId": "e556ed2a-e58a-440f-b103-0f06c91bc75c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXxRUUW2TGe1"
   },
   "source": [
    "Wunderbar, \"Vektor\" enthält jetzt zwei 7er, meine Lieblingszahl.\n",
    "\n",
    "Wie viele Dimensionen wird er wohl haben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03hm3VVv8kr4",
    "outputId": "2035bb26-0189-4b28-fa02-34220d44677f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of dimensions of vector\n",
    "vector.ndim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0VYvSGbTGe1"
   },
   "source": [
    "Hmm, das ist seltsam, `vector` enthält zwei Zahlen, hat aber nur eine einzige Dimension.\n",
    "\n",
    "\n",
    "- Sie können die Anzahl der Dimensionen eines Tensors in PyTorch an der Anzahl der eckigen Klammern auf der Außenseite (`[`) erkennen, und Sie brauchen nur eine Seite zu zählen.\n",
    "- Wie viele eckige Klammern hat `vector`?\n",
    "- Ein weiteres wichtiges Konzept für Tensoren ist ihr Attribut `shape`. Die Form gibt an, wie die Elemente in ihnen angeordnet sind.\n",
    "\n",
    "Schauen wir uns die Form von `vector` an.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zREV1bDTGe2",
    "outputId": "2a6e7ceb-7eb2-422b-b006-2c6e4825272f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of vector\n",
    "vector.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aWKppNyTGe2"
   },
   "source": [
    "Das obige Ergebnis ist `torch.Size([2])`, was bedeutet, dass unser Vektor eine Form von `[2]` hat. Das liegt an den beiden Elementen, die wir innerhalb der eckigen Klammern platziert haben (`[7, 7]`).\n",
    "\n",
    "Sehen wir uns nun eine **Matrix** an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5iNwCYL8QO9",
    "outputId": "88fc63a7-4130-4c7a-a574-c61e85d2e99e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7, 8], [9, 10]])\n",
    "MATRIX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3U1bCdjTGe3"
   },
   "source": [
    "Wow! Mehr Zahlen! Matrizen sind genauso flexibel wie Vektoren, nur dass sie eine zusätzliche Dimension haben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LREUbeb8r8j",
    "outputId": "636246b0-b109-472a-c6d5-8601a9e08654"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of dimensions\n",
    "MATRIX.ndim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhXXgq-dTGe3"
   },
   "source": [
    "MATRIX\" hat zwei Dimensionen (haben Sie die Anzahl der eckigen Klammern auf der Außenseite einer Seite gezählt?).\n",
    "\n",
    "Welche \"Form\" wird er deiner Meinung nach haben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TL26I31TGe3",
    "outputId": "f05ec0b6-0bc1-4381-9474-56cbe6c67139"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvLpUvrKTGe4"
   },
   "source": [
    "Wir erhalten die Ausgabe `torch.Size([2, 2])`, weil `MATRIX` zwei Elemente tief und zwei Elemente breit ist.\n",
    "\n",
    "Wie wäre es, wenn wir einen **Tensor** erstellen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEMDQr188QWW",
    "outputId": "4230e6bd-1844-4210-eea8-245bb8b8b265"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3], [3, 6, 9], [2, 4, 5]]])\n",
    "TENSOR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmJKkXD7TGe4"
   },
   "source": [
    "Wahnsinn! Was für ein gut aussehender Tensor.\n",
    "\n",
    "Ich möchte betonen, dass Tensoren fast alles darstellen können.\n",
    "\n",
    "Der Tensor, den wir gerade erstellt haben, könnte die Verkaufszahlen für ein Steak- und ein Mandelbuttergeschäft darstellen (zwei meiner Lieblingslebensmittel).\n",
    "\n",
    "![ein einfacher Tensor in Google Sheets, der den Wochentag, die Steakverkäufe und die Mandelbutterverkäufe anzeigt](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_simple_tensor.png)\n",
    "\n",
    "Wie viele Dimensionen hat er Ihrer Meinung nach? (Tipp: Verwenden Sie den Trick mit den eckigen Klammern)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dhuEsjS8QcT",
    "outputId": "7a45df1b-fc32-4cc5-e330-527c6ef7ba5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of dimensions for TENSOR\n",
    "TENSOR.ndim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ln9dys5VTGe4"
   },
   "source": [
    "Und was ist mit seiner Form?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdVv4iNRTGe5",
    "outputId": "d8ac706c-020b-4926-b145-d44e41f35e90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of TENSOR\n",
    "TENSOR.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxk8GU7oTGe5"
   },
   "source": [
    "In Ordnung, es wird `torch.Size([1, 3, 3])` ausgegeben.\n",
    "\n",
    "- Die Dimensionen gehen von außen nach innen.\n",
    "- Das bedeutet, dass es 1 Dimension von 3 mal 3 gibt.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png\" alt=\"Beispiel für verschiedene Tensordimensionen\" width=\"800\">\n",
    "\n",
    "> **Anmerkung:** Sie haben vielleicht bemerkt, dass ich Kleinbuchstaben für `Skalar` und `Vektor` und Großbuchstaben für `MATRIX` und `TENSOR` verwendet habe. Das war Absicht. In der Praxis sieht man Skalare und Vektoren oft als Kleinbuchstaben wie \"y\" oder \"a\". Und Matrizen und Tensoren werden mit Großbuchstaben wie \"X\" oder \"W\" bezeichnet.\n",
    ">\n",
    "> Sie werden auch feststellen, dass die Bezeichnungen \"Matrix\" und \"Tensor\" synonym verwendet werden. Das ist üblich. Da man es in PyTorch oft mit `torch.Tensor` zu tun hat (daher der Tensorname), bestimmen die Form und die Dimensionen dessen, was sich darin befindet, was es tatsächlich ist.\n",
    "\n",
    "Lassen Sie uns zusammenfassen.\n",
    "\n",
    "| Name | Was ist es? | Anzahl der Dimensionen | Untere oder obere (normalerweise/Beispiel) |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "**Skalar** | eine einzelne Zahl | 0 | niedriger (`a`) |\n",
    "| **Vektor** | eine Zahl mit Richtung (z. B. Windgeschwindigkeit mit Richtung), kann aber auch viele andere Zahlen enthalten | 1 | Lower (`y`) |\n",
    "| **Matrix** | eine 2-dimensionale Anordnung von Zahlen | 2 | Upper (`Q`) |\n",
    "**Tensor** | eine n-dimensionale Anordnung von Zahlen | kann eine beliebige Zahl sein, ein Tensor der Dimension 0 ist ein Skalar, ein Tensor der Dimension 1 ist ein Vektor | Upper (`X`) |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png\" alt=\"Skalar-Vektor-Matrix-Tensor und wie sie aussehen\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dms7G4nkTGe5"
   },
   "source": [
    "### Zufällige Tensoren\n",
    "\n",
    "Wir haben festgestellt, dass Tensoren eine Form von Daten darstellen. Und maschinelle Lernmodelle wie neuronale Netze manipulieren und suchen Muster in Tensoren.\n",
    "Bei der Erstellung von maschinellen Lernmodellen mit PyTorch ist es jedoch selten, dass man Tensoren von Hand erstellt (wie wir es getan haben). Stattdessen beginnt ein maschinelles Lernmodell oft mit großen zufälligen Zahlentensoren und passt diese Zufallszahlen an, während es die Daten durcharbeitet, um sie besser darzustellen. \n",
    "Im Wesentlichen bedeutet dies:\n",
    "- \"Mit Zufallszahlen beginnen -> Daten betrachten -> Zufallszahlen aktualisieren -> Daten betrachten -> Zufallszahlen aktualisieren...\".\n",
    "\n",
    "Als Datenwissenschaftler können Sie festlegen, wie das Modell für maschinelles Lernen startet (Initialisierung), die Daten betrachtet (Darstellung) und seine Zufallszahlen aktualisiert (Optimierung). Wir werden uns später mit diesen Schritten befassen. Sehen wir uns zunächst an, wie man einen Tensor mit Zufallszahlen erstellt.\n",
    "\n",
    "Wir können dies mit [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) und der Übergabe des Parameters `size` tun.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOJEtDx--GnK",
    "outputId": "2680d44b-e31c-4ab1-d5b1-c0cd76706a0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6541, 0.4807, 0.2162, 0.6168],\n",
       "         [0.4428, 0.6608, 0.6194, 0.8620],\n",
       "         [0.2795, 0.6055, 0.4958, 0.5483]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wB1c_cXTGe5"
   },
   "source": [
    "Die Flexibilität von `torch.rand()` besteht darin, dass wir die `Größe so einstellen können, wie wir wollen. Nehmen wir zum Beispiel an, Sie wollten einen zufälligen Tensor in der üblichen Bildform von `[224, 224, 3]` (`[Höhe, Breite, Farbkanäle`])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMF_NUp3Ym__",
    "outputId": "8346b853-0b1e-481a-d9ee-a410ee21bab0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (224, 224, 3)\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MQNTY0eTGe6"
   },
   "source": [
    "### Nullen und Einsen\n",
    "\n",
    "Manchmal möchte man Tensoren einfach mit Nullen oder Einsen füllen. Dies geschieht häufig bei der Maskierung (z.B. Maskierung einiger Werte in einem Tensor mit Nullen, damit ein Modell weiß, dass es sie nicht lernen soll). Lassen Sie uns einen Tensor voller Nullen mit [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html) erstellen. Wieder kommt der Parameter `size` ins Spiel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCzhd0hl9Vp6",
    "outputId": "9c8ec87f-d8c9-4751-a13e-6a5e986daaa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros, zeros.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDQBZJRUZWTN"
   },
   "source": [
    "Wir können dasselbe tun, um einen Tensor mit allen Einsen zu erzeugen, aber stattdessen [`torch.ones()` ](https://pytorch.org/docs/stable/generated/torch.ones.html) verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRe6sSXiTGe6",
    "outputId": "3f45b0b8-7f65-423d-c664-f5b5f7866fd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hib1NYrSarL2"
   },
   "source": [
    "### Erstellen eines Bereichs und Tensoren wie\n",
    "\n",
    "Manchmal braucht man einen Zahlenbereich, z. B. 1 bis 10 oder 0 bis 100.\n",
    "\n",
    "Dazu können Sie `torch.arange(start, end, step)` verwenden.\n",
    "\n",
    "Wobei:\n",
    "* `Start` = Beginn des Bereichs (z.B. 0)\n",
    "* `Ende` = Ende des Bereichs (z.B. 10)\n",
    "* \"step\" = wie viele Schritte zwischen den einzelnen Werten (z.B. 1)\n",
    "\n",
    "> **Anmerkung:** In Python können Sie `range()` verwenden, um einen Bereich zu erstellen. In PyTorch ist `torch.range()` jedoch veraltet und kann in Zukunft einen Fehler anzeigen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1IqUs81d9W4W",
    "outputId": "2a6f0c08-052e-4b36-b4eb-6a537239026f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange(), torch.range() is deprecated\n",
    "zero_to_ten_deprecated = torch.arange(\n",
    "    0, 10\n",
    ")  # Note: this may return an error in the future\n",
    "\n",
    "# Create a range of values 0 to 10\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-bXf0Ugbh-D"
   },
   "source": [
    "- Manchmal möchte man einen Tensor eines bestimmten Typs mit der gleichen Form wie einen anderen Tensor haben.\n",
    "- Zum Beispiel einen Tensor mit lauter Nullen, der die gleiche Form hat wie ein vorheriger Tensor.\n",
    "- Dazu können Sie [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) oder [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) verwenden, die einen Tensor mit Nullen bzw. Einsen in der gleichen Form wie der `input` zurückgeben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvXwUut5BhHq",
    "outputId": "096b2f8e-8c21-4ace-97b9-c36b92b2fe77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also create a tensor of zeros similar to another tensor\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten)  # will have same shape\n",
    "ten_zeros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huKZ6QlYTGe7"
   },
   "source": [
    "### Tensor-Datentypen\n",
    "\n",
    "Es gibt viele verschiedene [Tensor-Datentypen in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "\n",
    "- Einige sind spezifisch für die CPU und einige sind besser für die GPU geeignet. Es kann einige Zeit dauern, um herauszufinden, welche das sind.\n",
    "- Wenn Sie irgendwo `torch.cuda` sehen, wird der Tensor im Allgemeinen für die GPU verwendet (da Nvidia GPUs ein Computing Toolkit namens CUDA verwenden).\n",
    "- Der gebräuchlichste Typ (und im Allgemeinen der Standard) ist `torch.float32` oder `torch.float`. Dies wird als \"32-Bit-Gleitkomma\" bezeichnet.\n",
    "- Aber es gibt auch 16-Bit-Gleitkomma (`torch.float16` oder `torch.half`) und 64-Bit-Gleitkomma (`torch.float64` oder `torch.double`). Und um die Dinge noch mehr zu verwirren, gibt es auch 8-Bit, 16-Bit, 32-Bit und 64-Bit Ganzzahlen.\n",
    "\n",
    "**Anmerkung:** Ein Integer ist eine flache, runde Zahl wie `7`, während ein Float eine dezimale `7.0` hat. Der Grund dafür ist die **Präzision beim Rechnen**. Die Genauigkeit ist die Detailgenauigkeit, die zur Beschreibung einer Zahl verwendet wird. Je höher der Präzisionswert (8, 16, 32), desto mehr Details und damit Daten werden zur Beschreibung einer Zahl verwendet. Dies ist beim Deep Learning und bei der numerischen Datenverarbeitung von Bedeutung, denn es werden so viele Operationen durchgeführt, dass der Rechenaufwand umso höher ist, je detaillierter die Daten sind.\n",
    "\n",
    "Datentypen mit geringerer Genauigkeit sind also in der Regel schneller in der Berechnung, haben aber Einbußen bei Bewertungsmetriken wie der Genauigkeit (schneller in der Berechnung, aber weniger genau).\n",
    "\n",
    "**Ressourcen:**\n",
    "  * Siehe die [PyTorch-Dokumentation für eine Liste aller verfügbaren Tensor-Datentypen](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "  * Lesen Sie die [Wikipedia-Seite für einen Überblick darüber, was Präzision in der Informatik](https://en.wikipedia.org/wiki/Precision_(computer_science)) ist.\n",
    "\n",
    "Schauen wir uns an, wie man einige Tensoren mit bestimmten Datentypen erstellt. Wir können dies mit dem Parameter `dtype` tun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3MoGnpw9XaF",
    "outputId": "61070939-8c52-4ac6-bed7-e64b3ce24615"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor(\n",
    "    [3.0, 6.0, 9.0],\n",
    "    dtype=None,  # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "    device=None,  # defaults to None, which uses the default tensor type\n",
    "    requires_grad=False,\n",
    ")  # if True, operations performed on the tensor are recorded\n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhP8kzDfe_ty"
   },
   "source": [
    "Abgesehen von Problemen mit der Form (Tensorformen stimmen nicht überein), sind zwei der häufigsten Probleme, auf die man in PyTorch stößt, Datentyp- und Geräteprobleme. Zum Beispiel ist einer der Tensoren `torch.float32` und der andere `torch.float16` (PyTorch möchte oft, dass die Tensoren das gleiche Format haben). Oder einer Ihrer Tensoren befindet sich auf der CPU und der andere auf der GPU (PyTorch möchte, dass die Berechnungen zwischen den Tensoren auf demselben Gerät stattfinden).\n",
    "\n",
    "Für den Moment wollen wir einen Tensor mit `dtype=torch.float16` erstellen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKSuajld_09s",
    "outputId": "cbac29d9-3371-4fe1-b47c-3af4623b5fbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor(\n",
    "    [3.0, 6.0, 9.0], dtype=torch.float16\n",
    ")  # torch.half would also work\n",
    "\n",
    "float_16_tensor.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUjkB2AX7Upz"
   },
   "source": [
    "## Informationen von Tensoren erhalten\n",
    "\n",
    "Sobald Sie Tensoren erstellt haben (oder jemand anderes oder ein PyTorch-Modul sie für Sie erstellt hat), möchten Sie vielleicht einige Informationen von ihnen erhalten.\n",
    "\n",
    "Wir haben diese bereits gesehen, aber drei der häufigsten Attribute, die man über Tensoren herausfinden möchte, sind:\n",
    "* \"Form\" - welche Form hat der Tensor? (einige Operationen erfordern spezifische Formregeln)\n",
    "* `dtype` - in welchem Datentyp sind die Elemente innerhalb des Tensors gespeichert?\n",
    "* Gerät\" - auf welchem Gerät ist der Tensor gespeichert? (normalerweise GPU oder CPU)\n",
    "\n",
    "Lassen Sie uns einen zufälligen Tensor erstellen und Details über ihn herausfinden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hd_X4D0j7Umq",
    "outputId": "86045713-ab36-4c8e-840c-e788f80c5266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0079, 0.8656, 0.5640, 0.0424],\n",
      "        [0.4597, 0.9129, 0.6073, 0.4909],\n",
      "        [0.0170, 0.3657, 0.8348, 0.9291]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\")  # will default to CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45K-E5uPg6cj"
   },
   "source": [
    "> **Hinweis:** Wenn Sie in PyTorch auf Probleme stoßen, hat das sehr oft mit einem der drei oben genannten Attribute zu tun. Wenn also die Fehlermeldungen auftauchen, singen Sie sich selbst ein kleines Lied namens \"was, was, wo\":\n",
    "  * \"*Welche Form haben meine Tensoren? welchen Datentyp haben sie und wo sind sie gespeichert? welche Form, welcher Datentyp, wo wo wo*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdiWvoAi7UjL"
   },
   "source": [
    "## Manipulation von Tensoren (Tensoroperationen)\n",
    "\n",
    "Beim Deep Learning werden Daten (Bilder, Text, Video, Audio, Proteinstrukturen usw.) als Tensoren dargestellt. Ein Modell lernt, indem es diese Tensoren untersucht und eine Reihe von Operationen (es könnten mehr als 1.000.000 sein) auf Tensoren ausführt, um eine Darstellung der Muster in den Eingabedaten zu erstellen.\n",
    "\n",
    "Diese Operationen sind oft ein wunderbarer Tanz zwischen:\n",
    "* Addition\n",
    "* Subtraktion\n",
    "* Multiplikation (elementweise)\n",
    "* Division\n",
    "* Matrix-Multiplikation\n",
    "\n",
    "Und das war's. Sicher gibt es hier und da noch ein paar mehr, aber das sind die Grundbausteine neuronaler Netze. Stapelt man diese Bausteine auf die richtige Weise, kann man die ausgeklügeltsten neuronalen Netze erstellen (wie bei Lego!).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk_6Dd7L7Uce"
   },
   "source": [
    "### Grundlegende Operationen\n",
    "\n",
    "Beginnen wir mit einigen der grundlegenden Operationen: Addition (`+`), Subtraktion (`-`), Multiplikation (`*`).\n",
    "\n",
    "Sie funktionieren genau so, wie Sie es sich vorstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X71WpQoPD7a4",
    "outputId": "ab30f13e-fc67-4ae4-c5ce-1006410dba07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of values and add a number to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor = tensor + 10\n",
    "tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sp4TlTWWEFeO",
    "outputId": "ce7d2296-881f-4eb3-802e-fd12bc25d6ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([110, 120, 130])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply it by 10\n",
    "tensor * 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1VEHnuRkn8Q"
   },
   "source": [
    "Beachten Sie, dass die obigen Tensorwerte nicht als `tensor([110, 120, 130])` enden, weil sich die Werte innerhalb des Tensors nicht ändern, es sei denn, sie werden neu zugewiesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuB1UjCIEJIA",
    "outputId": "57cae862-c145-4681-d74b-fe6d77f2125a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors don't change unless reassigned\n",
    "tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYvqGpUTk1o6"
   },
   "source": [
    "Wir subtrahieren eine Zahl und weisen diesmal die Variable `Tensor` neu zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4iWKoLsENry",
    "outputId": "14d6771d-eb57-4b11-88a7-b1bb308ddc6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract and reassign\n",
    "tensor = tensor - 10\n",
    "tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFgZY-PaFNXa",
    "outputId": "3536ea54-a056-444c-cd5d-6d438ddda965"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add and reassign\n",
    "tensor = tensor + 10\n",
    "tensor\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CYXDoIOzk-6I"
   },
   "source": [
    "PyTorch hat auch eine Reihe von eingebauten Funktionen wie [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) (kurz für Multiplikation) und [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html), um grundlegende Operationen durchzuführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVysdk3kFWbY",
    "outputId": "3a5bf687-cf24-4224-9e76-975f84638ca8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([110, 120, 130])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use torch functions\n",
    "torch.multiply(tensor, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxuPJIpNFbqO",
    "outputId": "f04cafd9-eaea-4254-df1a-5ab3b524d74e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor is still unchanged\n",
    "tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70UNL33AlVQq"
   },
   "source": [
    "Es ist jedoch gebräuchlicher, die Operator-Symbole wie \"*\" anstelle von \"torch.mul()\" zu verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5v3RkR0F2Jq",
    "outputId": "0137caab-5ea1-4d95-f4c5-a0baa0fd652d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13]) * tensor([11, 12, 13])\n",
      "Equals: tensor([121, 144, 169])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"Equals:\", tensor * tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TT5fVuyu7q5z"
   },
   "source": [
    "### Matrixmultiplikation (ist alles, was Sie brauchen)\n",
    "\n",
    "Eine der gebräuchlichsten Operationen in Algorithmen für maschinelles Lernen und Deep Learning (wie neuronale Netze) ist die [Matrixmultiplikation](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
    "\n",
    "PyTorch implementiert die Funktionalität der Matrixmultiplikation in der Methode [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
    "\n",
    "Die zwei wichtigsten Regeln für die Matrixmultiplikation, die man sich merken sollte, sind:\n",
    "\n",
    "1. Die **inneren Dimensionen** müssen übereinstimmen:\n",
    "  * `(3, 2) @ (3, 2)` wird nicht funktionieren\n",
    "  * `(2, 3) @ (3, 2)` wird funktionieren\n",
    "  * `(3, 2) @ (2, 3)` wird funktionieren\n",
    "2. Die resultierende Matrix hat die Form der **Außendimensionen**:\n",
    " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
    "\n",
    "> **Hinweis:** \"`@`\" ist in Python das Symbol für die Matrixmultiplikation.\n",
    "\n",
    "> **Ressource:** Sie können alle Regeln für die Matrixmultiplikation mit `torch.matmul()` [in der PyTorch-Dokumentation] (https://pytorch.org/docs/stable/generated/torch.matmul.html) sehen.\n",
    "\n",
    "Erstellen wir einen Tensor und führen wir eine elementweise Multiplikation und eine Matrixmultiplikation mit ihm durch.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZE7loucmDlEM",
    "outputId": "44032bf9-c1f7-42fc-c842-dbe7a5c1221a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUAZ3_b0vOKv"
   },
   "source": [
    "Der Unterschied zwischen der elementweisen Multiplikation und der Matrixmultiplikation besteht in der Addition von Werten.\n",
    "\n",
    "Für unsere `Tensor`-Variable mit den Werten `[1, 2, 3]`:\n",
    "\n",
    "| Operation | Berechnung | Code |\n",
    "| ----- | ----- | ----- |\n",
    "| **Elementweise Multiplikation** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `Tensor * Tensor` |\n",
    "| **Matrix-Multiplikation** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i42gkUeHvI_1",
    "outputId": "18a630ce-bb56-4c40-81b4-9fdbb2ed7a4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise matrix multiplication\n",
    "tensor * tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvCBiiTTDk8y",
    "outputId": "cf623247-8f1b-49f1-e788-16da3ed1e59c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4E_pROBDk2r",
    "outputId": "a09af00f-277b-479e-b0a2-ad6311ee5413"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use the \"@\" symbol for matrix multiplication, though not recommended\n",
    "tensor @ tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obbginUMv43A"
   },
   "source": [
    "Sie können die Matrixmultiplikation von Hand durchführen, aber das ist nicht empfehlenswert. Die eingebaute Methode `torch.matmul()` ist schneller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6qMSaLOoJscL",
    "outputId": "8bcad8a2-c900-4966-e13c-ff2cc02b9207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Matrix multiplication by hand\n",
    "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVWiKB0KwH74",
    "outputId": "fce58235-5c09-49ec-f34b-a90e5640281e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ4DDmo1TGe-"
   },
   "source": [
    "## Einer der häufigsten Fehler beim Deep Learning (Formfehler)\n",
    "\n",
    "Da ein großer Teil des Deep Learning aus der Multiplikation und der Durchführung von Operationen mit Matrizen besteht und für Matrizen strenge Regeln gelten, welche Formen und Größen kombiniert werden können, ist einer der häufigsten Fehler, auf den man beim Deep Learning stößt, die Nichtübereinstimmung von Formen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "rN5RcoD4Jo6y",
    "outputId": "20f6c65b-86f4-4903-d253-f6cbf0583934"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      3\u001b[0m                          [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      4\u001b[0m                          [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m], \n\u001b[0;32m      8\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way\n",
    "tensor_A = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10], [8, 11], [9, 12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B)  # (this will error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNA6MZEFxWVt"
   },
   "source": [
    "Wir können die Matrixmultiplikation zwischen \"Tensor_A\" und \"Tensor_B\" durchführen, indem wir ihre inneren Dimensionen übereinstimmen lassen.\n",
    "\n",
    "Eine der Möglichkeiten, dies zu tun, ist eine **Transposition** (die Dimensionen eines gegebenen Tensors vertauschen).\n",
    "\n",
    "Sie können Transpositionen in PyTorch durchführen, indem Sie entweder:\n",
    "* `torch.transpose(input, dim0, dim1)` - wobei `input` der gewünschte zu transponierende Tensor ist und `dim0` und `dim1` die zu vertauschenden Dimensionen sind.\n",
    "* `tensor.T` - wobei `tensor` der gewünschte Tensor ist, der transponiert werden soll.\n",
    "\n",
    "Versuchen wir Letzteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUqgaANiy1wq",
    "outputId": "e48bbf0c-8008-434e-d372-caa658b2f36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DveqxO7iy_Fi",
    "outputId": "1bd2e85b-ea4d-4948-c408-8eb46ef3534c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B.T\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35rEIu-NKtVE",
    "outputId": "0b32c7f1-556e-45d4-de22-388419e93dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(\n",
    "    f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\"\n",
    ")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output)\n",
    "print(f\"\\nOutput shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfcFEqfLjN24"
   },
   "source": [
    "Sie können auch [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html) verwenden, was eine Abkürzung für `torch.matmul()` ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3rJvW_TTGe_",
    "outputId": "2c501972-20bf-4a83-ad4a-b5f1b2424097"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm is a shortcut for matmul\n",
    "torch.mm(tensor_A, tensor_B.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXKozI4T0hFi"
   },
   "source": [
    "Ohne die Transponierung sind die Regeln der Matrixmultiplikation nicht erfüllt, und wir erhalten einen Fehler wie oben.\n",
    "\n",
    "Wie wäre es mit einer visuellen Darstellung?\n",
    "\n",
    "![Visuelle Demo der Matrixmultiplikation](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/00-matrix-multiply-crop.gif)\n",
    "\n",
    "Sie können Ihre eigenen visuellen Darstellungen der Matrixmultiplikation wie diese unter http://matrixmultiplication.xyz/ erstellen.\n",
    "\n",
    "**Anmerkung:** Eine Matrixmultiplikation wie diese wird auch als das [**Punktprodukt**](https://www.mathsisfun.com/algebra/vectors-dot-product.html) zweier Matrizen bezeichnet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hA64Z4DmkB31"
   },
   "source": [
    "Neuronale Netze sind voll von Matrixmultiplikationen und Skalarprodukten. Das Modul [`torch.nn.Linear()`](https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html) (wir werden es später in Aktion sehen), auch bekannt als Feed-Forward-Schicht oder vollständig verbundene Schicht, implementiert eine Matrixmultiplikation zwischen einer Eingabe `x` und einer Gewichtungsmatrix `A`.\n",
    "\n",
    "$$\n",
    "y = W^{\\top} \\cdot x + b\n",
    "$$\n",
    "\n",
    "Wobei:\n",
    "- $x$ ist die Eingabe für die Schicht (Deep Learning ist ein Stapel von Schichten wie `torch.nn.Linear()` und andere übereinander).\n",
    "- $W$ ist die Gewichtungsmatrix, die von der Schicht erstellt wird. Am Anfang sind es Zufallszahlen, die angepasst werden, wenn ein neuronales Netzwerk lernt, Muster in den Daten besser darzustellen (beachten Sie das \"T\", das ist, weil die Gewichtungsmatrix transponiert wird). Oft wird auch $A$ oder ein anderer Buchstabe wie $\\theta$ verwendet, um die Gewichtungsmatrix darzustellen.\n",
    "- $b$ ist der Bias-Begriff, der verwendet wird, um die Gewichte und Eingaben leicht zu verschieben.\n",
    "- $y$ ist die Ausgabe (eine Manipulation der Eingabe in der Hoffnung, Muster darin zu entdecken).\n",
    "\n",
    "Dies ist eine lineare Funktion (vielleicht haben Sie in der Schule oder anderswo schon einmal etwas wie $y = mx+b$ gesehen) und kann zum Zeichnen einer geraden Linie verwendet werden!\n",
    "- Versuchen Sie, die Werte von `in_features` und `out_features` zu ändern und sehen Sie, was passiert.\n",
    "- Fällt Ihnen etwas auf, was mit den Formen zu tun hat?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mC_MjKW1LX7T",
    "outputId": "768f75d2-c978-4df3-e18a-4684d46bdfa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(\n",
    "    in_features=2,  # in_features = matches inner dimension of input\n",
    "    out_features=6,\n",
    ")  # out_features = describes outer value\n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIGrP5j1pN7j"
   },
   "source": [
    "> **Question:** What happens if you change `in_features` from 2 to 3 above? Does it error? How could you change the shape of the input (`x`) to accommodate to the error? Hint: what did we have to do to `tensor_B` above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPNF0nMWoGEj"
   },
   "source": [
    "Wenn Sie sich noch nie mit der Matrixmultiplikation beschäftigt haben, kann das Thema zunächst verwirrend sein.\n",
    "\n",
    "Aber nachdem Sie ein paar Mal damit herumgespielt und sogar ein paar neuronale Netze geknackt haben, werden Sie feststellen, dass sie überall vorkommt.\n",
    "\n",
    "Denken Sie daran: Matrixmultiplikation ist alles, was Sie brauchen.\n",
    "\n",
    "![Matrixmultiplikation ist alles, was du brauchst](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_matrix_multiplication_is_all_you_need.jpeg)\n",
    "\n",
    "*Wenn du anfängst, dich mit neuronalen Netzwerkschichten zu beschäftigen und deine eigenen zu bauen, wirst du überall Matrixmultiplikationen finden. **Quelle:** https://marksaroufim.substack.com/p/working-class-deep-learner*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjMmrJOOPv5e"
   },
   "source": [
    "### Min., Max., Mittelwert, Summe usw. ermitteln (Aggregation)\n",
    "\n",
    "Nachdem wir nun einige Möglichkeiten zur Manipulation von Tensoren kennengelernt haben, wollen wir nun einige Möglichkeiten zur Aggregation von Tensoren durchspielen (von mehr Werten zu weniger Werten). Zuerst werden wir einen Tensor erstellen und dann das Maximum, das Minimum, den Mittelwert und die Summe davon finden.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrFQbe5fP1Rk",
    "outputId": "034013c1-b384-4a0d-edf8-295ed3a456f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-J-wfMdlsEco"
   },
   "source": [
    "Lassen Sie uns nun eine Aggregation durchführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5wSP9YKP3Lb",
    "outputId": "3aa238c7-646f-434f-a55c-292aabef7227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "# print(f\"Mean: {x.mean()}\") # this will error\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\")  # won't work without float datatype\n",
    "print(f\"Sum: {x.sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHoKpsg3sKQE"
   },
   "source": [
    "**Hinweis:** Einige Methoden, wie z.B. `torch.mean()`, erfordern, dass die Tensoren im Datentyp `torch.float32` (der häufigste) oder einem anderen spezifischen Datentyp vorliegen, andernfalls schlägt die Operation fehl.\n",
    "\n",
    "Sie können auch das Gleiche wie oben mit `torch`-Methoden tun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Cr23Y9uP3HO",
    "outputId": "9c86d805-eef2-465c-e2c8-2bccd515e6d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(0), tensor(45.), tensor(450))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7ApCaZjDkvp"
   },
   "source": [
    "### Positionsbezogenes Min/Max\n",
    "\n",
    "Sie können auch den Index eines Tensors, in dem das Maximum oder Minimum auftritt, mit [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) bzw. [`torch.argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html) ermitteln.\n",
    "\n",
    "Dies ist hilfreich, wenn Sie nur die Position suchen, an der der höchste (oder niedrigste) Wert liegt, und nicht den eigentlichen Wert selbst (wir werden dies in einem späteren Abschnitt sehen, wenn wir die [softmax-Aktivierungsfunktion](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) verwenden).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FzNBl9JSGlHi",
    "outputId": "01e0740e-c34f-469b-9c8f-9e6e5f0363af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 8\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "# Returns index of max and min values\n",
    "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurs: {tensor.argmin()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBu33WihOXBk"
   },
   "source": [
    "### Tensor-Datentyp ändern\n",
    "\n",
    "Wie bereits erwähnt, besteht ein häufiges Problem bei Deep-Learning-Operationen darin, dass die Tensoren in verschiedenen Datentypen vorliegen. Wenn ein Tensor im Datentyp `torch.float64` und ein anderer im Datentyp `torch.float32` ist, kann es zu Fehlern kommen. Aber es gibt eine Lösung.\n",
    "\n",
    "- Sie können die Datentypen von Tensoren mit [`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html) ändern, wobei der Parameter `dtype` der Datentyp ist, den Sie verwenden möchten.\n",
    "- Zuerst erstellen wir einen Tensor und prüfen seinen Datentyp (die Vorgabe ist `torch.float32`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rY2FEsCAOaLu",
    "outputId": "507f1ade-7c7a-4172-fa48-60c9ac4831c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and check its datatype\n",
    "tensor = torch.arange(10.0, 100.0, 10.0)\n",
    "tensor.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jR30FHEc92of"
   },
   "source": [
    "Jetzt erstellen wir einen weiteren Tensor wie zuvor, ändern aber den Datentyp in \"torch.float16\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cac8gRYjOeab",
    "outputId": "96e5ce12-bc29-4a2b-f81c-bfc89ea2d075"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a float16 tensor\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndVlKJZ4-7_5"
   },
   "source": [
    "Und wir können etwas Ähnliches tun, um einen `torch.int8`-Tensor zu erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Yqovld2Oj6s",
    "outputId": "667da17f-e38f-404a-bd2d-63683e45c99a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an int8 tensor\n",
    "tensor_int8 = tensor.type(torch.int8)\n",
    "tensor_int8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44GxVabar-xe"
   },
   "source": [
    "> **Anmerkung:** Verschiedene Datentypen können anfangs verwirrend sein. Je niedriger die Zahl ist (z. B. 32, 16, 8), desto ungenauer speichert ein Computer den Wert. Und eine geringere Speichermenge führt im Allgemeinen zu einer schnelleren Berechnung und einem kleineren Gesamtmodell. Mobile neuronale Netze arbeiten oft mit 8-Bit-Ganzzahlen, die kleiner und schneller sind, aber weniger genau als ihre Float32-Gegenstücke. Mehr dazu finden Sie in [precision in computing] (https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
    "\n",
    "> **Übung:** Bis jetzt haben wir einige Tensor-Methoden behandelt, aber es gibt noch eine Menge mehr in der [`torch.Tensor` Dokumentation](https://pytorch.org/docs/stable/tensors.html), ich würde empfehlen, 10 Minuten damit zu verbringen, durchzublättern und sich alle anzuschauen, die Ihnen ins Auge fallen. Klicken Sie sie an und schreiben Sie sie dann selbst in Code, um zu sehen, was passiert.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CkCtAYmGsHY"
   },
   "source": [
    "### Umformen, Stapeln, Quetschen und Aufheben des Quetschens\n",
    "\n",
    "Oft möchte man die Form oder die Dimensionen seiner Tensoren ändern, ohne die Werte darin zu verändern.\n",
    "\n",
    "Hierfür gibt es einige beliebte Methoden:\n",
    "\n",
    "| Methode | Einzeilige Beschreibung |\n",
    "| ----- | ----- |\n",
    "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Formt `input` in `shape` um (falls kompatibel), kann auch `torch.Tensor.reshape()` verwenden. |\n",
    "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Gibt eine Ansicht des ursprünglichen Tensors in einer anderen `Form` zurück, hat aber die gleichen Daten wie der ursprüngliche Tensor. |\n",
    "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Verkettet eine Folge von `Tensoren` entlang einer neuen Dimension (`dim`), alle `Tensoren` müssen gleich groß sein. |\n",
    "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Quetscht `input` um alle Dimenionen mit dem Wert `1` zu entfernen. |\n",
    "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Gibt `input` mit einem Dimensionswert von `1` zurück, der bei `dim` hinzugefügt wurde. |\n",
    "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Gibt eine *Ansicht* der ursprünglichen `Eingabe` mit ihren Dimensionen permutiert (umgeordnet) zu `dims` zurück. |\n",
    "\n",
    "Warum dies alles tun?\n",
    "\n",
    "Weil es bei Deep-Learning-Modellen (neuronalen Netzen) immer darum geht, Tensoren auf irgendeine Weise zu manipulieren. Und aufgrund der Regeln der Matrixmultiplikation kommt es zu Fehlern, wenn die Formen nicht übereinstimmen. Mit diesen Methoden können Sie sicherstellen, dass die richtigen Elemente Ihrer Tensoren mit den richtigen Elementen anderer Tensoren gemischt werden.\n",
    "\n",
    "Probieren wir sie aus. Zuerst erstellen wir einen Tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYjRTLOzG4Ev",
    "outputId": "f7f2719c-15ce-406b-dc8f-4477046cd5d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "\n",
    "x = torch.arange(1.0, 8.0)\n",
    "x, x.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_VarMO9CoT8"
   },
   "source": [
    "Nun wollen wir mit `torch.reshape()` eine zusätzliche Dimension hinzufügen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "US4WjpQ3SG-8",
    "outputId": "c519d59e-85f1-4a10-eaaa-acb487028e3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 7)\n",
    "x_reshaped, x_reshaped.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tig5xm0jCxuU"
   },
   "source": [
    "Wir können auch die Ansicht mit `torch.view()` ändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDN2BNe5TGfB",
    "outputId": "3df1b0d6-2548-4ecc-ca25-0c4e28a6e536"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change view (keeps same data as original but changes view)\n",
    "# See more: https://stackoverflow.com/a/54507446/7900723\n",
    "z = x.view(1, 7)\n",
    "z, z.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8joAaUEC2NX"
   },
   "source": [
    "Denken Sie aber daran, dass das Ändern der Ansicht eines Tensors mit `torch.view()` wirklich nur eine neue Ansicht des *gleichen* Tensors erzeugt.\n",
    "Das Ändern der Ansicht ändert also auch den ursprünglichen Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DxURVvXTGfC",
    "outputId": "668d194d-dd0a-4db1-da00-9c3fd8849186"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x\n",
    "z[:, 0] = 5\n",
    "z, x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxnqDBlpDDJ_"
   },
   "source": [
    "Wenn wir unseren neuen Tensor fünfmal auf sich selbst stapeln wollten, könnten wir dies mit `torch.stack()` tun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pX5Adf3ORiTK",
    "outputId": "703e8568-61df-4ebd-f4d3-a6366dc265c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack(\n",
    "    [x, x, x, x], dim=0\n",
    ")  # try changing dim to dim=1 and see what happens\n",
    "x_stacked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ET56QzNHDuOI"
   },
   "source": [
    "Wie wäre es, alle einzelnen Dimensionen aus einem Tensor zu entfernen?\n",
    "\n",
    "Dazu können Sie `torch.squeeze()` verwenden (ich erinnere mich daran, dass der Tensor nur Dimensionen über 1 haben soll)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2Y2HEoDRxJZ",
    "outputId": "dd0645a6-1cdd-46bc-a3a2-433d9cd09336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "Previous shape: torch.Size([1, 7])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "New shape: torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acjDLk8WD8NC"
   },
   "source": [
    "Und um das Gegenteil von \"torch.squeeze()\" zu tun, können Sie \"torch.unsqueeze()\" verwenden, um einen Dimensionswert von 1 bei einem bestimmten Index hinzuzufügen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUC-DEEwSYv7",
    "outputId": "da60e019-3ea6-42f8-8e47-ba037ead737f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "Previous shape: torch.Size([7])\n",
      "\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "New shape: torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9DuJzXgFbM5"
   },
   "source": [
    "Sie können auch die Reihenfolge der Achsenwerte mit `torch.permute(input, dims)` neu anordnen, wobei der `input` in eine *Ansicht* mit neuen `dims` umgewandelt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCRGCX8DTGfC",
    "outputId": "6853328b-a1cf-4470-f366-106a231a189c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor with specific shape\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the original tensor to rearrange the axis order\n",
    "x_permuted = x_original.permute(2, 0, 1)  # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06LKaFemGBoE"
   },
   "source": [
    "> **Anmerkung**: Da die Permutation eine *view* (mit denselben Daten wie das Original) ergibt, sind die Werte im permutierten Tensor dieselben wie im ursprünglichen Tensor, und wenn Sie die Werte in der Ansicht ändern, werden auch die Werte des Originals geändert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEPqVL7fTGfC"
   },
   "source": [
    "## Indizierung (Auswahl von Daten aus Tensoren)\n",
    "\n",
    "- Manchmal möchte man bestimmte Daten aus Tensoren auswählen (zum Beispiel nur die erste Spalte oder die zweite Zeile).\n",
    "- Zu diesem Zweck können Sie die Indizierung verwenden.\n",
    "- Wenn Sie schon einmal mit Python-Listen oder NumPy-Arrays indiziert haben, ist die Indizierung in PyTorch mit Tensoren sehr ähnlich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSXzdxCQTGfD",
    "outputId": "05a72c08-5f8c-433a-cd31-46065686f825"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQG5krnKG43B"
   },
   "source": [
    "Die Indizierung der Werte geht von der äußeren Dimension zur inneren Dimension (siehe die eckigen Klammern)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zv_Z3IAzTGfD",
    "outputId": "cf6c0936-7600-4af4-9b6f-f6b8ac9b4c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First square bracket:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square bracket: tensor([1, 2, 3])\n",
      "Third square bracket: 1\n"
     ]
    }
   ],
   "source": [
    "# Let's index bracket by bracket\n",
    "print(f\"First square bracket:\\n{x[0]}\")\n",
    "print(f\"Second square bracket: {x[0][0]}\")\n",
    "print(f\"Third square bracket: {x[0][0][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaLjaIFxHe89"
   },
   "source": [
    "Sie können auch `:` verwenden, um \"alle Werte in dieser Dimension\" anzugeben und dann ein Komma (`,`) verwenden, um eine weitere Dimension hinzuzufügen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCT09pqeTGfD",
    "outputId": "a91f9b73-f8f0-476a-9c69-fcd03b042f6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
    "x[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwDx_gMsTGfD",
    "outputId": "8165cfd9-a88d-4212-8c45-1eb84ef5be83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
    "x[:, :, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiw3_1E3TGfD",
    "outputId": "12fa4749-cf52-4e88-c2c0-44d26aeb633c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
    "x[:, 1, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFVEgrKhTGfD",
    "outputId": "69eadeb9-11b3-4b48-cb95-0b3305c1274c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
    "x[0, 0, :]  # same as x[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ik0r11RIxtm"
   },
   "source": [
    "Die Indizierung kann anfangs ziemlich verwirrend sein, vor allem bei größeren Tensoren (ich muss die Indizierung immer noch mehrmals ausprobieren, um sie richtig hinzubekommen). Aber mit ein bisschen Übung und dem Motto des Datenexplorers (***Visualisieren, visualisieren, visualisieren***) werden Sie den Dreh schon raus haben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8ZaW0Bq7rCm"
   },
   "source": [
    "## PyTorch Tensoren & NumPy\n",
    "\n",
    "Da NumPy eine beliebte Python-Bibliothek für numerische Berechnungen ist, verfügt PyTorch über Funktionen, die eine gute Interaktion mit ihr ermöglichen.\n",
    "\n",
    "Die beiden wichtigsten Methoden, die Sie für den Übergang von NumPy zu PyTorch (und zurück) verwenden sollten, sind:\n",
    "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - NumPy-Array -> PyTorch-Tensor.\n",
    "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - PyTorch Tensor -> NumPy Array.\n",
    "\n",
    "Probieren wir sie aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDrDCnvY7rKS",
    "outputId": "86155a63-01f9-4372-e889-61a65ebf0fb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16JG6cONLPnO"
   },
   "source": [
    "> **Hinweis:** Standardmäßig werden NumPy-Arrays mit dem Datentyp \"Float64\" erstellt, und wenn Sie sie in einen PyTorch-Tensor konvertieren, behalten sie denselben Datentyp (wie oben).\n",
    "> Viele PyTorch-Berechnungen verwenden jedoch standardmäßig den Datentyp `Float32`.\n",
    "> Wenn Sie also Ihr NumPy-Array (`float64`) -> PyTorch-Tensor (`float64`) -> PyTorch-Tensor (float32) konvertieren wollen, können Sie `tensor = torch.from_numpy(array).type(torch.float32)` verwenden.\n",
    "\n",
    "Da wir `tensor` oben neu zugewiesen haben, bleibt das Array gleich, wenn Sie den Tensor ändern.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovwl7VCREv8L",
    "outputId": "efd21eb9-0010-436a-dc29-f851e3d7d77a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the array, keep the tensor\n",
    "array = array + 1\n",
    "array, tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geVvu1p0MTWc"
   },
   "source": [
    "Und wenn Sie von einem PyTorch-Tensor zu einem NumPy-Array wechseln wollen, können Sie \"tensor.numpy()\" aufrufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xw_7ZyVaTKxQ",
    "outputId": "54d6f347-d3f6-44df-9155-83d980c31780"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7)  # create a tensor of ones with dtype=float32\n",
    "numpy_tensor = tensor.numpy()  # will be dtype=float32 unless changed\n",
    "tensor, numpy_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt8yEV1jMfi2"
   },
   "source": [
    "Und es gilt die gleiche Regel wie oben: Wenn Sie den ursprünglichen `Tensor` ändern, bleibt der neue `numpy_tensor` derselbe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMp6ZSkET4_Y",
    "outputId": "100678a4-c220-4a44-e4a5-0542359cb9de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, keep the array the same\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gU3ubCrUkI-"
   },
   "source": [
    "## Reproduzierbarkeit (Versuch, den Zufall aus dem Zufall herauszuhalten)\n",
    "\n",
    "Wenn Sie mehr über neuronale Netze und maschinelles Lernen lernen, werden Sie feststellen, wie sehr der Zufall eine Rolle spielt. Nun ja, eher der Pseudozufall, denn schließlich ist ein Computer grundsätzlich deterministisch (jeder Schritt ist vorhersehbar), so dass die Zufälligkeiten, die er erzeugt, simulierte Zufälligkeiten sind.\n",
    "\n",
    "Was hat das nun mit neuronalen Netzen und Deep Learning zu tun? Wir haben besprochen, dass neuronale Netze mit Zufallszahlen beginnen, um Muster in Daten zu beschreiben (diese Zahlen sind schlechte Beschreibungen), und versuchen, diese Zufallszahlen mithilfe von Tensoroperationen (und einigen anderen Dingen, die wir noch nicht besprochen haben) zu verbessern, um Muster in Daten besser zu beschreiben.\n",
    "\n",
    "Kurz gesagt:\n",
    "\n",
    "``Anfang mit Zufallszahlen -> Tensoroperationen -> Versuch, es besser zu machen (wieder und wieder und wieder)``\n",
    "\n",
    "Obwohl Zufälligkeit schön und mächtig ist, hätte man manchmal gerne etwas weniger Zufälligkeit. Und warum? Damit Sie wiederholbare Experimente durchführen können.\n",
    "\n",
    "- Ein Beispiel: Sie entwickeln einen Algorithmus, der eine Leistung von X erreicht.\n",
    "- Und dann probiert Ihr Freund ihn aus, um zu überprüfen, ob Sie nicht verrückt sind. Wie könnten sie so etwas tun?\n",
    "\n",
    "Hier kommt die **Reproduzierbarkeit** ins Spiel. Mit anderen Worten: Können Sie auf Ihrem Computer mit demselben Code die gleichen (oder sehr ähnliche) Ergebnisse erzielen wie ich auf meinem? Schauen wir uns ein kurzes Beispiel für Reproduzierbarkeit in PyTorch an.\n",
    "\n",
    "Wir beginnen damit, zwei zufällige Tensoren zu erzeugen. Da sie zufällig sind, sollte man erwarten, dass sie unterschiedlich sind, oder?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSwxnwEbTGfF",
    "outputId": "73b34154-734f-496f-9b55-b6aaa137e854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.8016, 0.3649, 0.6286, 0.9663],\n",
      "        [0.7687, 0.4566, 0.5745, 0.9200],\n",
      "        [0.3230, 0.8613, 0.0919, 0.3102]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.9536, 0.6002, 0.0351, 0.6826],\n",
      "        [0.3743, 0.5220, 0.1336, 0.9666],\n",
      "        [0.9754, 0.8474, 0.8988, 0.1105]])\n",
      "\n",
      "Does Tensor A equal Tensor B? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
    "random_tensor_A == random_tensor_B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPU6mDKJnr8M"
   },
   "source": [
    "Wie Sie vielleicht erwartet haben, haben die Tensoren unterschiedliche Werte. Aber was wäre, wenn Sie zwei zufällige Tensoren mit den *gleichen* Werten erstellen wollten? Das heißt, die Tensoren würden immer noch zufällige Werte enthalten, aber sie wären vom gleichen Geschmack.\n",
    "\n",
    "Hier kommt [`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html) ins Spiel, wobei `seed` eine ganze Zahl ist (z.B. `42`, aber es kann alles sein), die den Zufallswert bestimmt. Probieren wir es aus, indem wir ein paar weitere *verfälschte* Zufallstensoren erzeugen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sB6d1GfYTGfF",
    "outputId": "4d11d38e-4406-4aff-9a81-cf13aa89ee5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor D:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Does Tensor C equal Tensor D? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "# # Set the random seed\n",
    "RANDOM_SEED = 42  # try changing this to different values and see what happens to the numbers below\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Have to reset the seed every time a new rand() is called\n",
    "# Without this, tensor_D would be different to tensor_C\n",
    "torch.random.manual_seed(\n",
    "    seed=RANDOM_SEED\n",
    ")  # try commenting this line out and seeing what happens\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
    "random_tensor_C == random_tensor_D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uct53Xr5QRC_"
   },
   "source": [
    "Sehr schön!\n",
    "\n",
    "Es sieht so aus, als ob das Setzen des Seeds funktioniert hat.\n",
    "\n",
    "**Ressourcen:** Was wir gerade behandelt haben, kratzt nur an der Oberfläche der Reproduzierbarkeit in PyTorch. Für mehr, über Reproduzierbarkeit im Allgemeinen und zufällige Seeds, würde ich mir das anschauen:\n",
    "> * [Die PyTorch-Dokumentation zur Reproduzierbarkeit] (https://pytorch.org/docs/stable/notes/randomness.html) (eine gute Übung wäre es, diese 10 Minuten lang durchzulesen, und selbst wenn Sie es jetzt nicht verstehen, ist es wichtig, es zu wissen).\n",
    "> * [The Wikipedia random seed page](https://en.wikipedia.org/wiki/Random_seed) (dies gibt einen guten Überblick über Zufallssamen und Pseudozufälligkeit im Allgemeinen).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxIIM7t27rQ-"
   },
   "source": [
    "## Tensoren auf GPUs ausführen (und schnellere Berechnungen durchführen)\n",
    "\n",
    "Deep-Learning-Algorithmen erfordern eine Menge numerischer Operationen.\n",
    "\n",
    "Und standardmäßig werden diese Operationen oft auf einer CPU (Computer Processing Unit) durchgeführt.\n",
    "\n",
    "Es gibt jedoch noch eine andere gängige Hardware, die Grafikprozessoreinheit (GPU), die bei der Ausführung der spezifischen Arten von Operationen, die neuronale Netze benötigen (Matrixmultiplikationen), oft viel schneller ist als CPUs.\n",
    "\n",
    "Vielleicht verfügt Ihr Computer über eine solche Einheit.\n",
    "\n",
    "Wenn ja, sollten Sie ihn so oft wie möglich zum Trainieren von neuronalen Netzen verwenden, da sich die Trainingszeit dadurch mit großer Wahrscheinlichkeit drastisch verkürzt.\n",
    "\n",
    "Es gibt mehrere Möglichkeiten, erstens Zugang zu einem Grafikprozessor zu bekommen und zweitens PyTorch dazu zu bringen, den Grafikprozessor zu nutzen.\n",
    "\n",
    "**Hinweis:** Wenn ich in diesem Kurs von einem \"Grafikprozessor\" spreche, beziehe ich mich auf einen [Nvidia-GPU mit CUDA](https://developer.nvidia.com/cuda-gpus), der aktiviert ist (CUDA ist eine Computerplattform und API, die es ermöglicht, Grafikprozessoren für allgemeine Berechnungen und nicht nur für Grafiken zu verwenden), sofern nicht anders angegeben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UiR6QpoYQH_"
   },
   "source": [
    "### 1. Eine GPU besorgen\n",
    "\n",
    "Wenn ich GPU sage, wissen Sie vielleicht schon, worum es geht. Aber wenn nicht, gibt es einige Möglichkeiten, um an eine zu kommen.\n",
    "\n",
    "| **Methode** | **Schwierigkeit der Einrichtung** | **Vorteile** | **Nachteile** | **Wie man einrichtet** |\n",
    "| ----- | ----- | ----- | ----- | ----- |\n",
    "| Google Colab | Einfach | Kostenlos zu verwenden, fast keine Einrichtung erforderlich, kann Arbeit mit anderen teilen, so einfach wie ein Link | Speichert Ihre Datenausgaben nicht, begrenzte Rechenleistung, unterliegt Zeitüberschreitungen | [Folgen Sie der Google Colab-Anleitung](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
    "| Verwenden Sie Ihr eigenes System | Mittel | Führen Sie alles lokal auf Ihrem eigenen Rechner aus | GPUs sind nicht kostenlos, erfordern Vorabkosten | Befolgen Sie die [PyTorch Installationsrichtlinien](https://pytorch.org/get-started/locally/) |\n",
    "| Cloud Computing (AWS, GCP, Azure) | Mittelschwer | Geringe Vorabkosten, Zugang zu fast unendlichen Rechenkapazitäten | Kann bei Dauerbetrieb teuer werden, benötigt einige Zeit für die richtige Einrichtung | Befolgen Sie die [PyTorch-Installationsrichtlinien](https://pytorch.org/get-started/cloud-partners/) |\n",
    "\n",
    "Es gibt noch weitere Optionen für die Nutzung von GPUs, aber die drei oben genannten reichen vorerst aus.\n",
    "\n",
    "Ich persönlich verwende eine Kombination aus Google Colab und meinem eigenen Computer für kleinere Experimente (und die Erstellung dieses Kurses) und greife auf Cloud-Ressourcen zurück, wenn ich mehr Rechenleistung benötige.\n",
    "\n",
    "**Ressourcen:** Wenn Sie einen eigenen Grafikprozessor kaufen möchten, aber nicht sicher sind, was Sie kaufen sollen, [Tim Dettmers hat einen hervorragenden Leitfaden](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/).\n",
    "\n",
    "Um zu überprüfen, ob Sie Zugang zu einem Nvidia-Grafikprozessor haben, können Sie `!nvidia-smi` ausführen, wobei das `!` (auch bang genannt) bedeutet: \"Führen Sie dies auf der Kommandozeile aus\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vEMcO-9zYc-w",
    "outputId": "77405db7-3494-4add-cfc7-8415e52a0412"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Der Befehl \"nvidia-smi\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvkB9p5zYf8E"
   },
   "source": [
    "Wenn Sie keinen Nvidia-Grafikprozessor zur Verfügung haben, wird die obige Ausgabe etwa so aussehen:\n",
    "\n",
    "```\n",
    "NVIDIA-SMI ist fehlgeschlagen, weil es nicht mit dem NVIDIA-Treiber kommunizieren konnte. Stellen Sie sicher, dass der neueste NVIDIA-Treiber installiert ist und läuft.\n",
    "```\n",
    "\n",
    "In diesem Fall gehen Sie wieder nach oben und folgen Sie den Installationsschritten.\n",
    "\n",
    "Wenn Sie einen Grafikprozessor haben, wird die obige Zeile etwas wie folgt ausgeben:\n",
    "\n",
    "\n",
    "```\n",
    "Wed Jan 19 22:09:08 2022       \n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
    "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|  No running processes found                                                 |\n",
    "+-----------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvibZ6e0YcDk"
   },
   "source": [
    "### 2. PyTorch auf der GPU zum Laufen bringen\n",
    "\n",
    "Sobald Sie eine GPU zur Verfügung haben, besteht der nächste Schritt darin, PyTorch für die Speicherung von Daten (Tensoren) und die Berechnung von Daten (Durchführung von Operationen auf Tensoren) zu verwenden.\n",
    "\n",
    "Dazu können Sie das Paket [`torch.cuda`](https://pytorch.org/docs/stable/cuda.html) verwenden.\n",
    "\n",
    "Anstatt darüber zu reden, sollten wir es lieber ausprobieren.\n",
    "\n",
    "Sie können testen, ob PyTorch Zugang zu einer GPU hat, indem Sie [`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available) verwenden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OweDLgwjEvZ2",
    "outputId": "3a278a24-3ec3-4b1f-8f96-298086fa6ea6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jedZcx2PZFpL"
   },
   "source": [
    "Wenn das obige Ergebnis `True` ist, kann PyTorch die GPU sehen und benutzen, wenn es `False` ist, kann es die GPU nicht sehen und in diesem Fall müssen Sie die Installationsschritte erneut durchführen.\n",
    "\n",
    "Nehmen wir nun an, Sie möchten Ihren Code so einrichten, dass er auf der CPU *oder* der GPU läuft, wenn diese verfügbar ist.\n",
    "\n",
    "Auf diese Weise funktioniert Ihr Code, wenn Sie oder jemand anderes ihn ausführen möchte, unabhängig von dem verwendeten Computergerät.\n",
    "\n",
    "Erstellen wir eine Variable `device`, um zu speichern, welche Art von Gerät verfügbar ist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "j92HBCKB7rYa",
    "outputId": "8cca1643-645c-4b67-f1f5-37066f6b9549"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjFyPP2WaCch"
   },
   "source": [
    "Wenn die obige Ausgabe \"cuda\" bedeutet, dass wir unseren gesamten PyTorch-Code so einstellen können, dass er das verfügbare CUDA-Gerät (eine GPU) verwendet, und wenn sie \"cpu\" ausgibt, bleibt unser PyTorch-Code bei der CPU.\n",
    "\n",
    "**Hinweis:** In PyTorch ist es die beste Praxis, [**Geräteunabhängigen Code**] (https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code) zu schreiben. Das bedeutet Code, der auf der CPU (immer verfügbar) oder der GPU (falls verfügbar) läuft.\n",
    "\n",
    "Wenn Sie schneller rechnen wollen, können Sie eine GPU verwenden, aber wenn Sie *viel* schneller rechnen wollen, können Sie mehrere GPUs verwenden.\n",
    "\n",
    "Sie können die Anzahl der GPUs, auf die PyTorch Zugriff hat, mit [`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count) zählen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MArsn0DFTGfG",
    "outputId": "de717df5-bb67-4900-805e-a6f00ad0b409"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVNf1hiqa-gO"
   },
   "source": [
    "Die Kenntnis der Anzahl der GPUs, auf die PyTorch Zugriff hat, ist hilfreich, wenn Sie einen bestimmten Prozess auf einer GPU und einen anderen Prozess auf einer anderen GPU laufen lassen wollen (PyTorch hat auch Funktionen, mit denen Sie einen Prozess auf *allen* GPUs laufen lassen können)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 PyTorch zum Laufen bringen auf Apple Silicon\n",
    "\n",
    "Um PyTorch auf Apples M1/M2/M3-GPUs laufen zu lassen, können Sie das Modul [`torch.backends.mps`](https://pytorch.org/docs/stable/notes/mps.html) verwenden.\n",
    "- Stellen Sie sicher, dass die Versionen von macOS und Pytorch aktualisiert sind.\n",
    "- Sie können testen, ob PyTorch Zugriff auf eine GPU hat, indem Sie `torch.backends.mps.is_available()` verwenden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Apple Silicon GPU\n",
    "import torch\n",
    "\n",
    "torch.backends.mps.is_available()  # Note this will print false if you're not running on a Mac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device type\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie zuvor bedeutet die obige Ausgabe \"mps\", dass wir unseren gesamten PyTorch-Code so einstellen können, dass er die verfügbare Apple Silicon GPU verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"  # Use NVIDIA GPU (if available)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"  # Use Apple Silicon GPU (if available)\n",
    "else:\n",
    "    device = \"cpu\"  # Default to CPU if no GPU is available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqQLcuj68OA-"
   },
   "source": [
    "### 3. Tensoren (und Modelle) auf der GPU platzieren\n",
    "\n",
    "Sie können Tensoren (und Modelle, das werden wir später sehen) auf ein bestimmtes Gerät legen, indem Sie [`to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) aufrufen. Wobei `Gerät` das Zielgerät ist, auf das Sie den Tensor (oder das Modell) legen möchten.\n",
    "\n",
    "Warum dies tun?\n",
    "\n",
    "GPUs bieten viel schnellere numerische Berechnungen als CPUs, und wenn keine GPU verfügbar ist, wird der Code aufgrund unseres **geräteunabhängigen Codes** (siehe oben) auf der CPU ausgeführt.\n",
    "\n",
    "**Hinweis:** Wenn Sie einen Tensor auf die GPU bringen, indem Sie `to(device)` verwenden (z.B. `some_tensor.to(device)`), wird eine Kopie dieses Tensors zurückgegeben, d.h. derselbe Tensor wird auf CPU und GPU sein. Um Tensoren zu überschreiben, ordnen Sie sie neu zu:\n",
    ">\n",
    "> \"irgendein_tensor = irgendein_tensor.to(device)`\n",
    "\n",
    "Versuchen wir, einen Tensor zu erstellen und ihn auf der GPU zu platzieren (wenn sie verfügbar ist).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhI3srFXEHfP",
    "outputId": "2f4f6435-fdc4-4e99-e87c-9421c2100f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor (default on CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxXeRKO0TGfG"
   },
   "source": [
    "Wenn Sie einen Grafikprozessor zur Verfügung haben, wird der obige Code etwas Ähnliches ausgeben:\n",
    "\n",
    "```\n",
    "tensor([1, 2, 3]) cpu\n",
    "tensor([1, 2, 3], device='cuda:0')\n",
    "```\n",
    "\n",
    "Beachten Sie, dass der zweite Tensor `device='cuda:0'` hat, was bedeutet, dass er auf der 0. verfügbaren GPU gespeichert ist (GPUs sind mit 0 indiziert, wenn zwei GPUs verfügbar wären, wären sie `'cuda:0'` bzw. `'cuda:1'`, bis zu `'cuda:n'`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4puyUX4Bci5D"
   },
   "source": [
    "### 4. Verschieben von Tensoren zurück in die CPU\n",
    "\n",
    "Was wäre, wenn wir den Tensor zurück zur CPU verschieben wollten? Dies ist zum Beispiel sinnvoll, wenn Sie mit NumPy mit Ihren Tensoren interagieren wollen (NumPy nutzt die GPU nicht). Versuchen wir, die Methode [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) für unseren \"Tensor_on_gpu\" zu verwenden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "id": "3ChSLJgPTGfG",
    "outputId": "32e92f62-db28-4dc7-ce93-c2ab33229252"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
    "tensor_on_gpu.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhymtkRDTGfG"
   },
   "source": [
    "Stattdessen können wir [`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html) verwenden, um einen Tensor zurück auf die CPU zu bringen und mit NumPy zu verwenden.\n",
    "\n",
    "Dies kopiert den Tensor in den CPU-Speicher, so dass er mit CPUs verwendet werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gN15s-NdTGfG",
    "outputId": "9fffb6f2-c200-4f9c-d987-d9ab5d9cba49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead, copy the tensor back to cpu\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyzNH5lrTGfH"
   },
   "source": [
    "Die obige Funktion gibt eine Kopie des GPU-Tensors im CPU-Speicher zurück, so dass sich der ursprüngliche Tensor immer noch auf der GPU befindet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5u83PCRTGfH",
    "outputId": "4cb931e2-7c8d-49b9-a7de-db3d3c6589b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlmBpnuPTGfH"
   },
   "source": [
    "## Übungen\n",
    "\n",
    "Alle Übungen konzentrieren sich auf das Einüben des obigen Codes.\n",
    "\n",
    "Sie sollten in der Lage sein, sie zu lösen, indem Sie sich auf die einzelnen Abschnitte beziehen oder indem Sie die verlinkten Ressourcen befolgen.\n",
    "\n",
    "**Ressourcen:**\n",
    "\n",
    "* [Übungsvorlagen-Notizbuch für 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb).\n",
    "* [Beispiellösungsheft für 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/00_pytorch_fundamentals_exercise_solutions.ipynb) (versuchen Sie die Übungen *bevor* Sie sich dies ansehen).\n",
    "\n",
    "1. Lesen der Dokumentation - Ein großer Teil des Deep Learning (und des Programmierens im Allgemeinen) besteht darin, sich mit der Dokumentation eines bestimmten Frameworks vertraut zu machen, das Sie verwenden. Wir werden die PyTorch-Dokumentation im weiteren Verlauf dieses Kurses häufig verwenden. Ich würde also empfehlen, sich 10 Minuten Zeit zu nehmen, um das Folgende zu lesen (es ist in Ordnung, wenn Sie einige Dinge vorerst nicht verstehen, der Schwerpunkt liegt noch nicht auf dem vollständigen Verständnis, sondern auf dem Bewusstsein). Siehe die Dokumentation zu [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor) und zu [`torch.cuda`](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics).\n",
    "2. Erzeugen Sie einen zufälligen Tensor mit der Form `(7, 7)`.\n",
    "3. Führen Sie eine Matrixmultiplikation auf dem Tensor von 2 mit einem anderen zufälligen Tensor mit der Form `(1, 7)` durch (Hinweis: Sie müssen den zweiten Tensor eventuell transponieren).\n",
    "4. Setzen Sie den Zufallskeim auf `0` und wiederholen Sie die Übungen 2 & 3.\n",
    "5. Apropos Zufallssaat, wir haben gesehen, wie man sie mit `torch.manual_seed()` setzt, aber gibt es ein GPU-Äquivalent? (Hinweis: Sie müssen dazu in die Dokumentation von `torch.cuda` schauen). Wenn ja, setzen Sie den GPU-Zufallswert auf \"1234\".\n",
    "6. Erzeugen Sie zwei zufällige Tensoren der Form `(2, 3)` und senden Sie beide an die GPU (Sie brauchen dafür Zugang zu einer GPU). Setzen Sie `torch.manual_seed(1234)` beim Erstellen der Tensoren (dies muss nicht der GPU-Zufallswert sein).\n",
    "7. Führen Sie eine Matrixmultiplikation mit den Tensoren durch, die Sie in 6 erstellt haben (auch hier müssen Sie möglicherweise die Form eines der Tensoren anpassen).\n",
    "8. Finde den maximalen und minimalen Wert der Ausgabe von 7.\n",
    "9. Ermitteln Sie den maximalen und minimalen Indexwert der Ausgabe von 7.\n",
    "10. Bilden Sie einen zufälligen Tensor mit der Form `(1, 1, 1, 10)` und erstellen Sie dann einen neuen Tensor, bei dem alle `1` Dimensionen entfernt wurden, um einen Tensor mit der Form `(10)` zu erhalten. Setze den Seed auf `7` wenn du ihn erstellst und drucke den ersten Tensor und seine Form sowie den zweiten Tensor und seine Form aus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlmBpnuPTGfH"
   },
   "source": [
    "## Extra-Lehrplan\n",
    "\n",
    "* Verbringen Sie 1 Stunde damit, das [PyTorch Grundlagen-Tutorial] (https://pytorch.org/tutorials/beginner/basics/intro.html) durchzuarbeiten (ich empfehle die Abschnitte [Quickstart] (https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) und [Tensoren] (https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)).\n",
    "* Um mehr darüber zu erfahren, wie ein Tensor Daten darstellen kann, sehen Sie sich dieses Video an: [Was ist ein Tensor?](https://youtu.be/f5liqUk0ZTw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "00_pytorch_fundamentals.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
