{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Bilder/ost_logo.png\" width=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Applied Neural Networks | FS 2025 </b><br>\n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> © Christoph Würsch, François Chollet </a> </div>\n",
    "<a href=\"https://www.ost.ch/de/forschung-und-dienstleistungen/technik-neu/systemtechnik/ice-institut-fuer-computational-engineering\"> Eastern Switzerland University of Applied Sciences OST | ICE </a>\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChristophWuersch/AppliedNeuralNetworks/blob/main/ANN07/7.2-Callbacks_und_Tensorboard_pl.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# für Ausführung auf Google Colab auskommentieren und installieren\n",
    "!pip install -q -r https://raw.githubusercontent.com/ChristophWuersch/AppliedNeuralNetworks/main/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Callbacks und Tensorboard\n",
    "\n",
    "This notebook contains the code samples found in Chapter 7, Section 2 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). \n",
    "\n",
    "Die Themen in diesem Kapitel:\n",
    "- **PyTorch Lightning Callbacks** verwenden\n",
    "- Das Visualisierungstool **TensorBoard**\n",
    "- Bewährte Verfahren für die Entwicklung von Modellen nach dem **aktuellen Stand der Technik**\n",
    "\n",
    "In dieser Lektion lernen wir eine Reihe leistungsfähiger Tools kennen, die es uns erleichtern, schwierige Aufgaben Modelle nach dem aktuellen Stand der Technik zu entwickeln. \n",
    "- PyTorch Lightning Callbacks und das browserbasierte Visualisierungstool TensorBoard ermöglichen es, Modelle während des Trainings zu überwachen.\n",
    "- Darüber hinaus kommen verschiedene andere bewährte Verfahren zur Sprache, wie die Normierung von Stapeln (*batch normalization*), residuale Verbindungen (*residual connections*), Hyperparameteroptimierung (*hyperparameter tuning*) und Ensemblemodelle (*ensemble models*).\n",
    "\n",
    "### 7.1 Deep-Learning-Modelle mit PyTorch Lightning und TensorBoard untersuchen und überwachen\n",
    "\n",
    "In diesem Abschnitt werden wir die Möglichkeiten untersuchen, mehr Kontrolle\n",
    "darüber zu erlangen, was beim Training eines Modells geschieht. \n",
    "- Das Training eines Modells mit einer grossen Datenmenge über Dutzende Epochen hinweg durch den Aufruf von `trainer.fit()` zu starten, hat eine gewisse Ähnlichkeit mit dem Werfen eines Papierflugzeugs: Nachdem Sie es losgelassen haben, können Sie keinen Einfluss mehr auf die Flugbahn oder den Ort der Landung nehmen. \n",
    "- Wenn Sie verhindern möchten, dass die Flüge ein schlimmes Ende nehmen (und die Papierflugzeuge zerstört werden), wäre es besser, statt eines Papierflugzeugs eine Drohne zu verwenden, die ihre Umgebung wahrnimmt, Daten an den Drohnenpiloten übermittelt und automatisch auf den aktuellen Zustand reagieren kann. \n",
    "- Der Aufruf von `trainer.fit()` macht mithilfe der hier vorgestellten Verfahren aus einem Papierflugzeug eine intelligente autonome Drohne, die sich selbst überwacht und dynamisch auf Ereignisse reagieren kann.\n",
    "\n",
    "### Beeinflussung eines Modells während des Trainings durch Callbacks\n",
    "\n",
    "Beim Trainieren eines Modells gibt es viele Dinge, die sich nicht vorhersagen lassen.\n",
    "Sie wissen insbesondere nicht, wie viele Epochen erforderlich sind, um bei\n",
    "der Validierung den optimalen Wert der Verlustfunktion zu erreichen. In den bisherigen\n",
    "Beispielen haben wir die Strategie verfolgt, das Modell so lange zu trainieren,\n",
    "bis eine Überanpassung einsetzt. Anschließend wurde das Modell von Grund\n",
    "auf neu mit der so ermittelten Anzahl von Epochen trainiert. Aber dieser Ansatz\n",
    "ist natürlich aufwendig und unwirtschaftlich. \n",
    "\n",
    "\n",
    "### Callbacks\n",
    "\n",
    "Besser wäre es, das Training abzubrechen, wenn Sie feststellen, dass sich die\n",
    "Werte der Verlustfunktion nicht mehr verbessern, und genau das lässt sich mit\n",
    "PyTorch Lightning's `Callbacks` erreichen. \n",
    "- Ein `Callback` ist ein Objekt (eine Klasseninstanz, die bestimmte Methoden implementiert), das dem Trainer beim Aufruf von `fit()` übergeben wird. \n",
    "\n",
    "- Anschließend ruft der Trainer dieses Objekt zu verschiedenen Zeitpunkten während des Trainings auf. \n",
    "\n",
    "- Das `Callback`-Objekt hat Zugriff auf alle verfügbaren Daten über den Zustand des Modells und dessen Leistung und kann Maßnahmen ergreifen: das Training unterbrechen, ein Modell speichern, andere Gewichtungen einlesen oder den Zustand des Modells auf andere Weise ändern.\n",
    "\n",
    "### Anwendungen von Callbacks:\n",
    "\n",
    "- Fixpunkterstellung (Model Checkpointing) – Die aktuellen Gewichtungen des Modells werden zu bestimmten Zeitpunkten während des Trainings automatisch gespeichert, z. B. das beste Modell basierend auf der Validierungsmetrik.\n",
    "→ ``lightning.pytorch.callbacks.ModelCheckpoint``\n",
    "\n",
    "- early stopping (früher Abbruch) – Wenn sich der Validierungsverlust oder eine andere Metrik über mehrere Epochen nicht mehr verbessert, wird das Training abgebrochen. Das beste gefundene Modell bleibt erhalten.\n",
    "→ ``lightning.pytorch.callbacks.EarlyStopping``\n",
    "\n",
    "- Dynamische Anpassung bestimmter Hyperparameter während des Trainings – typischerweise die Lernrate des Optimierers.\n",
    "→ z. B. ``torch.optim.lr_scheduler.LambdaLR`` oder ``ReduceLROnPlateau`` über ``configure_optimizers``\n",
    "\n",
    "- Protokollierung von Leistungskennzahlen des Trainings und der Validierung oder auch Visualisierung von Metriken und erlernten Repräsentationen während des Trainings.\n",
    "→ ``lightning.pytorch.loggers.CSVLogger``, TensorBoardLogger, etc.\n",
    "\n",
    "Der bekannte Fortschrittsbalken beim Training kommt auch in Lightning – standardmässig – über einen eingebauten Callback (ProgressBar).\n",
    "| Lightning Entsprechung                                     |\n",
    "|------------------------------------------------------------|\n",
    "| `lightning.pytorch.callbacks.ModelCheckpoint`              |\n",
    "| `lightning.pytorch.callbacks.EarlyStopping`                |\n",
    "| `torch.optim.lr_scheduler.LambdaLR` + `configure_optimizers` |\n",
    "| `torch.optim.lr_scheduler.ReduceLROnPlateau` + `configure_optimizers` |\n",
    "| `lightning.pytorch.loggers.CSVLogger`                      |\n",
    "\n",
    "\n",
    "Einige davon werden wir etwas näher betrachten, damit Sie eine Vorstellung\n",
    "davon bekommen, wie man sie verwendet, nämlich \n",
    "- `ModelCheckpoint` (Fixpunkterstellung),\n",
    "- `EarlyStopping` (früher Abbruch) und \n",
    "- `ReduceLROnPlateau` (Anpassung der Lernrate).\n",
    "## 7.2 Ein bekanntes Beispiel (CNN, MNIST-Datensatz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks und TensorBoard mit PyTorch Lightning\n",
    "\n",
    "In diesem Notebook lernst du, wie man mit **PyTorch Lightning** (importiert als `L`) das Training von Deep-Learning-Modellen überwacht und steuert.\n",
    "\n",
    "**Zentrale Themen:**\n",
    "- Verwendung von **Callbacks** zur dynamischen Beeinflussung des Trainings\n",
    "- Visualisierung von Metriken mit **TensorBoard**\n",
    "- Best Practices: Early Stopping, Model Checkpointing, Lernratenanpassung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import lightning.pytorch as L\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation: Kontrolle beim Modelltraining\n",
    "\n",
    "Beim Training von Deep-Learning-Modellen laufen viele Prozesse automatisch ab. Ohne Kontrolle könnte das Training:\n",
    "- zu lange dauern\n",
    "- in Überanpassung (Overfitting) enden\n",
    "- eine suboptimale Lernrate verwenden\n",
    "\n",
    "✔ Durch den Einsatz von **Callbacks** können wir eingreifen:\n",
    "- **Training frühzeitig abbrechen** (Early Stopping)\n",
    "- **Bestes Modell speichern** (ModelCheckpoint)\n",
    "- **Lernrate dynamisch anpassen** (ReduceLROnPlateau)\n",
    "\n",
    "✔ Mit **TensorBoard** sehen wir, wie sich Metriken entwickeln, und können fundierte Entscheidungen treffen.\n",
    "\n",
    "\n",
    "### PyTorch Lightning: Vorteile\n",
    "\n",
    "Lightning strukturiert deinen Code und entlastet dich von Boilerplate:\n",
    "- ➔ Trainings- und Validierungslogik übersichtlich in `training_step`, `validation_step`\n",
    "- ➔ Einfaches Logging mit `self.log()`\n",
    "- ➔ Integration von Callbacks und TensorBoard ohne Mehraufwand\n",
    "\n",
    "\n",
    "### Daten laden (MNIST)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_ds, val_ds = random_split(mnist_train, [55000, 5000])\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=128)\n",
    "test_loader = DataLoader(mnist_test, batch_size=128)\n",
    "\n",
    "# Visualisierung einiger Bilder\n",
    "fig, axs = plt.subplots(5, 10, figsize=(12, 6))\n",
    "k = 0\n",
    "for i in range(5):\n",
    "    for j in range(10):\n",
    "        axs[i, j].imshow(train_ds[k][0].squeeze(), cmap=\"gray\")\n",
    "        axs[i, j].axis(\"off\")\n",
    "        k += 1\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell als LightningModule definieren\n",
    "\n",
    "Ein `LightningModule` definiert:\n",
    "- das Modell (Layers, Architektur)\n",
    "- die Loss-Funktion\n",
    "- die Schritte für Training und Validierung\n",
    "- Optimizer und Scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64 * 5 * 5, 10),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        )\n",
    "        self.loss_fn = nn.NLLLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss, on_epoch=True)\n",
    "        self.log(\"train_acc\", acc, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"},\n",
    "        }\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks erklärt\n",
    "\n",
    "### Was genau machen Callbacks im Detail?\n",
    "Was genau machen Callbacks im Detail?\n",
    "- **ModelCheckpoint**\n",
    "    - Speichert automatisch das Modell, wenn sich eine bestimmte Metrik verbessert (z. B. ``val_loss`` oder ``val_acc``).\n",
    "    - Vorteil: Du verlierst nie das beste Modell – selbst wenn das Training später schlechter wird.\n",
    "    - ➔ Beispiel: Bestes Ergebnis war bei Epoche 17 → dieses Modell wird gespeichert.\n",
    "    - Pfad zur Datei: Standard oder via ``dirpath`` definierbar.\n",
    "\n",
    "- **EarlyStopping**\n",
    "    - Stoppt das Training automatisch, wenn sich eine Metrik über mehrere Epochen nicht mehr verbessert.\n",
    "    - Verhindert Overfitting und spart Zeit.\n",
    "    - ➔ Beispiel: ``patience=3`` ➔ nach 3 Epochen ohne Verbesserung wird gestoppt.\n",
    "    - Das beste Modell bleibt gespeichert (in Kombi mit ModelCheckpoint).\n",
    "\n",
    "- **TensorBoard – Visualisierung leicht gemacht**\n",
    "    - Ein browserbasiertes Tool zur Überwachung des Trainingsverlaufs.\n",
    "    - Zeigt:\n",
    "        - 📊 Verlust (``Loss``) und Genauigkeit (``Accuracy``) über die Zeit\n",
    "        - 🔍 Modellgraph (Architektur)\n",
    "        - 📈 Lernratenverlauf\n",
    "        - 📉 Gewichtshistogramme\n",
    "        - 📝 Eigene Logs (Text, Bilder etc.)\n",
    "\n",
    "[noch mehr Lightning Callbacks hier!](https://lightning.ai/docs/pytorch/stable/extensions/callbacks.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = L.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\", save_top_k=1, mode=\"min\", filename=\"mnist-best\"\n",
    ")\n",
    "\n",
    "earlystop_cb = L.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "\n",
    "logger = L.loggers.TensorBoardLogger(\"tb_logs\", name=\"mnist_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training starten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel()\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=5,\n",
    "    callbacks=[checkpoint_cb, earlystop_cb],\n",
    "    logger=logger,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, dataloaders=test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard starten in Kommandozeile\n",
    "\n",
    "```bash\n",
    "%tensorboard --logdir=Lektionen/ANN07/pytorchlightning/tb_logs\n",
    "```\n",
    "\n",
    "➔ Im Browser: `http://localhost:6006`\n",
    "\n",
    "Du siehst: Trainingskurven, Validierungsmetriken, Histogramme, Graphen. (eventuell Pfad anpassen!)\n",
    "\n",
    "### Benutzerdefinierter Callback: Aktivierungen speichern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLoggerCallback(L.Callback):\n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        sample = next(iter(val_loader))[0][0:1].to(pl_module.device)\n",
    "        with torch.no_grad():\n",
    "            activations = pl_module.model(sample)\n",
    "        np.save(\n",
    "            f\"activations_epoch_{trainer.current_epoch}.npy\", activations.cpu().numpy()\n",
    "        )\n",
    "\n",
    "\n",
    "# Training mit eigenem Callback\n",
    "trainer_with_custom_cb = L.Trainer(\n",
    "    max_epochs=5, callbacks=[ActivationLoggerCallback()], logger=logger\n",
    ")\n",
    "trainer_with_custom_cb.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Fazit\n",
    "\n",
    "Mit **Callbacks** und **TensorBoard** kannst du das Modelltraining nicht nur besser verstehen, sondern auch effizienter und intelligenter steuern:\n",
    "- **Zeit sparen** durch frühzeitiges Stoppen\n",
    "- **Beste Modelle sichern**\n",
    "- **Lernrate adaptiv anpassen**\n",
    "- **Metriken visuell analysieren** für bessere Entscheidungen\n",
    "\n",
    "PyTorch Lightning macht das einfach – und deine Experimente werden reproduzierbar und sauber dokumentiert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
